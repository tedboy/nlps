

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3. Similarity Queries</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../index.html"/>
        <link rel="up" title="Gensim Tutorials" href="tutorial.html"/>
        <link rel="next" title="4. Experiments on the English Wikipedia" href="wiki.html"/>
        <link rel="prev" title="2. Topics and Transformations" href="tut2.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="tutorial.html">Gensim Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tut1.html">1. Corpora and Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="tut2.html">2. Topics and Transformations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">3. Similarity Queries</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#similarity-interface">3.1. Similarity interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#initializing-query-structures">3.1.1. Initializing query structures</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performing-queries">3.1.2. Performing queries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#where-next">3.2. Where next?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="wiki.html">4. Experiments on the English Wikipedia</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html">5. Distributed Computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial.html#preliminaries">Preliminaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial.html#quick-example">Quick Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="tutorial.html">Gensim Tutorials</a> &raquo;</li>
        
      <li>3. Similarity Queries</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/gensim_tutorial/tut3.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="similarity-queries">
<span id="tut3"></span><h1>3. Similarity Queries<a class="headerlink" href="#similarity-queries" title="Permalink to this headline">¶</a></h1>
<p>Don&#8217;t forget to set</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">logging</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> : </span><span class="si">%(levelname)s</span><span class="s1"> : </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>
</div>
<p>if you want to see logging events.</p>
<div class="section" id="similarity-interface">
<h2>3.1. Similarity interface<a class="headerlink" href="#similarity-interface" title="Permalink to this headline">¶</a></h2>
<p>In the previous tutorials on <a class="reference internal" href="tut1.html"><em>Corpora and Vector Spaces</em></a> and <a class="reference internal" href="tut2.html"><em>Topics and Transformations</em></a>, we covered what it means
to create a corpus in the Vector Space Model and how to transform it between different
vector spaces. A common reason for such a charade is that we want to determine
<strong>similarity between pairs of documents</strong>, or the <strong>similarity between a specific document
and a set of other documents</strong> (such as a user query vs. indexed documents).</p>
<p>To show how this can be done in gensim, let us consider the same corpus as in the
previous examples (which really originally comes from Deerwester et al.&#8217;s
<a class="reference external" href="http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf">&#8220;Indexing by Latent Semantic Analysis&#8221;</a>
seminal 1990 article):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.dict&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.mm&#39;</span><span class="p">)</span> <span class="c1"># comes from the first tutorial, &quot;From strings to vectors&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="go">MmCorpus(9 documents, 12 features, 28 non-zero entries)</span>
</pre></div>
</div>
<p>To follow Deerwester&#8217;s example, we first use this tiny corpus to define a 2-dimensional
LSI space:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Now suppose a user typed in the query <cite>&#8220;Human computer interaction&#8221;</cite>. We would
like to sort our nine corpus documents in decreasing order of relevance to this query.
Unlike modern search engines, here we only concentrate on a single aspect of possible
similarities&#8212;on apparent semantic relatedness of their texts (words). No hyperlinks,
no random-walk static ranks, just a semantic extension over the boolean keyword match:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">doc</span> <span class="o">=</span> <span class="s2">&quot;Human computer interaction&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec_bow</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">lsi</span><span class="p">[</span><span class="n">vec_bow</span><span class="p">]</span> <span class="c1"># convert the query to LSI space</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">vec_lsi</span><span class="p">)</span>
<span class="go">[(0, -0.461821), (1, 0.070028)]</span>
</pre></div>
</div>
<p>In addition, we will be considering <a class="reference external" href="http://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a>
to determine the similarity of two vectors. Cosine similarity is a standard measure
in Vector Space Modeling, but wherever the vectors represent probability distributions,
<a class="reference external" href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Symmetrised_divergence">different similarity measures</a>
may be more appropriate.</p>
<div class="section" id="initializing-query-structures">
<h3>3.1.1. Initializing query structures<a class="headerlink" href="#initializing-query-structures" title="Permalink to this headline">¶</a></h3>
<p>To prepare for similarity queries, we need to enter all documents which we want
to compare against subsequent queries. In our case, they are the same nine documents
used for training LSI, converted to 2-D LSA space. But that&#8217;s only incidental, we
might also be indexing a different corpus altogether.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">lsi</span><span class="p">[</span><span class="n">corpus</span><span class="p">])</span> <span class="c1"># transform corpus to LSI space and index it</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>The class <code class="xref py py-class docutils literal"><span class="pre">similarities.MatrixSimilarity</span></code> is only appropriate when the whole
set of vectors fits into memory. For example, a corpus of one million documents
would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.</p>
<p class="last">Without 2GB of free RAM, you would need to use the <code class="xref py py-class docutils literal"><span class="pre">similarities.Similarity</span></code> class.
This class operates in fixed memory, by splitting the index across multiple files on disk, called shards.
It uses <code class="xref py py-class docutils literal"><span class="pre">similarities.MatrixSimilarity</span></code> and <code class="xref py py-class docutils literal"><span class="pre">similarities.SparseMatrixSimilarity</span></code> internally,
so it is still fast, although slightly more complex.</p>
</div>
<p>Index persistency is handled via the standard <code class="xref py py-func docutils literal"><span class="pre">save()</span></code> and <code class="xref py py-func docutils literal"><span class="pre">load()</span></code> functions:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">index</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.index&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.index&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This is true for all similarity indexing classes (<code class="xref py py-class docutils literal"><span class="pre">similarities.Similarity</span></code>,
<code class="xref py py-class docutils literal"><span class="pre">similarities.MatrixSimilarity</span></code> and <code class="xref py py-class docutils literal"><span class="pre">similarities.SparseMatrixSimilarity</span></code>).
Also in the following, <cite>index</cite> can be an object of any of these. When in doubt,
use <code class="xref py py-class docutils literal"><span class="pre">similarities.Similarity</span></code>, as it is the most scalable version, and it also
supports adding more documents to the index later.</p>
</div>
<div class="section" id="performing-queries">
<h3>3.1.2. Performing queries<a class="headerlink" href="#performing-queries" title="Permalink to this headline">¶</a></h3>
<p>To obtain similarities of our query document against the nine indexed documents:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sims</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">vec_lsi</span><span class="p">]</span> <span class="c1"># perform a similarity query against the corpus</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">)))</span> <span class="c1"># print (document_number, document_similarity) 2-tuples</span>
<span class="go">[(0, 0.99809301), (1, 0.93748635), (2, 0.99844527), (3, 0.9865886), (4, 0.90755945),</span>
<span class="go">(5, -0.12416792), (6, -0.1063926), (7, -0.098794639), (8, 0.05004178)]</span>
</pre></div>
</div>
<p>Cosine measure returns similarities in the range <cite>&lt;-1, 1&gt;</cite> (the greater, the more similar),
so that the first document has a score of 0.99809301 etc.</p>
<p>With some standard Python magic we sort these similarities into descending
order, and obtain the final answer to the query <cite>&#8220;Human computer interaction&#8221;</cite>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sims</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="o">-</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">sims</span><span class="p">)</span> <span class="c1"># print sorted (document number, similarity score) 2-tuples</span>
<span class="go">[(2, 0.99844527), # The EPS user interface management system</span>
<span class="go">(0, 0.99809301), # Human machine interface for lab abc computer applications</span>
<span class="go">(3, 0.9865886), # System and human system engineering testing of EPS</span>
<span class="go">(1, 0.93748635), # A survey of user opinion of computer system response time</span>
<span class="go">(4, 0.90755945), # Relation of user perceived response time to error measurement</span>
<span class="go">(8, 0.050041795), # Graph minors A survey</span>
<span class="go">(7, -0.098794639), # Graph minors IV Widths of trees and well quasi ordering</span>
<span class="go">(6, -0.1063926), # The intersection graph of paths in trees</span>
<span class="go">(5, -0.12416792)] # The generation of random binary unordered trees</span>
</pre></div>
</div>
<p>(I added the original documents in their &#8220;string form&#8221; to the output comments, to
improve clarity.)</p>
<p>The thing to note here is that documents no. 2 (<code class="docutils literal"><span class="pre">&quot;The</span> <span class="pre">EPS</span> <span class="pre">user</span> <span class="pre">interface</span> <span class="pre">management</span> <span class="pre">system&quot;</span></code>)
and 4 (<code class="docutils literal"><span class="pre">&quot;Relation</span> <span class="pre">of</span> <span class="pre">user</span> <span class="pre">perceived</span> <span class="pre">response</span> <span class="pre">time</span> <span class="pre">to</span> <span class="pre">error</span> <span class="pre">measurement&quot;</span></code>) would never be returned by
a standard boolean fulltext search, because they do not share any common words with <code class="docutils literal"><span class="pre">&quot;Human</span>
<span class="pre">computer</span> <span class="pre">interaction&quot;</span></code>. However, after applying LSI, we can observe that both of
them received quite high similarity scores (no. 2 is actually the most similar!),
which corresponds better to our intuition of
them sharing a &#8220;computer-human&#8221; related topic with the query. In fact, this semantic
generalization is the reason why we apply transformations and do topic modelling
in the first place.</p>
</div>
</div>
<div class="section" id="where-next">
<h2>3.2. Where next?<a class="headerlink" href="#where-next" title="Permalink to this headline">¶</a></h2>
<p>Congratulations, you have finished the tutorials &#8211; now you know how gensim works :-)
To delve into more details, you can browse through the <code class="xref doc docutils literal"><span class="pre">API</span> <span class="pre">documentation</span></code>,
see the <a class="reference internal" href="wiki.html"><em>Wikipedia experiments</em></a> or perhaps check out <a class="reference internal" href="distributed.html"><em>distributed computing</em></a> in <cite>gensim</cite>.</p>
<p>Gensim is a fairly mature package that has been used successfully by many individuals and companies, both for rapid prototyping and in production.
That doesn&#8217;t mean it&#8217;s perfect though:</p>
<ul class="simple">
<li>there are parts that could be implemented more efficiently (in C, for example), or make better use of parallelism (multiple machines cores)</li>
<li>new algorithms are published all the time; help gensim keep up by <a class="reference external" href="http://groups.google.com/group/gensim">discussing them</a> and <a class="reference external" href="https://github.com/piskvorky/gensim/wiki/Developer-page">contributing code</a></li>
<li>your <strong>feedback is most welcome</strong> and appreciated (and it&#8217;s not just the code!):
<a class="reference external" href="https://github.com/piskvorky/gensim/wiki/Ideas-&amp;-Features-proposals">idea contributions</a>,
<a class="reference external" href="https://github.com/piskvorky/gensim/issues">bug reports</a> or just consider contributing
<a class="reference external" href="http://groups.google.com/group/gensim/topics">user stories and general questions</a>.</li>
</ul>
<p>Gensim has no ambition to become an all-encompassing framework, across all NLP (or even Machine Learning) subfields.
Its mission is to help NLP practicioners try out popular topic modelling algorithms
on large datasets easily, and to facilitate prototyping of new algorithms for researchers.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="wiki.html" class="btn btn-neutral float-right" title="4. Experiments on the English Wikipedia" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tut2.html" class="btn btn-neutral" title="2. Topics and Transformations" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>