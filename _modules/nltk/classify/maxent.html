

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nltk.classify.maxent</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="nltk" href="../../nltk.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../nltk.html">nltk</a> &raquo;</li>
        
      <li>nltk.classify.maxent</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nltk.classify.maxent</h1><div class="highlight"><pre>
<span></span><span class="c1"># Natural Language Toolkit: Maximum Entropy Classifiers</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2015 NLTK Project</span>
<span class="c1"># Author: Edward Loper &lt;edloper@gmail.com&gt;</span>
<span class="c1">#         Dmitry Chichkov &lt;dchichkov@gmail.com&gt; (TypedMaxentFeatureEncoding)</span>
<span class="c1"># URL: &lt;http://nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A classifier model based on maximum entropy modeling framework.  This</span>
<span class="sd">framework considers all of the probability distributions that are</span>
<span class="sd">empirically consistent with the training data; and chooses the</span>
<span class="sd">distribution with the highest entropy.  A probability distribution is</span>
<span class="sd">&quot;empirically consistent&quot; with a set of training data if its estimated</span>
<span class="sd">frequency with which a class and a feature vector value co-occur is</span>
<span class="sd">equal to the actual frequency in the data.</span>

<span class="sd">Terminology: &#39;feature&#39;</span>
<span class="sd">======================</span>
<span class="sd">The term *feature* is usually used to refer to some property of an</span>
<span class="sd">unlabeled token.  For example, when performing word sense</span>
<span class="sd">disambiguation, we might define a ``&#39;prevword&#39;`` feature whose value is</span>
<span class="sd">the word preceding the target word.  However, in the context of</span>
<span class="sd">maxent modeling, the term *feature* is typically used to refer to a</span>
<span class="sd">property of a &quot;labeled&quot; token.  In order to prevent confusion, we</span>
<span class="sd">will introduce two distinct terms to disambiguate these two different</span>
<span class="sd">concepts:</span>

<span class="sd">  - An &quot;input-feature&quot; is a property of an unlabeled token.</span>
<span class="sd">  - A &quot;joint-feature&quot; is a property of a labeled token.</span>

<span class="sd">In the rest of the ``nltk.classify`` module, the term &quot;features&quot; is</span>
<span class="sd">used to refer to what we will call &quot;input-features&quot; in this module.</span>

<span class="sd">In literature that describes and discusses maximum entropy models,</span>
<span class="sd">input-features are typically called &quot;contexts&quot;, and joint-features</span>
<span class="sd">are simply referred to as &quot;features&quot;.</span>

<span class="sd">Converting Input-Features to Joint-Features</span>
<span class="sd">-------------------------------------------</span>
<span class="sd">In maximum entropy models, joint-features are required to have numeric</span>
<span class="sd">values.  Typically, each input-feature ``input_feat`` is mapped to a</span>
<span class="sd">set of joint-features of the form:</span>

<span class="sd">|   joint_feat(token, label) = { 1 if input_feat(token) == feat_val</span>
<span class="sd">|                              {      and label == some_label</span>
<span class="sd">|                              {</span>
<span class="sd">|                              { 0 otherwise</span>

<span class="sd">For all values of ``feat_val`` and ``some_label``.  This mapping is</span>
<span class="sd">performed by classes that implement the ``MaxentFeatureEncodingI``</span>
<span class="sd">interface.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>
<span class="n">__docformat__</span> <span class="o">=</span> <span class="s1">&#39;epytext en&#39;</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">numpy</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">compat</span>
<span class="kn">from</span> <span class="nn">nltk.data</span> <span class="kn">import</span> <span class="n">gzip_open_unicode</span>
<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">DictionaryProbDist</span>

<span class="kn">from</span> <span class="nn">nltk.classify.api</span> <span class="kn">import</span> <span class="n">ClassifierI</span>
<span class="kn">from</span> <span class="nn">nltk.classify.util</span> <span class="kn">import</span> <span class="n">CutoffChecker</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">log_likelihood</span>
<span class="kn">from</span> <span class="nn">nltk.classify.megam</span> <span class="kn">import</span> <span class="p">(</span><span class="n">call_megam</span><span class="p">,</span>
                                 <span class="n">write_megam_file</span><span class="p">,</span> <span class="n">parse_megam_weights</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.classify.tadm</span> <span class="kn">import</span> <span class="n">call_tadm</span><span class="p">,</span> <span class="n">write_tadm_file</span><span class="p">,</span> <span class="n">parse_tadm_weights</span>

<span class="c1">######################################################################</span>
<span class="c1">#{ Classifier Model</span>
<span class="c1">######################################################################</span>

<span class="nd">@compat.python_2_unicode_compatible</span>
<div class="viewcode-block" id="MaxentClassifier"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.html#nltk.MaxentClassifier">[docs]</a><span class="k">class</span> <span class="nc">MaxentClassifier</span><span class="p">(</span><span class="n">ClassifierI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A maximum entropy classifier (also known as a &quot;conditional</span>
<span class="sd">    exponential classifier&quot;).  This classifier is parameterized by a</span>
<span class="sd">    set of &quot;weights&quot;, which are used to combine the joint-features</span>
<span class="sd">    that are generated from a featureset by an &quot;encoding&quot;.  In</span>
<span class="sd">    particular, the encoding maps each ``(featureset, label)`` pair to</span>
<span class="sd">    a vector.  The probability of each label is then computed using</span>
<span class="sd">    the following equation::</span>

<span class="sd">                                dotprod(weights, encode(fs,label))</span>
<span class="sd">      prob(fs|label) = ---------------------------------------------------</span>
<span class="sd">                       sum(dotprod(weights, encode(fs,l)) for l in labels)</span>

<span class="sd">    Where ``dotprod`` is the dot product::</span>

<span class="sd">      dotprod(a,b) = sum(x*y for (x,y) in zip(a,b))</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="MaxentClassifier.__init__"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.__init__.html#nltk.MaxentClassifier.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">logarithmic</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct a new maxent classifier model.  Typically, new</span>
<span class="sd">        classifier models are created using the ``train()`` method.</span>

<span class="sd">        :type encoding: MaxentFeatureEncodingI</span>
<span class="sd">        :param encoding: An encoding that is used to convert the</span>
<span class="sd">            featuresets that are given to the ``classify`` method into</span>
<span class="sd">            joint-feature vectors, which are used by the maxent</span>
<span class="sd">            classifier model.</span>

<span class="sd">        :type weights: list of float</span>
<span class="sd">        :param weights:  The feature weight vector for this classifier.</span>

<span class="sd">        :type logarithmic: bool</span>
<span class="sd">        :param logarithmic: If false, then use non-logarithmic weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span> <span class="o">=</span> <span class="n">encoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logarithmic</span> <span class="o">=</span> <span class="n">logarithmic</span>
        <span class="c1">#self._logarithmic = False</span>
        <span class="k">assert</span> <span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">()</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaxentClassifier.labels"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.labels.html#nltk.MaxentClassifier.labels">[docs]</a>    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">labels</span><span class="p">()</span></div>

<div class="viewcode-block" id="MaxentClassifier.set_weights"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.set_weights.html#nltk.MaxentClassifier.set_weights">[docs]</a>    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the feature weight vector for this classifier.</span>
<span class="sd">        :param new_weights: The new feature weight vector.</span>
<span class="sd">        :type new_weights: list of float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">new_weights</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">length</span><span class="p">()</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaxentClassifier.weights"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.weights.html#nltk.MaxentClassifier.weights">[docs]</a>    <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: The feature weight vector for this classifier.</span>
<span class="sd">        :rtype: list of float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span></div>

<div class="viewcode-block" id="MaxentClassifier.classify"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.classify.html#nltk.MaxentClassifier.classify">[docs]</a>    <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_classify</span><span class="p">(</span><span class="n">featureset</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span></div>

<div class="viewcode-block" id="MaxentClassifier.prob_classify"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.prob_classify.html#nltk.MaxentClassifier.prob_classify">[docs]</a>    <span class="k">def</span> <span class="nf">prob_classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">):</span>
        <span class="n">prob_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">labels</span><span class="p">():</span>
            <span class="n">feature_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logarithmic</span><span class="p">:</span>
                <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">f_id</span><span class="p">,</span> <span class="n">f_val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">feature_vector</span><span class="p">:</span>
                    <span class="n">total</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">f_val</span>
                <span class="n">prob_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">total</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">prod</span> <span class="o">=</span> <span class="mf">1.0</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">f_id</span><span class="p">,</span> <span class="n">f_val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">feature_vector</span><span class="p">:</span>
                    <span class="n">prod</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span> <span class="o">**</span> <span class="n">f_val</span>
                <span class="n">prob_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">prod</span>

        <span class="c1"># Normalize the dictionary to give a probability distribution</span>
        <span class="k">return</span> <span class="n">DictionaryProbDist</span><span class="p">(</span><span class="n">prob_dict</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_logarithmic</span><span class="p">,</span>
                                  <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaxentClassifier.explain"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.explain.html#nltk.MaxentClassifier.explain">[docs]</a>    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Print a table showing the effect of each of the features in</span>
<span class="sd">        the given feature set, and how they combine to determine the</span>
<span class="sd">        probabilities of each label for that featureset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">descr_width</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">TEMPLATE</span> <span class="o">=</span> <span class="s1">&#39;  %-&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">descr_width</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;s</span><span class="si">%s%8.3f</span><span class="s1">&#39;</span>

        <span class="n">pdist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_classify</span><span class="p">(</span><span class="n">featureset</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pdist</span><span class="o">.</span><span class="n">samples</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">pdist</span><span class="o">.</span><span class="n">prob</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">columns</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  Feature&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">descr_width</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="s1">&#39;</span><span class="si">%8s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">((</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">l</span><span class="p">)[:</span><span class="mi">7</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  &#39;</span><span class="o">+</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">descr_width</span><span class="o">-</span><span class="mi">2</span><span class="o">+</span><span class="mi">8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
        <span class="n">sums</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">feature_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">feature_vector</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">fid__</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">fid__</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span>
                                <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">f_id</span><span class="p">,</span> <span class="n">f_val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">feature_vector</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logarithmic</span><span class="p">:</span>
                    <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">f_val</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span> <span class="o">**</span> <span class="n">f_val</span>
                <span class="n">descr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">f_id</span><span class="p">)</span>
                <span class="n">descr</span> <span class="o">=</span> <span class="n">descr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; and label is &#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># hack</span>
                <span class="n">descr</span> <span class="o">+=</span> <span class="s1">&#39; (</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">f_val</span>                 <span class="c1"># hack</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">descr</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">47</span><span class="p">:</span>
                    <span class="n">descr</span> <span class="o">=</span> <span class="n">descr</span><span class="p">[:</span><span class="mi">44</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;...&#39;</span>
                <span class="k">print</span><span class="p">(</span><span class="n">TEMPLATE</span> <span class="o">%</span> <span class="p">(</span><span class="n">descr</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="mi">8</span><span class="o">*</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
                <span class="n">sums</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="n">score</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  &#39;</span><span class="o">+</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">descr_width</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="mi">8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  TOTAL:&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">descr_width</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="s1">&#39;</span><span class="si">%8.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">sums</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  PROBS:&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">descr_width</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="s1">&#39;</span><span class="si">%8.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pdist</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">))</span></div>

<div class="viewcode-block" id="MaxentClassifier.show_most_informative_features"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.show_most_informative_features.html#nltk.MaxentClassifier.show_most_informative_features">[docs]</a>    <span class="k">def</span> <span class="nf">show_most_informative_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param show: all, neg, or pos (for negative-only or positive-only)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">))),</span>
                      <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">fid</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">fid</span><span class="p">]),</span>
                      <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span> <span class="o">==</span> <span class="s1">&#39;pos&#39;</span><span class="p">:</span>
            <span class="n">fids</span> <span class="o">=</span> <span class="p">[</span><span class="n">fid</span> <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">fids</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">show</span> <span class="o">==</span> <span class="s1">&#39;neg&#39;</span><span class="p">:</span>
            <span class="n">fids</span> <span class="o">=</span> <span class="p">[</span><span class="n">fid</span> <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">fids</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">fids</span><span class="p">[:</span><span class="n">n</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%8.3f</span><span class="s1"> </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">[</span><span class="n">fid</span><span class="p">],</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">fid</span><span class="p">)))</span></div>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;&lt;ConditionalExponentialClassifier: </span><span class="si">%d</span><span class="s1"> labels, </span><span class="si">%d</span><span class="s1"> features&gt;&#39;</span> <span class="o">%</span>
                <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">labels</span><span class="p">()),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="o">.</span><span class="n">length</span><span class="p">()))</span>

    <span class="c1">#: A list of the algorithm names that are accepted for the</span>
    <span class="c1">#: ``train()`` method&#39;s ``algorithm`` parameter.</span>
    <span class="n">ALGORITHMS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;GIS&#39;</span><span class="p">,</span> <span class="s1">&#39;IIS&#39;</span><span class="p">,</span> <span class="s1">&#39;MEGAM&#39;</span><span class="p">,</span> <span class="s1">&#39;TADM&#39;</span><span class="p">]</span>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="MaxentClassifier.train"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.MaxentClassifier.train.html#nltk.MaxentClassifier.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
              <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">gaussian_prior_sigma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train a new maxent classifier based on the given corpus of</span>
<span class="sd">        training samples.  This classifier will have its weights</span>
<span class="sd">        chosen to maximize entropy while remaining empirically</span>
<span class="sd">        consistent with the training corpus.</span>

<span class="sd">        :rtype: MaxentClassifier</span>
<span class="sd">        :return: The new maxent classifier</span>

<span class="sd">        :type train_toks: list</span>
<span class="sd">        :param train_toks: Training data, represented as a list of</span>
<span class="sd">            pairs, the first member of which is a featureset,</span>
<span class="sd">            and the second of which is a classification label.</span>

<span class="sd">        :type algorithm: str</span>
<span class="sd">        :param algorithm: A case-insensitive string, specifying which</span>
<span class="sd">            algorithm should be used to train the classifier.  The</span>
<span class="sd">            following algorithms are currently available.</span>

<span class="sd">            - Iterative Scaling Methods: Generalized Iterative Scaling (``&#39;GIS&#39;``),</span>
<span class="sd">              Improved Iterative Scaling (``&#39;IIS&#39;``)</span>
<span class="sd">            - External Libraries (requiring megam):</span>
<span class="sd">              LM-BFGS algorithm, with training performed by Megam (``&#39;megam&#39;``)</span>

<span class="sd">            The default algorithm is ``&#39;IIS&#39;``.</span>

<span class="sd">        :type trace: int</span>
<span class="sd">        :param trace: The level of diagnostic tracing output to produce.</span>
<span class="sd">            Higher values produce more verbose output.</span>
<span class="sd">        :type encoding: MaxentFeatureEncodingI</span>
<span class="sd">        :param encoding: A feature encoding, used to convert featuresets</span>
<span class="sd">            into feature vectors.  If none is specified, then a</span>
<span class="sd">            ``BinaryMaxentFeatureEncoding`` will be built based on the</span>
<span class="sd">            features that are attested in the training corpus.</span>
<span class="sd">        :type labels: list(str)</span>
<span class="sd">        :param labels: The set of possible labels.  If none is given, then</span>
<span class="sd">            the set of all labels attested in the training data will be</span>
<span class="sd">            used instead.</span>
<span class="sd">        :param gaussian_prior_sigma: The sigma value for a gaussian</span>
<span class="sd">            prior on model weights.  Currently, this is supported by</span>
<span class="sd">            ``megam``. For other algorithms, its value is ignored.</span>
<span class="sd">        :param cutoffs: Arguments specifying various conditions under</span>
<span class="sd">            which the training should be halted.  (Some of the cutoff</span>
<span class="sd">            conditions are not supported by some algorithms.)</span>

<span class="sd">            - ``max_iter=v``: Terminate after ``v`` iterations.</span>
<span class="sd">            - ``min_ll=v``: Terminate after the negative average</span>
<span class="sd">              log-likelihood drops under ``v``.</span>
<span class="sd">            - ``min_lldelta=v``: Terminate if a single iteration improves</span>
<span class="sd">              log likelihood by less than ``v``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">algorithm</span> <span class="o">=</span> <span class="s1">&#39;iis&#39;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">cutoffs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;max_iter&#39;</span><span class="p">,</span> <span class="s1">&#39;min_ll&#39;</span><span class="p">,</span> <span class="s1">&#39;min_lldelta&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;max_acc&#39;</span><span class="p">,</span> <span class="s1">&#39;min_accdelta&#39;</span><span class="p">,</span> <span class="s1">&#39;count_cutoff&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;norm&#39;</span><span class="p">,</span> <span class="s1">&#39;explicit&#39;</span><span class="p">,</span> <span class="s1">&#39;bernoulli&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Unexpected keyword arg </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">key</span><span class="p">)</span>
        <span class="n">algorithm</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;iis&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">train_maxent_classifier_with_iis</span><span class="p">(</span>
                <span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;gis&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">train_maxent_classifier_with_gis</span><span class="p">(</span>
                <span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;megam&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">train_maxent_classifier_with_megam</span><span class="p">(</span>
                <span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span>
                <span class="n">gaussian_prior_sigma</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;tadm&#39;</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">cutoffs</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;trace&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trace</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;encoding&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;gaussian_prior_sigma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gaussian_prior_sigma</span>
            <span class="k">return</span> <span class="n">TadmMaxentClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown algorithm </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">algorithm</span><span class="p">)</span></div></div>


<span class="c1">#: Alias for MaxentClassifier.</span>
<span class="n">ConditionalExponentialClassifier</span> <span class="o">=</span> <span class="n">MaxentClassifier</span>


<span class="c1">######################################################################</span>
<span class="c1">#{ Feature Encodings</span>
<span class="c1">######################################################################</span>

<span class="k">class</span> <span class="nc">MaxentFeatureEncodingI</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A mapping that converts a set of input-feature values to a vector</span>
<span class="sd">    of joint-feature values, given a label.  This conversion is</span>
<span class="sd">    necessary to translate featuresets into a format that can be used</span>
<span class="sd">    by maximum entropy models.</span>

<span class="sd">    The set of joint-features used by a given encoding is fixed, and</span>
<span class="sd">    each index in the generated joint-feature vectors corresponds to a</span>
<span class="sd">    single joint-feature.  The length of the generated joint-feature</span>
<span class="sd">    vectors is therefore constant (for a given encoding).</span>

<span class="sd">    Because the joint-feature vectors generated by</span>
<span class="sd">    ``MaxentFeatureEncodingI`` are typically very sparse, they are</span>
<span class="sd">    represented as a list of ``(index, value)`` tuples, specifying the</span>
<span class="sd">    value of each non-zero joint-feature.</span>

<span class="sd">    Feature encodings are generally created using the ``train()``</span>
<span class="sd">    method, which generates an appropriate encoding based on the</span>
<span class="sd">    input-feature values and labels that are present in a given</span>
<span class="sd">    corpus.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a (featureset, label) pair, return the corresponding</span>
<span class="sd">        vector of joint-feature values.  This vector is represented as</span>
<span class="sd">        a list of ``(index, value)`` tuples, specifying the value of</span>
<span class="sd">        each non-zero joint-feature.</span>

<span class="sd">        :type featureset: dict</span>
<span class="sd">        :rtype: list(tuple(int, int))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: The size of the fixed-length joint-feature vectors</span>
<span class="sd">            that are generated by this encoding.</span>
<span class="sd">        :rtype: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: A list of the \&quot;known labels\&quot; -- i.e., all labels</span>
<span class="sd">            ``l`` such that ``self.encode(fs,l)`` can be a nonzero</span>
<span class="sd">            joint-feature vector for some value of ``fs``.</span>
<span class="sd">        :rtype: list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fid</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: A string describing the value of the joint-feature</span>
<span class="sd">            whose index in the generated feature vectors is ``fid``.</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct and return new feature encoding, based on a given</span>
<span class="sd">        training corpus ``train_toks``.</span>

<span class="sd">        :type train_toks: list(tuple(dict, str))</span>
<span class="sd">        :param train_toks: Training data, represented as a list of</span>
<span class="sd">            pairs, the first member of which is a feature dictionary,</span>
<span class="sd">            and the second of which is a classification label.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">FunctionBackedMaxentFeatureEncoding</span><span class="p">(</span><span class="n">MaxentFeatureEncodingI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature encoding that calls a user-supplied function to map a</span>
<span class="sd">    given featureset/label pair to a sparse joint-feature vector.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct a new feature encoding based on the given function.</span>

<span class="sd">        :type func: (callable)</span>
<span class="sd">        :param func: A function that takes two arguments, a featureset</span>
<span class="sd">             and a label, and returns the sparse joint feature vector</span>
<span class="sd">             that encodes them::</span>

<span class="sd">                 func(featureset, label) -&gt; feature_vector</span>

<span class="sd">             This sparse joint feature vector (``feature_vector``) is a</span>
<span class="sd">             list of ``(index,value)`` tuples.</span>

<span class="sd">        :type length: int</span>
<span class="sd">        :param length: The size of the fixed-length joint-feature</span>
<span class="sd">            vectors that are generated by this encoding.</span>

<span class="sd">        :type labels: list</span>
<span class="sd">        :param labels: A list of the \&quot;known labels\&quot; for this</span>
<span class="sd">            encoding -- i.e., all labels ``l`` such that</span>
<span class="sd">            ``self.encode(fs,l)`` can be a nonzero joint-feature vector</span>
<span class="sd">            for some value of ``fs``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_func</span> <span class="o">=</span> <span class="n">func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_func</span><span class="p">(</span><span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span>

    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span>

    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fid</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;no description available&#39;</span>

<div class="viewcode-block" id="BinaryMaxentFeatureEncoding"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.html#nltk.BinaryMaxentFeatureEncoding">[docs]</a><span class="k">class</span> <span class="nc">BinaryMaxentFeatureEncoding</span><span class="p">(</span><span class="n">MaxentFeatureEncodingI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature encoding that generates vectors containing a binary</span>
<span class="sd">    joint-features of the form:</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    Where ``fname`` is the name of an input-feature, ``fval`` is a value</span>
<span class="sd">    for that input-feature, and ``label`` is a label.</span>

<span class="sd">    Typically, these features are constructed based on a training</span>
<span class="sd">    corpus, using the ``train()`` method.  This method will create one</span>
<span class="sd">    feature for each combination of ``fname``, ``fval``, and ``label``</span>
<span class="sd">    that occurs at least once in the training corpus.</span>

<span class="sd">    The ``unseen_features`` parameter can be used to add &quot;unseen-value</span>
<span class="sd">    features&quot;, which are used whenever an input feature has a value</span>
<span class="sd">    that was not encountered in the training corpus.  These features</span>
<span class="sd">    have the form:</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])</span>
<span class="sd">    |                      {      and l == label</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    Where ``is_unseen(fname, fval)`` is true if the encoding does not</span>
<span class="sd">    contain any joint features that are true when ``fs[fname]==fval``.</span>

<span class="sd">    The ``alwayson_features`` parameter can be used to add &quot;always-on</span>
<span class="sd">    features&quot;, which have the form::</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if (l == label)</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    These always-on features allow the maxent model to directly model</span>
<span class="sd">    the prior probabilities of each label.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.__init__"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.__init__.html#nltk.BinaryMaxentFeatureEncoding.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="n">unseen_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">alwayson_features</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param labels: A list of the \&quot;known labels\&quot; for this encoding.</span>

<span class="sd">        :param mapping: A dictionary mapping from ``(fname,fval,label)``</span>
<span class="sd">            tuples to corresponding joint-feature indexes.  These</span>
<span class="sd">            indexes must be the set of integers from 0...len(mapping).</span>
<span class="sd">            If ``mapping[fname,fval,label]=id``, then</span>
<span class="sd">            ``self.encode(..., fname:fval, ..., label)[id]`` is 1;</span>
<span class="sd">            otherwise, it is 0.</span>

<span class="sd">        :param unseen_features: If true, then include unseen value</span>
<span class="sd">           features in the generated joint-feature vectors.</span>

<span class="sd">        :param alwayson_features: If true, then include always-on</span>
<span class="sd">           features in the generated joint-feature vectors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">mapping</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">))):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Mapping values must be exactly the &#39;</span>
                             <span class="s1">&#39;set of integers from 0...len(mapping)&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;A list of attested labels.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span> <span class="o">=</span> <span class="n">mapping</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from (fname,fval,label) -&gt; fid&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;The length of generated joint feature vectors.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from label -&gt; fid&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from fname -&gt; fid&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">alwayson_features</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_length</span><span class="p">)</span>
                                  <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">unseen_features</span><span class="p">:</span>
            <span class="n">fnames</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">fname</span> <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">fname</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_length</span><span class="p">)</span>
                                <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fnames</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fnames</span><span class="p">)</span></div>

<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.encode"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.encode.html#nltk.BinaryMaxentFeatureEncoding.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Convert input-features to joint-features:</span>
        <span class="k">for</span> <span class="n">fname</span><span class="p">,</span> <span class="n">fval</span> <span class="ow">in</span> <span class="n">featureset</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Known feature name &amp; value:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

            <span class="c1"># Otherwise, we might want to fire an &quot;unseen-value feature&quot;.</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">:</span>
                <span class="c1"># Have we seen this fname/fval combination with any label?</span>
                <span class="k">for</span> <span class="n">label2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                        <span class="k">break</span> <span class="c1"># we&#39;ve seen this fname/fval combo</span>
                <span class="c1"># We haven&#39;t -- fire the unseen-value feature</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">fname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">:</span>
                        <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">[</span><span class="n">fname</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Add always-on features:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="ow">and</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">:</span>
            <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">encoding</span></div>

<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.describe"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.describe.html#nltk.BinaryMaxentFeatureEncoding.describe">[docs]</a>    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_id</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f_id</span><span class="p">,</span> <span class="n">compat</span><span class="o">.</span><span class="n">integer_types</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;describe() expected an int&#39;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">info</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span>

        <span class="k">if</span> <span class="n">f_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">):</span>
            <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span>
            <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">==</span><span class="si">%r</span><span class="s1"> and label is </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="ow">and</span> <span class="n">f_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">f_id2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">f_id</span> <span class="o">==</span> <span class="n">f_id2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s1">&#39;label is </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">label</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="ow">and</span> <span class="n">f_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">f_id2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">f_id</span> <span class="o">==</span> <span class="n">f_id2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is unseen&#39;</span> <span class="o">%</span> <span class="n">fname</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Bad feature id&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.labels"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.labels.html#nltk.BinaryMaxentFeatureEncoding.labels">[docs]</a>    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span></div>

<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.length"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.length.html#nltk.BinaryMaxentFeatureEncoding.length">[docs]</a>    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="BinaryMaxentFeatureEncoding.train"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.BinaryMaxentFeatureEncoding.train.html#nltk.BinaryMaxentFeatureEncoding.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">count_cutoff</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct and return new feature encoding, based on a given</span>
<span class="sd">        training corpus ``train_toks``.  See the class description</span>
<span class="sd">        ``BinaryMaxentFeatureEncoding`` for a description of the</span>
<span class="sd">        joint-features that will be included in this encoding.</span>

<span class="sd">        :type train_toks: list(tuple(dict, str))</span>
<span class="sd">        :param train_toks: Training data, represented as a list of</span>
<span class="sd">            pairs, the first member of which is a feature dictionary,</span>
<span class="sd">            and the second of which is a classification label.</span>

<span class="sd">        :type count_cutoff: int</span>
<span class="sd">        :param count_cutoff: A cutoff value that is used to discard</span>
<span class="sd">            rare joint-features.  If a joint-feature&#39;s value is 1</span>
<span class="sd">            fewer than ``count_cutoff`` times in the training corpus,</span>
<span class="sd">            then that joint-feature is not included in the generated</span>
<span class="sd">            encoding.</span>

<span class="sd">        :type labels: list</span>
<span class="sd">        :param labels: A list of labels that should be used by the</span>
<span class="sd">            classifier.  If not specified, then the set of labels</span>
<span class="sd">            attested in ``train_toks`` will be used.</span>

<span class="sd">        :param options: Extra parameters for the constructor, such as</span>
<span class="sd">            ``unseen_features`` and ``alwayson_features``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>              <span class="c1"># maps (fname, fval, label) -&gt; fid</span>
        <span class="n">seen_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>       <span class="c1"># The set of labels we&#39;ve encountered</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># maps (fname, fval) -&gt; count</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">and</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected label </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">seen_labels</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

            <span class="c1"># Record each of the features.</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tok</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

                <span class="c1"># If a count cutoff is given, then only add a joint</span>
                <span class="c1"># feature once the corresponding (fname, fval, label)</span>
                <span class="c1"># tuple exceeds that cutoff.</span>
                <span class="n">count</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">count</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">count_cutoff</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">:</span>
                        <span class="n">mapping</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">seen_labels</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span></div></div>

<span class="k">class</span> <span class="nc">GISEncoding</span><span class="p">(</span><span class="n">BinaryMaxentFeatureEncoding</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A binary feature encoding which adds one new joint-feature to the</span>
<span class="sd">    joint-features defined by ``BinaryMaxentFeatureEncoding``: a</span>
<span class="sd">    correction feature, whose value is chosen to ensure that the</span>
<span class="sd">    sparse vector always sums to a constant non-negative number.  This</span>
<span class="sd">    new feature is used to ensure two preconditions for the GIS</span>
<span class="sd">    training algorithm:</span>

<span class="sd">      - At least one feature vector index must be nonzero for every</span>
<span class="sd">        token.</span>
<span class="sd">      - The feature vector must sum to a constant non-negative number</span>
<span class="sd">        for every token.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="n">unseen_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">alwayson_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param C: The correction constant.  The value of the correction</span>
<span class="sd">            feature is based on this value.  In particular, its value is</span>
<span class="sd">            ``C - sum([v for (f,v) in encoding])``.</span>
<span class="sd">        :seealso: ``BinaryMaxentFeatureEncoding.__init__``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="n">unseen_features</span><span class="p">,</span> <span class="n">alwayson_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">fname</span> <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_C</span> <span class="o">=</span> <span class="n">C</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">C</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The non-negative constant that all encoded feature vectors</span>
<span class="sd">        will sum to.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_C</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="c1"># Get the basic encoding.</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">base_length</span> <span class="o">=</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Add a correction feature.</span>
        <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">v</span> <span class="k">for</span> <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">encoding</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_C</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Correction feature is not high enough!&#39;</span><span class="p">)</span>
        <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">base_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_C</span><span class="o">-</span><span class="n">total</span><span class="p">))</span>

        <span class="c1"># Return the result</span>
        <span class="k">return</span> <span class="n">encoding</span>

    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_id</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">f_id</span> <span class="o">==</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="s1">&#39;Correction feature (</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_C</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_id</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TadmEventMaxentFeatureEncoding</span><span class="p">(</span><span class="n">BinaryMaxentFeatureEncoding</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="n">unseen_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                       <span class="n">alwayson_features</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">,</span>
                                             <span class="n">unseen_features</span><span class="p">,</span>
                                             <span class="n">alwayson_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">featureset</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)],</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">_label_mapping</span><span class="p">[</span><span class="n">value</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">encoding</span>

    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span>

    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fid</span><span class="p">):</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span> <span class="o">==</span> <span class="n">fid</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">count_cutoff</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># This gets read twice, so compute the values in case it&#39;s lazy.</span>
        <span class="n">train_toks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_toks</span><span class="p">)</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">featureset</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">:</span>
                        <span class="n">mapping</span><span class="p">[(</span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>


<div class="viewcode-block" id="TypedMaxentFeatureEncoding"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.html#nltk.TypedMaxentFeatureEncoding">[docs]</a><span class="k">class</span> <span class="nc">TypedMaxentFeatureEncoding</span><span class="p">(</span><span class="n">MaxentFeatureEncodingI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature encoding that generates vectors containing integer,</span>
<span class="sd">    float and binary joint-features of the form:</span>

<span class="sd">    Binary (for string and boolean features):</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    Value (for integer and float features):</span>

<span class="sd">    |  joint_feat(fs, l) = { fval if     (fs[fname] == type(fval))</span>
<span class="sd">    |                      {         and (l == label)</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { not encoded otherwise</span>

<span class="sd">    Where ``fname`` is the name of an input-feature, ``fval`` is a value</span>
<span class="sd">    for that input-feature, and ``label`` is a label.</span>

<span class="sd">    Typically, these features are constructed based on a training</span>
<span class="sd">    corpus, using the ``train()`` method.</span>

<span class="sd">    For string and boolean features [type(fval) not in (int, float)]</span>
<span class="sd">    this method will create one feature for each combination of</span>
<span class="sd">    ``fname``, ``fval``, and ``label`` that occurs at least once in the</span>
<span class="sd">    training corpus.</span>

<span class="sd">    For integer and float features [type(fval) in (int, float)] this</span>
<span class="sd">    method will create one feature for each combination of ``fname``</span>
<span class="sd">    and ``label`` that occurs at least once in the training corpus.</span>

<span class="sd">    For binary features the ``unseen_features`` parameter can be used</span>
<span class="sd">    to add &quot;unseen-value features&quot;, which are used whenever an input</span>
<span class="sd">    feature has a value that was not encountered in the training</span>
<span class="sd">    corpus.  These features have the form:</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])</span>
<span class="sd">    |                      {      and l == label</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    Where ``is_unseen(fname, fval)`` is true if the encoding does not</span>
<span class="sd">    contain any joint features that are true when ``fs[fname]==fval``.</span>

<span class="sd">    The ``alwayson_features`` parameter can be used to add &quot;always-on</span>
<span class="sd">    features&quot;, which have the form:</span>

<span class="sd">    |  joint_feat(fs, l) = { 1 if (l == label)</span>
<span class="sd">    |                      {</span>
<span class="sd">    |                      { 0 otherwise</span>

<span class="sd">    These always-on features allow the maxent model to directly model</span>
<span class="sd">    the prior probabilities of each label.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="TypedMaxentFeatureEncoding.__init__"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.__init__.html#nltk.TypedMaxentFeatureEncoding.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="n">unseen_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">alwayson_features</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param labels: A list of the \&quot;known labels\&quot; for this encoding.</span>

<span class="sd">        :param mapping: A dictionary mapping from ``(fname,fval,label)``</span>
<span class="sd">            tuples to corresponding joint-feature indexes.  These</span>
<span class="sd">            indexes must be the set of integers from 0...len(mapping).</span>
<span class="sd">            If ``mapping[fname,fval,label]=id``, then</span>
<span class="sd">            ``self.encode({..., fname:fval, ...``, label)[id]} is 1;</span>
<span class="sd">            otherwise, it is 0.</span>

<span class="sd">        :param unseen_features: If true, then include unseen value</span>
<span class="sd">           features in the generated joint-feature vectors.</span>

<span class="sd">        :param alwayson_features: If true, then include always-on</span>
<span class="sd">           features in the generated joint-feature vectors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">mapping</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">))):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Mapping values must be exactly the &#39;</span>
                             <span class="s1">&#39;set of integers from 0...len(mapping)&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;A list of attested labels.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span> <span class="o">=</span> <span class="n">mapping</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from (fname,fval,label) -&gt; fid&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;The length of generated joint feature vectors.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from label -&gt; fid&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="sd">&quot;&quot;&quot;dict mapping from fname -&gt; fid&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">alwayson_features</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_length</span><span class="p">)</span>
                                  <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">unseen_features</span><span class="p">:</span>
            <span class="n">fnames</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">fname</span> <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">fname</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_length</span><span class="p">)</span>
                                <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fnames</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fnames</span><span class="p">)</span></div>

<div class="viewcode-block" id="TypedMaxentFeatureEncoding.encode"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.encode.html#nltk.TypedMaxentFeatureEncoding.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">featureset</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Convert input-features to joint-features:</span>
        <span class="k">for</span> <span class="n">fname</span><span class="p">,</span> <span class="n">fval</span> <span class="ow">in</span> <span class="n">featureset</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fval</span><span class="p">,</span> <span class="p">(</span><span class="n">compat</span><span class="o">.</span><span class="n">integer_types</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="c1"># Known feature name &amp; value:</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fval</span><span class="p">),</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                    <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fval</span><span class="p">),</span>
                                                   <span class="n">label</span><span class="p">],</span> <span class="n">fval</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Known feature name &amp; value:</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                    <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

                <span class="c1"># Otherwise, we might want to fire an &quot;unseen-value feature&quot;.</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">:</span>
                    <span class="c1"># Have we seen this fname/fval combination with any label?</span>
                    <span class="k">for</span> <span class="n">label2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span><span class="p">:</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">:</span>
                            <span class="k">break</span> <span class="c1"># we&#39;ve seen this fname/fval combo</span>
                    <span class="c1"># We haven&#39;t -- fire the unseen-value feature</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">fname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">:</span>
                            <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="p">[</span><span class="n">fname</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>


        <span class="c1"># Add always-on features:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="ow">and</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">:</span>
            <span class="n">encoding</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">encoding</span></div>

<div class="viewcode-block" id="TypedMaxentFeatureEncoding.describe"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.describe.html#nltk.TypedMaxentFeatureEncoding.describe">[docs]</a>    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_id</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f_id</span><span class="p">,</span> <span class="n">compat</span><span class="o">.</span><span class="n">integer_types</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;describe() expected an int&#39;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">info</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span>

        <span class="k">if</span> <span class="n">f_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mapping</span><span class="p">):</span>
            <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inv_mapping</span><span class="p">[</span><span class="n">f_id</span><span class="p">]</span>
            <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">==</span><span class="si">%r</span><span class="s1"> and label is </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span> <span class="ow">and</span> <span class="n">f_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">f_id2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alwayson</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">f_id</span> <span class="o">==</span> <span class="n">f_id2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s1">&#39;label is </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">label</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span> <span class="ow">and</span> <span class="n">f_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">f_id2</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unseen</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">f_id</span> <span class="o">==</span> <span class="n">f_id2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is unseen&#39;</span> <span class="o">%</span> <span class="n">fname</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Bad feature id&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TypedMaxentFeatureEncoding.labels"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.labels.html#nltk.TypedMaxentFeatureEncoding.labels">[docs]</a>    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span></div>

<div class="viewcode-block" id="TypedMaxentFeatureEncoding.length"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.length.html#nltk.TypedMaxentFeatureEncoding.length">[docs]</a>    <span class="k">def</span> <span class="nf">length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Inherit docs.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="TypedMaxentFeatureEncoding.train"><a class="viewcode-back" href="../../../generated/generated/nltk.classify.TypedMaxentFeatureEncoding.train.html#nltk.TypedMaxentFeatureEncoding.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">count_cutoff</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct and return new feature encoding, based on a given</span>
<span class="sd">        training corpus ``train_toks``.  See the class description</span>
<span class="sd">        ``TypedMaxentFeatureEncoding`` for a description of the</span>
<span class="sd">        joint-features that will be included in this encoding.</span>

<span class="sd">        Note: recognized feature values types are (int, float), over</span>
<span class="sd">        types are interpreted as regular binary features.</span>

<span class="sd">        :type train_toks: list(tuple(dict, str))</span>
<span class="sd">        :param train_toks: Training data, represented as a list of</span>
<span class="sd">            pairs, the first member of which is a feature dictionary,</span>
<span class="sd">            and the second of which is a classification label.</span>

<span class="sd">        :type count_cutoff: int</span>
<span class="sd">        :param count_cutoff: A cutoff value that is used to discard</span>
<span class="sd">            rare joint-features.  If a joint-feature&#39;s value is 1</span>
<span class="sd">            fewer than ``count_cutoff`` times in the training corpus,</span>
<span class="sd">            then that joint-feature is not included in the generated</span>
<span class="sd">            encoding.</span>

<span class="sd">        :type labels: list</span>
<span class="sd">        :param labels: A list of labels that should be used by the</span>
<span class="sd">            classifier.  If not specified, then the set of labels</span>
<span class="sd">            attested in ``train_toks`` will be used.</span>

<span class="sd">        :param options: Extra parameters for the constructor, such as</span>
<span class="sd">            ``unseen_features`` and ``alwayson_features``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>              <span class="c1"># maps (fname, fval, label) -&gt; fid</span>
        <span class="n">seen_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>       <span class="c1"># The set of labels we&#39;ve encountered</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># maps (fname, fval) -&gt; count</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">and</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected label </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">seen_labels</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

            <span class="c1"># Record each of the features.</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tok</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">fval</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                    <span class="n">fval</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">fval</span><span class="p">)</span>
                <span class="c1"># If a count cutoff is given, then only add a joint</span>
                <span class="c1"># feature once the corresponding (fname, fval, label)</span>
                <span class="c1"># tuple exceeds that cutoff.</span>
                <span class="n">count</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">count</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">count_cutoff</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">:</span>
                        <span class="n">mapping</span><span class="p">[</span><span class="n">fname</span><span class="p">,</span> <span class="n">fval</span><span class="p">,</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">seen_labels</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mapping</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span></div></div>




<span class="c1">######################################################################</span>
<span class="c1">#{ Classifier Trainer: Generalized Iterative Scaling</span>
<span class="c1">######################################################################</span>

<span class="k">def</span> <span class="nf">train_maxent_classifier_with_gis</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                     <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train a new ``ConditionalExponentialClassifier``, using the given</span>
<span class="sd">    training samples, using the Generalized Iterative Scaling</span>
<span class="sd">    algorithm.  This ``ConditionalExponentialClassifier`` will encode</span>
<span class="sd">    the model that maximizes entropy from all the models that are</span>
<span class="sd">    empirically consistent with ``train_toks``.</span>

<span class="sd">    :see: ``train_maxent_classifier()`` for parameter descriptions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cutoffs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;max_iter&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">cutoffchecker</span> <span class="o">=</span> <span class="n">CutoffChecker</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">)</span>

    <span class="c1"># Construct an encoding from the training data.</span>
    <span class="k">if</span> <span class="n">encoding</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">GISEncoding</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;The GIS algorithm requires an encoding that &#39;</span>
                        <span class="s1">&#39;defines C (e.g., GISEncoding).&#39;</span><span class="p">)</span>

    <span class="c1"># Cinv is the inverse of the sum of each joint feature vector.</span>
    <span class="c1"># This controls the learning rate: higher Cinv (or lower C) gives</span>
    <span class="c1"># faster learning.</span>
    <span class="n">Cinv</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">encoding</span><span class="o">.</span><span class="n">C</span>

    <span class="c1"># Count how many times each feature occurs in the training data.</span>
    <span class="n">empirical_fcount</span> <span class="o">=</span> <span class="n">calculate_empirical_fcount</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span>

    <span class="c1"># Check for any features that are not attested in train_toks.</span>
    <span class="n">unattested</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">empirical_fcount</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Build the classifier.  Start with weight=0 for each attested</span>
    <span class="c1"># feature, and weight=-infinity for each unattested feature.</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">empirical_fcount</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">unattested</span><span class="p">:</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">NINF</span>
    <span class="n">classifier</span> <span class="o">=</span> <span class="n">ConditionalExponentialClassifier</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Take the log of the empirical fcount.</span>
    <span class="n">log_empirical_fcount</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">empirical_fcount</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">empirical_fcount</span>

    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  ==&gt; Training (</span><span class="si">%d</span><span class="s1"> iterations)&#39;</span> <span class="o">%</span> <span class="n">cutoffs</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      Iteration    Log Likelihood    Accuracy&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      ---------------------------------------&#39;</span><span class="p">)</span>

    <span class="c1"># Train the classifier.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">ll</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">ll</span> <span class="ow">or</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
                <span class="n">acc</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">acc</span> <span class="ow">or</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
                <span class="n">iternum</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">iter</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;     </span><span class="si">%9d</span><span class="s1">    </span><span class="si">%14.5f</span><span class="s1">    </span><span class="si">%9.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iternum</span><span class="p">,</span> <span class="n">ll</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

            <span class="c1"># Use the model to estimate the number of times each</span>
            <span class="c1"># feature should occur in the training data.</span>
            <span class="n">estimated_fcount</span> <span class="o">=</span> <span class="n">calculate_estimated_fcount</span><span class="p">(</span>
                <span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span>

            <span class="c1"># Take the log of estimated fcount (avoid taking log(0).)</span>
            <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">unattested</span><span class="p">:</span>
                <span class="n">estimated_fcount</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">log_estimated_fcount</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">estimated_fcount</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">estimated_fcount</span>

            <span class="c1"># Update the classifier weights</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">weights</span><span class="p">()</span>
            <span class="n">weights</span> <span class="o">+=</span> <span class="p">(</span><span class="n">log_empirical_fcount</span> <span class="o">-</span> <span class="n">log_estimated_fcount</span><span class="p">)</span> <span class="o">*</span> <span class="n">Cinv</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

            <span class="c1"># Check the log-likelihood &amp; accuracy cutoffs.</span>
            <span class="k">if</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">):</span>
                <span class="k">break</span>

    <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      Training stopped: keyboard interrupt&#39;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span>

    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;         Final    </span><span class="si">%14.5f</span><span class="s1">    </span><span class="si">%9.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ll</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

<span class="c1"># Return the classifier.</span>
    <span class="k">return</span> <span class="n">classifier</span>

<span class="k">def</span> <span class="nf">calculate_empirical_fcount</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">):</span>
    <span class="n">fcount</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">(),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
            <span class="n">fcount</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">+=</span> <span class="n">val</span>

    <span class="k">return</span> <span class="n">fcount</span>

<span class="k">def</span> <span class="nf">calculate_estimated_fcount</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">):</span>
    <span class="n">fcount</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">(),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
        <span class="n">pdist</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">prob_classify</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">pdist</span><span class="o">.</span><span class="n">samples</span><span class="p">():</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">pdist</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">fid</span><span class="p">,</span> <span class="n">fval</span><span class="p">)</span> <span class="ow">in</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
                <span class="n">fcount</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">prob</span><span class="o">*</span><span class="n">fval</span>

    <span class="k">return</span> <span class="n">fcount</span>


<span class="c1">######################################################################</span>
<span class="c1">#{ Classifier Trainer: Improved Iterative Scaling</span>
<span class="c1">######################################################################</span>

<span class="k">def</span> <span class="nf">train_maxent_classifier_with_iis</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                     <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">cutoffs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train a new ``ConditionalExponentialClassifier``, using the given</span>
<span class="sd">    training samples, using the Improved Iterative Scaling algorithm.</span>
<span class="sd">    This ``ConditionalExponentialClassifier`` will encode the model</span>
<span class="sd">    that maximizes entropy from all the models that are empirically</span>
<span class="sd">    consistent with ``train_toks``.</span>

<span class="sd">    :see: ``train_maxent_classifier()`` for parameter descriptions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cutoffs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;max_iter&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">cutoffchecker</span> <span class="o">=</span> <span class="n">CutoffChecker</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">)</span>

    <span class="c1"># Construct an encoding from the training data.</span>
    <span class="k">if</span> <span class="n">encoding</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

    <span class="c1"># Count how many times each feature occurs in the training data.</span>
    <span class="n">empirical_ffreq</span> <span class="o">=</span> <span class="p">(</span><span class="n">calculate_empirical_fcount</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span> <span class="o">/</span>
                       <span class="nb">len</span><span class="p">(</span><span class="n">train_toks</span><span class="p">))</span>

    <span class="c1"># Find the nf map, and related variables nfarray and nfident.</span>
    <span class="c1"># nf is the sum of the features for a given labeled text.</span>
    <span class="c1"># nfmap compresses this sparse set of values to a dense list.</span>
    <span class="c1"># nfarray performs the reverse operation.  nfident is</span>
    <span class="c1"># nfarray multiplied by an identity matrix.</span>
    <span class="n">nfmap</span> <span class="o">=</span> <span class="n">calculate_nfmap</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span>
    <span class="n">nfarray</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">nfmap</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">nfmap</span><span class="o">.</span><span class="n">__getitem__</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="n">nftranspose</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nfarray</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nfarray</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Check for any features that are not attested in train_toks.</span>
    <span class="n">unattested</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">empirical_ffreq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Build the classifier.  Start with weight=0 for each attested</span>
    <span class="c1"># feature, and weight=-infinity for each unattested feature.</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">empirical_ffreq</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">unattested</span><span class="p">:</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">NINF</span>
    <span class="n">classifier</span> <span class="o">=</span> <span class="n">ConditionalExponentialClassifier</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;  ==&gt; Training (</span><span class="si">%d</span><span class="s1"> iterations)&#39;</span> <span class="o">%</span> <span class="n">cutoffs</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      Iteration    Log Likelihood    Accuracy&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      ---------------------------------------&#39;</span><span class="p">)</span>

    <span class="c1"># Train the classifier.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">ll</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">ll</span> <span class="ow">or</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
                <span class="n">acc</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">acc</span> <span class="ow">or</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
                <span class="n">iternum</span> <span class="o">=</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">iter</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;     </span><span class="si">%9d</span><span class="s1">    </span><span class="si">%14.5f</span><span class="s1">    </span><span class="si">%9.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iternum</span><span class="p">,</span> <span class="n">ll</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

            <span class="c1"># Calculate the deltas for this iteration, using Newton&#39;s method.</span>
            <span class="n">deltas</span> <span class="o">=</span> <span class="n">calculate_deltas</span><span class="p">(</span>
                <span class="n">train_toks</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">unattested</span><span class="p">,</span> <span class="n">empirical_ffreq</span><span class="p">,</span>
                <span class="n">nfmap</span><span class="p">,</span> <span class="n">nfarray</span><span class="p">,</span> <span class="n">nftranspose</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span>

            <span class="c1"># Use the deltas to update our weights.</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">weights</span><span class="p">()</span>
            <span class="n">weights</span> <span class="o">+=</span> <span class="n">deltas</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

            <span class="c1"># Check the log-likelihood &amp; accuracy cutoffs.</span>
            <span class="k">if</span> <span class="n">cutoffchecker</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">):</span>
                <span class="k">break</span>

    <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;      Training stopped: keyboard interrupt&#39;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span>


    <span class="k">if</span> <span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;         Final    </span><span class="si">%14.5f</span><span class="s1">    </span><span class="si">%9.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ll</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

    <span class="c1"># Return the classifier.</span>
    <span class="k">return</span> <span class="n">classifier</span>

<span class="k">def</span> <span class="nf">calculate_nfmap</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a map that can be used to compress ``nf`` (which is</span>
<span class="sd">    typically sparse).</span>

<span class="sd">    *nf(feature_vector)* is the sum of the feature values for</span>
<span class="sd">    *feature_vector*.</span>

<span class="sd">    This represents the number of features that are active for a</span>
<span class="sd">    given labeled text.  This method finds all values of *nf(t)*</span>
<span class="sd">    that are attested for at least one token in the given list of</span>
<span class="sd">    training tokens; and constructs a dictionary mapping these</span>
<span class="sd">    attested values to a continuous range *0...N*.  For example,</span>
<span class="sd">    if the only values of *nf()* that were attested were 3, 5, and</span>
<span class="sd">    7, then ``_nfmap`` might return the dictionary ``{3:0, 5:1, 7:2}``.</span>

<span class="sd">    :return: A map that can be used to compress ``nf`` to a dense</span>
<span class="sd">        vector.</span>
<span class="sd">    :rtype: dict(int -&gt; int)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Map from nf to indices.  This allows us to use smaller arrays.</span>
    <span class="n">nfset</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">encoding</span><span class="o">.</span><span class="n">labels</span><span class="p">():</span>
            <span class="n">nfset</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">val</span> <span class="k">for</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">((</span><span class="n">nf</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">nf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nfset</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">calculate_deltas</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">unattested</span><span class="p">,</span> <span class="n">ffreq_empirical</span><span class="p">,</span>
                     <span class="n">nfmap</span><span class="p">,</span> <span class="n">nfarray</span><span class="p">,</span> <span class="n">nftranspose</span><span class="p">,</span> <span class="n">encoding</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the update values for the classifier weights for</span>
<span class="sd">    this iteration of IIS.  These update weights are the value of</span>
<span class="sd">    ``delta`` that solves the equation::</span>

<span class="sd">      ffreq_empirical[i]</span>
<span class="sd">             =</span>
<span class="sd">      SUM[fs,l] (classifier.prob_classify(fs).prob(l) *</span>
<span class="sd">                 feature_vector(fs,l)[i] *</span>
<span class="sd">                 exp(delta[i] * nf(feature_vector(fs,l))))</span>

<span class="sd">    Where:</span>
<span class="sd">        - *(fs,l)* is a (featureset, label) tuple from ``train_toks``</span>
<span class="sd">        - *feature_vector(fs,l)* = ``encoding.encode(fs,l)``</span>
<span class="sd">        - *nf(vector)* = ``sum([val for (id,val) in vector])``</span>

<span class="sd">    This method uses Newton&#39;s method to solve this equation for</span>
<span class="sd">    *delta[i]*.  In particular, it starts with a guess of</span>
<span class="sd">    ``delta[i]`` = 1; and iteratively updates ``delta`` with:</span>

<span class="sd">    | delta[i] -= (ffreq_empirical[i] - sum1[i])/(-sum2[i])</span>

<span class="sd">    until convergence, where *sum1* and *sum2* are defined as:</span>

<span class="sd">    |    sum1[i](delta) = SUM[fs,l] f[i](fs,l,delta)</span>
<span class="sd">    |    sum2[i](delta) = SUM[fs,l] (f[i](fs,l,delta).nf(feature_vector(fs,l)))</span>
<span class="sd">    |    f[i](fs,l,delta) = (classifier.prob_classify(fs).prob(l) .</span>
<span class="sd">    |                        feature_vector(fs,l)[i] .</span>
<span class="sd">    |                        exp(delta[i] . nf(feature_vector(fs,l))))</span>

<span class="sd">    Note that *sum1* and *sum2* depend on ``delta``; so they need</span>
<span class="sd">    to be re-computed each iteration.</span>

<span class="sd">    The variables ``nfmap``, ``nfarray``, and ``nftranspose`` are</span>
<span class="sd">    used to generate a dense encoding for *nf(ltext)*.  This</span>
<span class="sd">    allows ``_deltas`` to calculate *sum1* and *sum2* using</span>
<span class="sd">    matrices, which yields a significant performance improvement.</span>

<span class="sd">    :param train_toks: The set of training tokens.</span>
<span class="sd">    :type train_toks: list(tuple(dict, str))</span>
<span class="sd">    :param classifier: The current classifier.</span>
<span class="sd">    :type classifier: ClassifierI</span>
<span class="sd">    :param ffreq_empirical: An array containing the empirical</span>
<span class="sd">        frequency for each feature.  The *i*\ th element of this</span>
<span class="sd">        array is the empirical frequency for feature *i*.</span>
<span class="sd">    :type ffreq_empirical: sequence of float</span>
<span class="sd">    :param unattested: An array that is 1 for features that are</span>
<span class="sd">        not attested in the training data; and 0 for features that</span>
<span class="sd">        are attested.  In other words, ``unattested[i]==0`` iff</span>
<span class="sd">        ``ffreq_empirical[i]==0``.</span>
<span class="sd">    :type unattested: sequence of int</span>
<span class="sd">    :param nfmap: A map that can be used to compress ``nf`` to a dense</span>
<span class="sd">        vector.</span>
<span class="sd">    :type nfmap: dict(int -&gt; int)</span>
<span class="sd">    :param nfarray: An array that can be used to uncompress ``nf``</span>
<span class="sd">        from a dense vector.</span>
<span class="sd">    :type nfarray: array(float)</span>
<span class="sd">    :param nftranspose: The transpose of ``nfarray``</span>
<span class="sd">    :type nftranspose: array(float)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># These parameters control when we decide that we&#39;ve</span>
    <span class="c1"># converged.  It probably should be possible to set these</span>
    <span class="c1"># manually, via keyword arguments to train.</span>
    <span class="n">NEWTON_CONVERGE</span> <span class="o">=</span> <span class="mf">1e-12</span>
    <span class="n">MAX_NEWTON</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="n">deltas</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">(),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

    <span class="c1"># Precompute the A matrix:</span>
    <span class="c1"># A[nf][id] = sum ( p(fs) * p(label|fs) * f(fs,label) )</span>
    <span class="c1"># over all label,fs s.t. num_features[label,fs]=nf</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">nfmap</span><span class="p">),</span> <span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">()),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">tok</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_toks</span><span class="p">:</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">prob_classify</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">encoding</span><span class="o">.</span><span class="n">labels</span><span class="p">():</span>
            <span class="c1"># Generate the feature vector</span>
            <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="c1"># Find the number of active features</span>
            <span class="n">nf</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">val</span> <span class="k">for</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">feature_vector</span><span class="p">)</span>
            <span class="c1"># Update the A matrix</span>
            <span class="k">for</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">feature_vector</span><span class="p">:</span>
                <span class="n">A</span><span class="p">[</span><span class="n">nfmap</span><span class="p">[</span><span class="n">nf</span><span class="p">],</span> <span class="nb">id</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dist</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">*</span> <span class="n">val</span>
    <span class="n">A</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_toks</span><span class="p">)</span>

    <span class="c1"># Iteratively solve for delta.  Use the following variables:</span>
    <span class="c1">#   - nf_delta[x][y] = nfarray[x] * delta[y]</span>
    <span class="c1">#   - exp_nf_delta[x][y] = exp(nf[x] * delta[y])</span>
    <span class="c1">#   - nf_exp_nf_delta[x][y] = nf[x] * exp(nf[x] * delta[y])</span>
    <span class="c1">#   - sum1[i][nf] = sum p(fs)p(label|fs)f[i](label,fs)</span>
    <span class="c1">#                       exp(delta[i]nf)</span>
    <span class="c1">#   - sum2[i][nf] = sum p(fs)p(label|fs)f[i](label,fs)</span>
    <span class="c1">#                       nf exp(delta[i]nf)</span>
    <span class="k">for</span> <span class="n">rangenum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_NEWTON</span><span class="p">):</span>
        <span class="n">nf_delta</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">nfarray</span><span class="p">,</span> <span class="n">deltas</span><span class="p">)</span>
        <span class="n">exp_nf_delta</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">nf_delta</span>
        <span class="n">nf_exp_nf_delta</span> <span class="o">=</span> <span class="n">nftranspose</span> <span class="o">*</span> <span class="n">exp_nf_delta</span>
        <span class="n">sum1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_nf_delta</span> <span class="o">*</span> <span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">sum2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nf_exp_nf_delta</span> <span class="o">*</span> <span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Avoid division by zero.</span>
        <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">unattested</span><span class="p">:</span>
            <span class="n">sum2</span><span class="p">[</span><span class="n">fid</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Update the deltas.</span>
        <span class="n">deltas</span> <span class="o">-=</span> <span class="p">(</span><span class="n">ffreq_empirical</span> <span class="o">-</span> <span class="n">sum1</span><span class="p">)</span> <span class="o">/</span> <span class="o">-</span><span class="n">sum2</span>

        <span class="c1"># We can stop once we converge.</span>
        <span class="n">n_error</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">((</span><span class="n">ffreq_empirical</span><span class="o">-</span><span class="n">sum1</span><span class="p">)))</span><span class="o">/</span>
                   <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">deltas</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">n_error</span> <span class="o">&lt;</span> <span class="n">NEWTON_CONVERGE</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">deltas</span>

    <span class="k">return</span> <span class="n">deltas</span>

<span class="c1">######################################################################</span>
<span class="c1">#{ Classifier Trainer: megam</span>
<span class="c1">######################################################################</span>

<span class="c1"># [xx] possible extension: add support for using implicit file format;</span>
<span class="c1"># this would need to put requirements on what encoding is used.  But</span>
<span class="c1"># we may need this for other maxent classifier trainers that require</span>
<span class="c1"># implicit formats anyway.</span>
<span class="k">def</span> <span class="nf">train_maxent_classifier_with_megam</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                       <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">gaussian_prior_sigma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                       <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train a new ``ConditionalExponentialClassifier``, using the given</span>
<span class="sd">    training samples, using the external ``megam`` library.  This</span>
<span class="sd">    ``ConditionalExponentialClassifier`` will encode the model that</span>
<span class="sd">    maximizes entropy from all the models that are empirically</span>
<span class="sd">    consistent with ``train_toks``.</span>

<span class="sd">    :see: ``train_maxent_classifier()`` for parameter descriptions.</span>
<span class="sd">    :see: ``nltk.classify.megam``</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">explicit</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">bernoulli</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="s1">&#39;explicit&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">explicit</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;explicit&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s1">&#39;bernoulli&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">bernoulli</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;bernoulli&#39;</span><span class="p">]</span>

    <span class="c1"># Construct an encoding from the training data.</span>
    <span class="k">if</span> <span class="n">encoding</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Count cutoff can also be controlled by megam with the -minfc</span>
        <span class="c1"># option. Not sure where the best place for it is.</span>
        <span class="n">count_cutoff</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;count_cutoff&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">BinaryMaxentFeatureEncoding</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">count_cutoff</span><span class="p">,</span>
                                                     <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                                                     <span class="n">alwayson_features</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Specify encoding or labels, not both&#39;</span><span class="p">)</span>

    <span class="c1"># Write a training file for megam.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fd</span><span class="p">,</span> <span class="n">trainfile_name</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkstemp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;nltk-&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">trainfile_name</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">trainfile</span><span class="p">:</span>
            <span class="n">write_megam_file</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">trainfile</span><span class="p">,</span>
                             <span class="n">explicit</span><span class="o">=</span><span class="n">explicit</span><span class="p">,</span> <span class="n">bernoulli</span><span class="o">=</span><span class="n">bernoulli</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fd</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">OSError</span><span class="p">,</span> <span class="ne">IOError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Error while creating megam training file: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">e</span><span class="p">)</span>

    <span class="c1"># Run megam on the training file.</span>
    <span class="n">options</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-nobias&#39;</span><span class="p">,</span> <span class="s1">&#39;-repeat&#39;</span><span class="p">,</span> <span class="s1">&#39;10&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">explicit</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-explicit&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">bernoulli</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-fvals&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">gaussian_prior_sigma</span><span class="p">:</span>
        <span class="c1"># Lambda is just the precision of the Gaussian prior, i.e. it&#39;s the</span>
        <span class="c1"># inverse variance, so the parameter conversion is 1.0/sigma**2.</span>
        <span class="c1"># See http://www.umiacs.umd.edu/~hal/docs/daume04cg-bfgs.pdf.</span>
        <span class="n">inv_variance</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">gaussian_prior_sigma</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">inv_variance</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">inv_variance</span><span class="p">,</span> <span class="s1">&#39;-tune&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">trace</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-quiet&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s1">&#39;max_iter&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-maxi&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">]]</span>
    <span class="k">if</span> <span class="s1">&#39;ll_delta&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="c1"># [xx] this is actually a perplexity delta, not a log</span>
        <span class="c1"># likelihood delta</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-dpp&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">abs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;ll_delta&#39;</span><span class="p">])]</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="s1">&#39;cost&#39;</span><span class="p">):</span>
        <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;-multilabel&#39;</span><span class="p">]</span>  <span class="c1"># each possible la</span>
    <span class="n">options</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;multiclass&#39;</span><span class="p">,</span> <span class="n">trainfile_name</span><span class="p">]</span>
    <span class="n">stdout</span> <span class="o">=</span> <span class="n">call_megam</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
    <span class="c1"># print &#39;./megam_i686.opt &#39;, &#39; &#39;.join(options)</span>
    <span class="c1"># Delete the training file</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">trainfile_name</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">OSError</span><span class="p">,</span> <span class="ne">IOError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Warning: unable to delete </span><span class="si">%s</span><span class="s1">: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">trainfile_name</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

    <span class="c1"># Parse the generated weight vector.</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">parse_megam_weights</span><span class="p">(</span><span class="n">stdout</span><span class="p">,</span> <span class="n">encoding</span><span class="o">.</span><span class="n">length</span><span class="p">(),</span> <span class="n">explicit</span><span class="p">)</span>

    <span class="c1"># Convert from base-e to base-2 weights.</span>
    <span class="n">weights</span> <span class="o">*=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>

    <span class="c1"># Build the classifier</span>
    <span class="k">return</span> <span class="n">MaxentClassifier</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<span class="c1">######################################################################</span>
<span class="c1">#{ Classifier Trainer: tadm</span>
<span class="c1">######################################################################</span>

<span class="k">class</span> <span class="nc">TadmMaxentClassifier</span><span class="p">(</span><span class="n">MaxentClassifier</span><span class="p">):</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">train_toks</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">algorithm</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;algorithm&#39;</span><span class="p">,</span> <span class="s1">&#39;tao_lmvm&#39;</span><span class="p">)</span>
        <span class="n">trace</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;encoding&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;gaussian_prior_sigma&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">count_cutoff</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;count_cutoff&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_iter&#39;</span><span class="p">)</span>
        <span class="n">ll_delta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;min_lldelta&#39;</span><span class="p">)</span>

        <span class="c1"># Construct an encoding from the training data.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">encoding</span><span class="p">:</span>
            <span class="n">encoding</span> <span class="o">=</span> <span class="n">TadmEventMaxentFeatureEncoding</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span>
                                                            <span class="n">count_cutoff</span><span class="p">,</span>
                                                            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">trainfile_fd</span><span class="p">,</span> <span class="n">trainfile_name</span> <span class="o">=</span> \
            <span class="n">tempfile</span><span class="o">.</span><span class="n">mkstemp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;nltk-tadm-events-&#39;</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">&#39;.gz&#39;</span><span class="p">)</span>
        <span class="n">weightfile_fd</span><span class="p">,</span> <span class="n">weightfile_name</span> <span class="o">=</span> \
            <span class="n">tempfile</span><span class="o">.</span><span class="n">mkstemp</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;nltk-tadm-weights-&#39;</span><span class="p">)</span>

        <span class="n">trainfile</span> <span class="o">=</span> <span class="n">gzip_open_unicode</span><span class="p">(</span><span class="n">trainfile_name</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">write_tadm_file</span><span class="p">(</span><span class="n">train_toks</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">trainfile</span><span class="p">)</span>
        <span class="n">trainfile</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="n">options</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-monitor&#39;</span><span class="p">])</span>
        <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-method&#39;</span><span class="p">,</span> <span class="n">algorithm</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">sigma</span><span class="p">:</span>
            <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-l2&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.6f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">max_iter</span><span class="p">:</span>
            <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-max_it&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">max_iter</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">ll_delta</span><span class="p">:</span>
            <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-fatol&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.6f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">abs</span><span class="p">(</span><span class="n">ll_delta</span><span class="p">)])</span>
        <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-events_in&#39;</span><span class="p">,</span> <span class="n">trainfile_name</span><span class="p">])</span>
        <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-params_out&#39;</span><span class="p">,</span> <span class="n">weightfile_name</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">trace</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;2&gt;&amp;1&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">options</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-summary&#39;</span><span class="p">])</span>

        <span class="n">call_tadm</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">weightfile_name</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">weightfile</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">parse_tadm_weights</span><span class="p">(</span><span class="n">weightfile</span><span class="p">)</span>

        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">trainfile_name</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">weightfile_name</span><span class="p">)</span>

        <span class="c1"># Convert from base-e to base-2 weights.</span>
        <span class="n">weights</span> <span class="o">*=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>

        <span class="c1"># Build the classifier</span>
        <span class="k">return</span> <span class="n">cls</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<span class="c1">######################################################################</span>
<span class="c1">#{ Demo</span>
<span class="c1">######################################################################</span>
<span class="k">def</span> <span class="nf">demo</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">nltk.classify.util</span> <span class="kn">import</span> <span class="n">names_demo</span>
    <span class="n">classifier</span> <span class="o">=</span> <span class="n">names_demo</span><span class="p">(</span><span class="n">MaxentClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">demo</span><span class="p">()</span>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>