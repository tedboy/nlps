

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nltk.tokenize.texttiling</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="nltk.tokenize" href="../tokenize.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../nltk.html">nltk</a> &raquo;</li>
        
          <li><a href="../tokenize.html">nltk.tokenize</a> &raquo;</li>
        
      <li>nltk.tokenize.texttiling</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nltk.tokenize.texttiling</h1><div class="highlight"><pre>
<span></span><span class="c1"># Natural Language Toolkit: TextTiling</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2015 NLTK Project</span>
<span class="c1"># Author: George Boutsioukis</span>
<span class="c1">#</span>
<span class="c1"># URL: &lt;http://nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">numpy</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize.api</span> <span class="kn">import</span> <span class="n">TokenizerI</span>

<span class="n">BLOCK_COMPARISON</span><span class="p">,</span> <span class="n">VOCABULARY_INTRODUCTION</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">LC</span><span class="p">,</span> <span class="n">HC</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">DEFAULT_SMOOTHING</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<div class="viewcode-block" id="TextTilingTokenizer"><a class="viewcode-back" href="../../../generated/generated/nltk.TextTilingTokenizer.html#nltk.TextTilingTokenizer">[docs]</a><span class="k">class</span> <span class="nc">TextTilingTokenizer</span><span class="p">(</span><span class="n">TokenizerI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenize a document into topical sections using the TextTiling algorithm.</span>
<span class="sd">    This algorithm detects subtopic shifts based on the analysis of lexical</span>
<span class="sd">    co-occurrence patterns.</span>

<span class="sd">    The process starts by tokenizing the text into pseudosentences of</span>
<span class="sd">    a fixed size w. Then, depending on the method used, similarity</span>
<span class="sd">    scores are assigned at sentence gaps. The algorithm proceeds by</span>
<span class="sd">    detecting the peak differences between these scores and marking</span>
<span class="sd">    them as boundaries. The boundaries are normalized to the closest</span>
<span class="sd">    paragraph break and the segmented text is returned.</span>

<span class="sd">    :param w: Pseudosentence size</span>
<span class="sd">    :type w: int</span>
<span class="sd">    :param k: Size (in sentences) of the block used in the block comparison method</span>
<span class="sd">    :type k: int</span>
<span class="sd">    :param similarity_method: The method used for determining similarity scores:</span>
<span class="sd">       `BLOCK_COMPARISON` (default) or `VOCABULARY_INTRODUCTION`.</span>
<span class="sd">    :type similarity_method: constant</span>
<span class="sd">    :param stopwords: A list of stopwords that are filtered out (defaults to NLTK&#39;s stopwords corpus)</span>
<span class="sd">    :type stopwords: list(str)</span>
<span class="sd">    :param smoothing_method: The method used for smoothing the score plot:</span>
<span class="sd">      `DEFAULT_SMOOTHING` (default)</span>
<span class="sd">    :type smoothing_method: constant</span>
<span class="sd">    :param smoothing_width: The width of the window used by the smoothing method</span>
<span class="sd">    :type smoothing_width: int</span>
<span class="sd">    :param smoothing_rounds: The number of smoothing passes</span>
<span class="sd">    :type smoothing_rounds: int</span>
<span class="sd">    :param cutoff_policy: The policy used to determine the number of boundaries:</span>
<span class="sd">      `HC` (default) or `LC`</span>
<span class="sd">    :type cutoff_policy: constant</span>

<span class="sd">    &gt;&gt;&gt; from nltk.corpus import brown</span>
<span class="sd">    &gt;&gt;&gt; tt = TextTilingTokenizer(demo_mode=True)</span>
<span class="sd">    &gt;&gt;&gt; text = brown.raw()[:10000]</span>
<span class="sd">    &gt;&gt;&gt; s, ss, d, b = tt.tokenize(text)</span>
<span class="sd">    &gt;&gt;&gt; b</span>
<span class="sd">    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,</span>
<span class="sd">     0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,</span>
<span class="sd">     0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TextTilingTokenizer.__init__"><a class="viewcode-back" href="../../../generated/generated/nltk.TextTilingTokenizer.__init__.html#nltk.TextTilingTokenizer.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">w</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                 <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">similarity_method</span><span class="o">=</span><span class="n">BLOCK_COMPARISON</span><span class="p">,</span>
                 <span class="n">stopwords</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">smoothing_method</span><span class="o">=</span><span class="n">DEFAULT_SMOOTHING</span><span class="p">,</span>
                 <span class="n">smoothing_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">smoothing_rounds</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">cutoff_policy</span><span class="o">=</span><span class="n">HC</span><span class="p">,</span>
                 <span class="n">demo_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>


        <span class="k">if</span> <span class="n">stopwords</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
            <span class="n">stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="p">[</span><span class="s1">&#39;self&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="TextTilingTokenizer.tokenize"><a class="viewcode-back" href="../../../generated/generated/nltk.TextTilingTokenizer.tokenize.html#nltk.TextTilingTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a tokenized copy of *text*, where each &quot;token&quot; represents</span>
<span class="sd">        a separate topic.&quot;&quot;&quot;</span>

        <span class="n">lowercase_text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">paragraph_breaks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mark_paragraph_breaks</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">text_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lowercase_text</span><span class="p">)</span>

        <span class="c1"># Tokenization step starts here</span>

        <span class="c1"># Remove punctuation</span>
        <span class="n">nopunct_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">lowercase_text</span>
                               <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s2">&quot;[a-z\-</span><span class="se">\&#39;</span><span class="s2"> </span><span class="se">\n\t</span><span class="s2">]&quot;</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">nopunct_par_breaks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mark_paragraph_breaks</span><span class="p">(</span><span class="n">nopunct_text</span><span class="p">)</span>

        <span class="n">tokseqs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_divide_to_tokensequences</span><span class="p">(</span><span class="n">nopunct_text</span><span class="p">)</span>

        <span class="c1"># The morphological stemming step mentioned in the TextTile</span>
        <span class="c1"># paper is not implemented.  A comment in the original C</span>
        <span class="c1"># implementation states that it offers no benefit to the</span>
        <span class="c1"># process. It might be interesting to test the existing</span>
        <span class="c1"># stemmers though.</span>
        <span class="c1">#words = _stem_words(words)</span>

        <span class="c1"># Filter stopwords</span>
        <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokseqs</span><span class="p">:</span>
            <span class="n">ts</span><span class="o">.</span><span class="n">wrdindex_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">wi</span> <span class="k">for</span> <span class="n">wi</span> <span class="ow">in</span> <span class="n">ts</span><span class="o">.</span><span class="n">wrdindex_list</span>
                                <span class="k">if</span> <span class="n">wi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopwords</span><span class="p">]</span>

        <span class="n">token_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_token_table</span><span class="p">(</span><span class="n">tokseqs</span><span class="p">,</span> <span class="n">nopunct_par_breaks</span><span class="p">)</span>
        <span class="c1"># End of the Tokenization step</span>

        <span class="c1"># Lexical score determination</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_method</span> <span class="o">==</span> <span class="n">BLOCK_COMPARISON</span><span class="p">:</span>
            <span class="n">gap_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_comparison</span><span class="p">(</span><span class="n">tokseqs</span><span class="p">,</span> <span class="n">token_table</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_method</span> <span class="o">==</span> <span class="n">VOCABULARY_INTRODUCTION</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Vocabulary introduction not implemented&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoothing_method</span> <span class="o">==</span> <span class="n">DEFAULT_SMOOTHING</span><span class="p">:</span>
            <span class="n">smooth_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_smooth_scores</span><span class="p">(</span><span class="n">gap_scores</span><span class="p">)</span>
        <span class="c1"># End of Lexical score Determination</span>

        <span class="c1"># Boundary identification</span>
        <span class="n">depth_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_depth_scores</span><span class="p">(</span><span class="n">smooth_scores</span><span class="p">)</span>
        <span class="n">segment_boundaries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_identify_boundaries</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">)</span>

        <span class="n">normalized_boundaries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_boundaries</span><span class="p">(</span><span class="n">text</span><span class="p">,</span>
                                                           <span class="n">segment_boundaries</span><span class="p">,</span>
                                                           <span class="n">paragraph_breaks</span><span class="p">)</span>
        <span class="c1"># End of Boundary Identification</span>
        <span class="n">segmented_text</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">prevb</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">normalized_boundaries</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">segmented_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">prevb</span><span class="p">:</span><span class="n">b</span><span class="p">])</span>
            <span class="n">prevb</span> <span class="o">=</span> <span class="n">b</span>

        <span class="k">if</span> <span class="n">prevb</span> <span class="o">&lt;</span> <span class="n">text_length</span><span class="p">:</span> <span class="c1"># append any text that may be remaining</span>
            <span class="n">segmented_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">prevb</span><span class="p">:])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">segmented_text</span><span class="p">:</span>
            <span class="n">segmented_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">demo_mode</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">gap_scores</span><span class="p">,</span> <span class="n">smooth_scores</span><span class="p">,</span> <span class="n">depth_scores</span><span class="p">,</span> <span class="n">segment_boundaries</span>
        <span class="k">return</span> <span class="n">segmented_text</span></div>

    <span class="k">def</span> <span class="nf">_block_comparison</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokseqs</span><span class="p">,</span> <span class="n">token_table</span><span class="p">):</span>
        <span class="s2">&quot;Implements the block comparison method&quot;</span>
        <span class="k">def</span> <span class="nf">blk_frq</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">block</span><span class="p">):</span>
            <span class="n">ts_occs</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">o</span><span class="p">:</span> <span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">block</span><span class="p">,</span>
                             <span class="n">token_table</span><span class="p">[</span><span class="n">tok</span><span class="p">]</span><span class="o">.</span><span class="n">ts_occurences</span><span class="p">)</span>
            <span class="n">freq</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">tsocc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">tsocc</span> <span class="ow">in</span> <span class="n">ts_occs</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">freq</span>

        <span class="n">gap_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">numgaps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokseqs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>

        <span class="k">for</span> <span class="n">curr_gap</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numgaps</span><span class="p">):</span>
            <span class="n">score_dividend</span><span class="p">,</span> <span class="n">score_divisor_b1</span><span class="p">,</span> <span class="n">score_divisor_b2</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="c1">#adjust window size for boundary conditions</span>
            <span class="k">if</span> <span class="n">curr_gap</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">window_size</span> <span class="o">=</span> <span class="n">curr_gap</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">curr_gap</span> <span class="o">&gt;</span> <span class="n">numgaps</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">:</span>
                <span class="n">window_size</span> <span class="o">=</span> <span class="n">numgaps</span> <span class="o">-</span> <span class="n">curr_gap</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>

            <span class="n">b1</span> <span class="o">=</span> <span class="p">[</span><span class="n">ts</span><span class="o">.</span><span class="n">index</span>
                  <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokseqs</span><span class="p">[</span><span class="n">curr_gap</span><span class="o">-</span><span class="n">window_size</span><span class="o">+</span><span class="mi">1</span> <span class="p">:</span> <span class="n">curr_gap</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="p">[</span><span class="n">ts</span><span class="o">.</span><span class="n">index</span>
                  <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokseqs</span><span class="p">[</span><span class="n">curr_gap</span><span class="o">+</span><span class="mi">1</span> <span class="p">:</span> <span class="n">curr_gap</span><span class="o">+</span><span class="n">window_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>

            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">token_table</span><span class="p">:</span>
                <span class="n">score_dividend</span> <span class="o">+=</span> <span class="n">blk_frq</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span><span class="o">*</span><span class="n">blk_frq</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
                <span class="n">score_divisor_b1</span> <span class="o">+=</span> <span class="n">blk_frq</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                <span class="n">score_divisor_b2</span> <span class="o">+=</span> <span class="n">blk_frq</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">score_dividend</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">score_divisor_b1</span><span class="o">*</span>
                                                 <span class="n">score_divisor_b2</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
                <span class="k">pass</span> <span class="c1"># score += 0.0</span>

            <span class="n">gap_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">gap_scores</span>

    <span class="k">def</span> <span class="nf">_smooth_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gap_scores</span><span class="p">):</span>
        <span class="s2">&quot;Wraps the smooth function from the SciPy Cookbook&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">smooth</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">gap_scores</span><span class="p">[:]),</span>
                           <span class="n">window_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoothing_width</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_mark_paragraph_breaks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Identifies indented text or line breaks as the beginning of</span>
<span class="sd">        paragraphs&quot;&quot;&quot;</span>

        <span class="n">MIN_PARAGRAPH</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;[ </span><span class="se">\t\r\f\v</span><span class="s2">]*</span><span class="se">\n</span><span class="s2">[ </span><span class="se">\t\r\f\v</span><span class="s2">]*</span><span class="se">\n</span><span class="s2">[ </span><span class="se">\t\r\f\v</span><span class="s2">]*&quot;</span><span class="p">)</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">pattern</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="n">last_break</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pbreaks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">pb</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pb</span><span class="o">.</span><span class="n">start</span><span class="p">()</span><span class="o">-</span><span class="n">last_break</span> <span class="o">&lt;</span> <span class="n">MIN_PARAGRAPH</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pbreaks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pb</span><span class="o">.</span><span class="n">start</span><span class="p">())</span>
                <span class="n">last_break</span> <span class="o">=</span> <span class="n">pb</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">pbreaks</span>

    <span class="k">def</span> <span class="nf">_divide_to_tokensequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="s2">&quot;Divides the text into pseudosentences of fixed size&quot;</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span>
        <span class="n">wrdindex_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="s2">&quot;\w+&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="n">wrdindex_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(),</span> <span class="n">match</span><span class="o">.</span><span class="n">start</span><span class="p">()))</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">TokenSequence</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="n">w</span><span class="p">,</span> <span class="n">wrdindex_list</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">w</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrdindex_list</span><span class="p">),</span> <span class="n">w</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">_create_token_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_sequences</span><span class="p">,</span> <span class="n">par_breaks</span><span class="p">):</span>
        <span class="s2">&quot;Creates a table of TokenTableFields&quot;</span>
        <span class="n">token_table</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">current_par</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">current_tok_seq</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pb_iter</span> <span class="o">=</span> <span class="n">par_breaks</span><span class="o">.</span><span class="n">__iter__</span><span class="p">()</span>
        <span class="n">current_par_break</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pb_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current_par_break</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">current_par_break</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pb_iter</span><span class="p">)</span> <span class="c1">#skip break at 0</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;No paragraph breaks were found(text too short perhaps?)&quot;</span>
                    <span class="p">)</span>
        <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">token_sequences</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">ts</span><span class="o">.</span><span class="n">wrdindex_list</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">while</span> <span class="n">index</span> <span class="o">&gt;</span> <span class="n">current_par_break</span><span class="p">:</span>
                        <span class="n">current_par_break</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">pb_iter</span><span class="p">)</span>
                        <span class="n">current_par</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                    <span class="c1">#hit bottom</span>
                    <span class="k">pass</span>

                <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">token_table</span><span class="p">:</span>
                    <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">total_count</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="k">if</span> <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">last_par</span> <span class="o">!=</span> <span class="n">current_par</span><span class="p">:</span>
                        <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">last_par</span> <span class="o">=</span> <span class="n">current_par</span>
                        <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">par_count</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="k">if</span> <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">last_tok_seq</span> <span class="o">!=</span> <span class="n">current_tok_seq</span><span class="p">:</span>
                        <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">last_tok_seq</span> <span class="o">=</span> <span class="n">current_tok_seq</span>
                        <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>\
                                <span class="o">.</span><span class="n">ts_occurences</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">current_tok_seq</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">ts_occurences</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1">#new word</span>
                    <span class="n">token_table</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">TokenTableField</span><span class="p">(</span><span class="n">first_pos</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                                                        <span class="n">ts_occurences</span><span class="o">=</span> \
                                                          <span class="p">[[</span><span class="n">current_tok_seq</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                                                        <span class="n">total_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                        <span class="n">par_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                        <span class="n">last_par</span><span class="o">=</span><span class="n">current_par</span><span class="p">,</span>
                                                        <span class="n">last_tok_seq</span><span class="o">=</span> \
                                                          <span class="n">current_tok_seq</span><span class="p">)</span>

            <span class="n">current_tok_seq</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">token_table</span>

    <span class="k">def</span> <span class="nf">_identify_boundaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depth_scores</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Identifies boundaries at the peaks of similarity score</span>
<span class="sd">        differences&quot;&quot;&quot;</span>

        <span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">depth_scores</span><span class="p">]</span>

        <span class="n">avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">)</span>
        <span class="n">stdev</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">)</span>

        <span class="c1">#SB: what is the purpose of this conditional?</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff_policy</span> <span class="o">==</span> <span class="n">LC</span><span class="p">:</span>
            <span class="n">cutoff</span> <span class="o">=</span> <span class="n">avg</span><span class="o">-</span><span class="n">stdev</span><span class="o">/</span><span class="mf">2.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cutoff</span> <span class="o">=</span> <span class="n">avg</span><span class="o">-</span><span class="n">stdev</span><span class="o">/</span><span class="mf">2.0</span>

        <span class="n">depth_tuples</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">depth_scores</span><span class="p">))))</span>
        <span class="n">depth_tuples</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">hp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">cutoff</span><span class="p">,</span> <span class="n">depth_tuples</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">hp</span><span class="p">:</span>
            <span class="n">boundaries</span><span class="p">[</span><span class="n">dt</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">dt2</span> <span class="ow">in</span> <span class="n">hp</span><span class="p">:</span> <span class="c1">#undo if there is a boundary close already</span>
                <span class="k">if</span> <span class="n">dt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">dt2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dt2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">dt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mi">4</span> \
                       <span class="ow">and</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">dt2</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">boundaries</span><span class="p">[</span><span class="n">dt</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">boundaries</span>

    <span class="k">def</span> <span class="nf">_depth_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculates the depth of each gap, i.e. the average difference</span>
<span class="sd">        between the left and right peaks and the gap&#39;s score&quot;&quot;&quot;</span>

        <span class="n">depth_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]</span>
        <span class="c1">#clip boundaries: this holds on the rule of thumb(my thumb)</span>
        <span class="c1">#that a section shouldn&#39;t be smaller than at least 2</span>
        <span class="c1">#pseudosentences for small texts and around 5 for larger ones.</span>

        <span class="n">clip</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">clip</span>

        <span class="k">for</span> <span class="n">gapscore</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="n">clip</span><span class="p">:</span><span class="o">-</span><span class="n">clip</span><span class="p">]:</span>
            <span class="n">lpeak</span> <span class="o">=</span> <span class="n">gapscore</span>
            <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="n">index</span><span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;=</span> <span class="n">lpeak</span><span class="p">:</span>
                    <span class="n">lpeak</span> <span class="o">=</span> <span class="n">score</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">rpeak</span> <span class="o">=</span> <span class="n">gapscore</span>
            <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="n">index</span><span class="p">:]:</span>
                <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;=</span> <span class="n">rpeak</span><span class="p">:</span>
                    <span class="n">rpeak</span> <span class="o">=</span> <span class="n">score</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">depth_scores</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">lpeak</span> <span class="o">+</span> <span class="n">rpeak</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">gapscore</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">depth_scores</span>

    <span class="k">def</span> <span class="nf">_normalize_boundaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">paragraph_breaks</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Normalize the boundaries identified to the original text&#39;s</span>
<span class="sd">        paragraph breaks&quot;&quot;&quot;</span>

        <span class="n">norm_boundaries</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">char_count</span><span class="p">,</span> <span class="n">word_count</span><span class="p">,</span> <span class="n">gaps_seen</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="n">seen_word</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
            <span class="n">char_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="s2">&quot; </span><span class="se">\t\n</span><span class="s2">&quot;</span> <span class="ow">and</span> <span class="n">seen_word</span><span class="p">:</span>
                <span class="n">seen_word</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="n">word_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="s2">&quot; </span><span class="se">\t\n</span><span class="s2">&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">seen_word</span><span class="p">:</span>
                <span class="n">seen_word</span><span class="o">=</span><span class="bp">True</span>
            <span class="k">if</span> <span class="n">gaps_seen</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="ow">and</span> <span class="n">word_count</span> <span class="o">&gt;</span> \
                                               <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">gaps_seen</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">gaps_seen</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1">#find closest paragraph break</span>
                    <span class="n">best_fit</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">br</span> <span class="ow">in</span> <span class="n">paragraph_breaks</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">best_fit</span> <span class="o">&gt;</span> <span class="nb">abs</span><span class="p">(</span><span class="n">br</span><span class="o">-</span><span class="n">char_count</span><span class="p">):</span>
                            <span class="n">best_fit</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">br</span><span class="o">-</span><span class="n">char_count</span><span class="p">)</span>
                            <span class="n">bestbr</span> <span class="o">=</span> <span class="n">br</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">break</span>
                    <span class="k">if</span> <span class="n">bestbr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">norm_boundaries</span><span class="p">:</span> <span class="c1">#avoid duplicates</span>
                        <span class="n">norm_boundaries</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bestbr</span><span class="p">)</span>
                <span class="n">gaps_seen</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">norm_boundaries</span></div>


<span class="k">class</span> <span class="nc">TokenTableField</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A field in the token table holding parameters for each token,</span>
<span class="sd">    used later in the process&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">first_pos</span><span class="p">,</span>
                 <span class="n">ts_occurences</span><span class="p">,</span>
                 <span class="n">total_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">par_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">last_par</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">last_tok_seq</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="p">[</span><span class="s1">&#39;self&#39;</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">TokenSequence</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s2">&quot;A token list with its original length and its index&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">index</span><span class="p">,</span>
                 <span class="n">wrdindex_list</span><span class="p">,</span>
                 <span class="n">original_length</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">original_length</span><span class="o">=</span><span class="n">original_length</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrdindex_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="p">[</span><span class="s1">&#39;self&#39;</span><span class="p">]</span>

<span class="c1">#Pasted from the SciPy cookbook: http://www.scipy.org/Cookbook/SignalSmooth</span>
<span class="k">def</span> <span class="nf">smooth</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">window_len</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span><span class="n">window</span><span class="o">=</span><span class="s1">&#39;flat&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;smooth the data using a window with requested size.</span>

<span class="sd">    This method is based on the convolution of a scaled window with the signal.</span>
<span class="sd">    The signal is prepared by introducing reflected copies of the signal</span>
<span class="sd">    (with the window size) in both ends so that transient parts are minimized</span>
<span class="sd">    in the beginning and end part of the output signal.</span>

<span class="sd">    :param x: the input signal</span>
<span class="sd">    :param window_len: the dimension of the smoothing window; should be an odd integer</span>
<span class="sd">    :param window: the type of window from &#39;flat&#39;, &#39;hanning&#39;, &#39;hamming&#39;, &#39;bartlett&#39;, &#39;blackman&#39;</span>
<span class="sd">        flat window will produce a moving average smoothing.</span>

<span class="sd">    :return: the smoothed signal</span>

<span class="sd">    example::</span>

<span class="sd">        t=linspace(-2,2,0.1)</span>
<span class="sd">        x=sin(t)+randn(len(t))*0.1</span>
<span class="sd">        y=smooth(x)</span>

<span class="sd">    :see also: numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve,</span>
<span class="sd">        scipy.signal.lfilter</span>

<span class="sd">    TODO: the window parameter could be the window itself if an array instead of a string</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;smooth only accepts 1 dimension arrays.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">&lt;</span> <span class="n">window_len</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input vector needs to be bigger than window size.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">window_len</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">window</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;flat&#39;</span><span class="p">,</span> <span class="s1">&#39;hanning&#39;</span><span class="p">,</span> <span class="s1">&#39;hamming&#39;</span><span class="p">,</span> <span class="s1">&#39;bartlett&#39;</span><span class="p">,</span> <span class="s1">&#39;blackman&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Window is on of &#39;flat&#39;, &#39;hanning&#39;, &#39;hamming&#39;, &#39;bartlett&#39;, &#39;blackman&#39;&quot;</span><span class="p">)</span>

    <span class="n">s</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">window_len</span><span class="p">:</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="n">window_len</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>

    <span class="c1">#print(len(s))</span>
    <span class="k">if</span> <span class="n">window</span> <span class="o">==</span> <span class="s1">&#39;flat&#39;</span><span class="p">:</span> <span class="c1">#moving average</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window_len</span><span class="p">,</span><span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="s1">&#39;numpy.&#39;</span> <span class="o">+</span> <span class="n">window</span> <span class="o">+</span> <span class="s1">&#39;(window_len)&#39;</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">w</span><span class="o">/</span><span class="n">w</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">s</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y</span><span class="p">[</span><span class="n">window_len</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="n">window_len</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">demo</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">brown</span>
    <span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span>
    <span class="n">tt</span> <span class="o">=</span> <span class="n">TextTilingTokenizer</span><span class="p">(</span><span class="n">demo_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">text</span> <span class="o">=</span> <span class="n">brown</span><span class="o">.</span><span class="n">raw</span><span class="p">()[:</span><span class="mi">10000</span><span class="p">]</span>
    <span class="n">s</span><span class="p">,</span> <span class="n">ss</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Sentence Gap index&quot;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Gap Scores&quot;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span> <span class="n">s</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gap Scores&quot;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ss</span><span class="p">)),</span> <span class="n">ss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Smoothed Gap scores&quot;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)),</span> <span class="n">d</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Depth scores&quot;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)),</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>