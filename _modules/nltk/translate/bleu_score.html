

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nltk.translate.bleu_score</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="nltk" href="../../nltk.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../nltk.html">nltk</a> &raquo;</li>
        
      <li>nltk.translate.bleu_score</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nltk.translate.bleu_score</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># Natural Language Toolkit: BLEU Score</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2015 NLTK Project</span>
<span class="c1"># Authors: Chin Yee Lee, Hengfeng Li, Ruxin Hou, Calvin Tanujaya Lim</span>
<span class="c1"># Contributors: Dmitrijs Milajevs, Liling Tan</span>
<span class="c1"># URL: &lt;http://nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>
<span class="sd">&quot;&quot;&quot;BLEU score implementation.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">ngrams</span>


<span class="k">def</span> <span class="nf">sentence_bleu</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
                  <span class="n">smoothing_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate BLEU score (Bilingual Evaluation Understudy) from</span>
<span class="sd">    Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.</span>
<span class="sd">    &quot;BLEU: a method for automatic evaluation of machine translation.&quot; </span>
<span class="sd">    In Proceedings of ACL. http://www.aclweb.org/anthology/P02-1040.pdf</span>

<span class="sd">    &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...               &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; hypothesis2 = [&#39;It&#39;, &#39;is&#39;, &#39;to&#39;, &#39;insure&#39;, &#39;the&#39;, &#39;troops&#39;,</span>
<span class="sd">    ...               &#39;forever&#39;, &#39;hearing&#39;, &#39;the&#39;, &#39;activity&#39;, &#39;guidebook&#39;,</span>
<span class="sd">    ...               &#39;that&#39;, &#39;party&#39;, &#39;direct&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...               &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">    ...               &#39;Party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis1) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5045...</span>

<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis2) # doctest: +ELLIPSIS</span>
<span class="sd">    0.3969...</span>

<span class="sd">    The default BLEU calculates a score for up to 4grams using uniform</span>
<span class="sd">    weights. To evaluate your translations with higher/lower order ngrams, </span>
<span class="sd">    use customized weights. E.g. when accounting for up to 6grams with uniform</span>
<span class="sd">    weights:</span>

<span class="sd">    &gt;&gt;&gt; weights = (0.1666, 0.1666, 0.1666, 0.1666, 0.1666)</span>
<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis1, weights)</span>
<span class="sd">    0.45838627164939455</span>
<span class="sd">    </span>
<span class="sd">    :param references: reference sentences</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param weights: weights for unigrams, bigrams, trigrams and so on</span>
<span class="sd">    :type weights: list(float)</span>
<span class="sd">    :return: The sentence-level BLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculates the brevity penalty.</span>
    <span class="c1"># *hyp_len* is referred to as *c* in Papineni et. al. (2002)</span>
    <span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
    <span class="c1"># *closest_ref_len* is referred to as *r* variable in Papineni et. al. (2002)</span>
    <span class="n">closest_ref_len</span> <span class="o">=</span> <span class="n">_closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
    <span class="n">bp</span> <span class="o">=</span> <span class="n">_brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
    
    <span class="c1"># Calculates the modified precision *p_n* for each order of ngram.</span>
    <span class="n">p_n</span> <span class="o">=</span> <span class="p">[</span><span class="n">_modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># Smoothen the modified precision.</span>
    <span class="c1"># Note: smooth_precision() converts values into float.</span>
    <span class="k">if</span> <span class="n">smoothing_function</span><span class="p">:</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="n">smoothing_function</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span> 
                                 <span class="n">hypothesis</span><span class="o">=</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="n">hyp_len</span><span class="p">)</span>
    
    <span class="c1"># Calculates the overall modified precision for all ngrams.</span>
    <span class="c1"># By sum of the product of the weights and the respective *p_n*</span>
    <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_i</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_i</span> <span class="k">else</span> <span class="mi">0</span> 
         <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">p_n</span><span class="p">))</span>
    <span class="n">sum_s</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">fsum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sum_s</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">p_n</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">bp</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sum_s</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">corpus_bleu</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
                <span class="n">smoothing_function</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a single corpus-level BLEU score (aka. system-level BLEU) for all </span>
<span class="sd">    the hypotheses and their respective references.  </span>

<span class="sd">    Instead of averaging the sentence level BLEU scores (i.e. marco-average </span>
<span class="sd">    precision), the original BLEU metric (Papineni et al. 2002) accounts for </span>
<span class="sd">    the micro-average precision (i.e. summing the numerators and denominators</span>
<span class="sd">    for each hypothesis-reference(s) pairs before the division).</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; hyp1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...         &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...         &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1a = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...          &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...          &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1b = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...          &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...          &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;, &#39;Party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1c = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...          &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...          &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; hyp2 = [&#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;, &#39;because&#39;, &#39;he&#39;, &#39;was&#39;, </span>
<span class="sd">    ...         &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref2a = [&#39;he&#39;, &#39;was&#39;, &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;, </span>
<span class="sd">    ...          &#39;because&#39;, &#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; list_of_references = [[ref1a, ref1b, ref1c], [ref2a]]</span>
<span class="sd">    &gt;&gt;&gt; hypotheses = [hyp1, hyp2]</span>
<span class="sd">    &gt;&gt;&gt; corpus_bleu(list_of_references, hypotheses) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5520...</span>
<span class="sd">    </span>
<span class="sd">    The example below show that corpus_bleu() is different from averaging </span>
<span class="sd">    sentence_bleu() for hypotheses </span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; score1 = sentence_bleu([ref1a, ref1b, ref1c], hyp1)</span>
<span class="sd">    &gt;&gt;&gt; score2 = sentence_bleu([ref2a], hyp2)</span>
<span class="sd">    &gt;&gt;&gt; (score1 + score2) / 2 # doctest: +ELLIPSIS</span>
<span class="sd">    0.6223...</span>
<span class="sd">    </span>
<span class="sd">    :param references: a corpus of lists of reference sentences, w.r.t. hypotheses</span>
<span class="sd">    :type references: list(list(list(str)))</span>
<span class="sd">    :param hypotheses: a list of hypothesis sentences</span>
<span class="sd">    :type hypotheses: list(list(str))</span>
<span class="sd">    :param weights: weights for unigrams, bigrams, trigrams and so on</span>
<span class="sd">    :type weights: list(float)</span>
<span class="sd">    :return: The corpus-level BLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p_numerators</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span> <span class="c1"># Key = ngram order, and value = no. of ngram matches.</span>
    <span class="n">p_denominators</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span> <span class="c1"># Key = ngram order, and value = no. of ngram in ref.</span>
    <span class="n">hyp_lengths</span><span class="p">,</span> <span class="n">ref_lengths</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">),</span> <span class="s2">&quot;The number of hypotheses and their reference(s) should be the same&quot;</span>
    
    <span class="c1"># Iterate through each hypothesis and their corresponding references.</span>
    <span class="k">for</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="c1"># For each order of ngram, calculate the numerator and</span>
        <span class="c1"># denominator for the corpus-level modified precision.</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span> 
            <span class="n">p_i</span> <span class="o">=</span> <span class="n">_modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">p_numerators</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span>
            <span class="n">p_denominators</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span>
            
        <span class="c1"># Calculate the hypothesis length and the closest reference length.</span>
        <span class="c1"># Adds them to the corpus-level hypothesis and reference counts.</span>
        <span class="n">hyp_len</span> <span class="o">=</span>  <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="n">hyp_lengths</span> <span class="o">+=</span> <span class="n">hyp_len</span>
        <span class="n">ref_lengths</span> <span class="o">+=</span> <span class="n">_closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>    
        
    <span class="c1"># Calculate corpus-level brevity penalty.</span>
    <span class="n">bp</span> <span class="o">=</span> <span class="n">_brevity_penalty</span><span class="p">(</span><span class="n">ref_lengths</span><span class="p">,</span> <span class="n">hyp_lengths</span><span class="p">)</span>
    
    <span class="c1"># Collects the various precision values for the different ngram orders.</span>
    <span class="n">p_n</span> <span class="o">=</span> <span class="p">[</span><span class="n">Fraction</span><span class="p">(</span><span class="n">p_numerators</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">p_denominators</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> 
           <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
    
    <span class="c1"># Smoothen the modified precision.</span>
    <span class="c1"># Note: smooth_precision() converts values into float.</span>
    <span class="k">if</span> <span class="n">smoothing_function</span><span class="p">:</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="n">smoothing_function</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span> 
                                 <span class="n">hypothesis</span><span class="o">=</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="n">hyp_len</span><span class="p">)</span>
        
    <span class="c1"># Calculates the overall modified precision for all ngrams.</span>
    <span class="c1"># By sum of the product of the weights and the respective *p_n*</span>
    <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_i</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_i</span> <span class="k">else</span> <span class="mi">0</span> 
         <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">p_n</span><span class="p">))</span>
        
    <span class="k">return</span> <span class="n">bp</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">fsum</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate modified ngram precision.</span>

<span class="sd">    The normal precision method may lead to some wrong translations with</span>
<span class="sd">    high-precision, e.g., the translation, in which a word of reference</span>
<span class="sd">    repeats several times, has very high precision.     </span>

<span class="sd">    This function only returns the Fraction object that contains the numerator </span>
<span class="sd">    and denominator necessary to calculate the corpus-level precision. </span>
<span class="sd">    To calculate the modified precision for a single pair of hypothesis and </span>
<span class="sd">    references, cast the Fraction object into a float. </span>
<span class="sd">    </span>
<span class="sd">    The famous &quot;the the the ... &quot; example shows that you can get BLEU precision</span>
<span class="sd">    by duplicating high frequency words.</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; reference1 = &#39;the cat is on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; reference2 = &#39;there is a cat on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hypothesis1 = &#39;the the the the the the the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2]</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis1, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.2857...</span>
<span class="sd">    </span>
<span class="sd">    In the modified n-gram precision, a reference word will be considered </span>
<span class="sd">    exhausted after a matching hypothesis word is identified, e.g.</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, </span>
<span class="sd">        ...               &#39;forever&#39;, &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;Party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">        ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = &#39;of the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis, n=1))</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis, n=2))</span>
<span class="sd">        1.0</span>
<span class="sd">        </span>
<span class="sd">    An example of a normal machine translation hypothesis:</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; hypothesis2 = [&#39;It&#39;, &#39;is&#39;, &#39;to&#39;, &#39;insure&#39;, &#39;the&#39;, &#39;troops&#39;,</span>
<span class="sd">        ...               &#39;forever&#39;, &#39;hearing&#39;, &#39;the&#39;, &#39;activity&#39;, &#39;guidebook&#39;,</span>
<span class="sd">        ...               &#39;that&#39;, &#39;party&#39;, &#39;direct&#39;]</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, </span>
<span class="sd">        ...               &#39;forever&#39;, &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;Party&#39;]</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">        ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis1, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.9444...</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis2, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.5714...</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis1, n=2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.5882352941176471</span>
<span class="sd">        &gt;&gt;&gt; float(_modified_precision(references, hypothesis2, n=2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.07692...</span>
<span class="sd">     </span>
<span class="sd">    </span>
<span class="sd">    :param references: A list of reference translations.</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: A hypothesis translation.</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param n: The ngram order.</span>
<span class="sd">    :type n: int</span>
<span class="sd">    :return: BLEU&#39;s modified precision for the nth order ngram.</span>
<span class="sd">    :rtype: Fraction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">counts</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">max_counts</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">:</span>
        <span class="n">reference_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
            <span class="n">max_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ngram</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">reference_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">])</span>

    <span class="n">clipped_counts</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">ngram</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">max_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]))</span> 
                          <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
    
    <span class="n">numerator</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">clipped_counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  
    
    <span class="k">return</span> <span class="n">Fraction</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">denominator</span><span class="p">)</span>  
    

<span class="k">def</span> <span class="nf">_closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function finds the reference that is the closest length to the </span>
<span class="sd">    hypothesis. The closest reference length is referred to as *r* variable </span>
<span class="sd">    from the brevity penalty formula in Papineni et. al. (2002)</span>
<span class="sd">    </span>
<span class="sd">    :param references: A list of reference translations.</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: The length of the hypothesis.</span>
<span class="sd">    :type hypothesis: int</span>
<span class="sd">    :return: The length of the reference that&#39;s closest to the hypothesis.</span>
<span class="sd">    :rtype: int    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ref_lens</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span> <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
    <span class="n">closest_ref_len</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">ref_lens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">ref_len</span><span class="p">:</span> 
                          <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">ref_len</span> <span class="o">-</span> <span class="n">hyp_len</span><span class="p">),</span> <span class="n">ref_len</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">closest_ref_len</span>

<span class="k">def</span> <span class="nf">_brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate brevity penalty.</span>

<span class="sd">    As the modified n-gram precision still has the problem from the short</span>
<span class="sd">    length sentence, brevity penalty is used to modify the overall BLEU</span>
<span class="sd">    score according to length.</span>

<span class="sd">    An example from the paper. There are three references with length 12, 15</span>
<span class="sd">    and 17. And a concise hypothesis of the length 12. The brevity penalty is 1.</span>

<span class="sd">        &gt;&gt;&gt; reference1 = list(&#39;aaaaaaaaaaaa&#39;)      # i.e. [&#39;a&#39;] * 12</span>
<span class="sd">        &gt;&gt;&gt; reference2 = list(&#39;aaaaaaaaaaaaaaa&#39;)   # i.e. [&#39;a&#39;] * 15</span>
<span class="sd">        &gt;&gt;&gt; reference3 = list(&#39;aaaaaaaaaaaaaaaaa&#39;) # i.e. [&#39;a&#39;] * 17</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = list(&#39;aaaaaaaaaaaa&#39;)      # i.e. [&#39;a&#39;] * 12</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; _brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">        1.0</span>

<span class="sd">    In case a hypothesis translation is shorter than the references, penalty is</span>
<span class="sd">    applied.</span>

<span class="sd">        &gt;&gt;&gt; references = [[&#39;a&#39;] * 28, [&#39;a&#39;] * 28]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; _brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">        0.2635971381157267</span>

<span class="sd">    The length of the closest reference is used to compute the penalty. If the</span>
<span class="sd">    length of a hypothesis is 12, and the reference lengths are 13 and 2, the</span>
<span class="sd">    penalty is applied because the hypothesis length (12) is less then the</span>
<span class="sd">    closest reference length (13).</span>

<span class="sd">        &gt;&gt;&gt; references = [[&#39;a&#39;] * 13, [&#39;a&#39;] * 2]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; _brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS</span>
<span class="sd">        0.9200...</span>

<span class="sd">    The brevity penalty doesn&#39;t depend on reference order. More importantly,</span>
<span class="sd">    when two reference sentences are at the same distance, the shortest</span>
<span class="sd">    reference sentence length is used.</span>

<span class="sd">        &gt;&gt;&gt; references = [[&#39;a&#39;] * 13, [&#39;a&#39;] * 11]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; bp1 = _brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(reversed(references), hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; bp2 = _brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; bp1 == bp2 == 1</span>
<span class="sd">        True</span>

<span class="sd">    A test example from mteval-v13a.pl (starting from the line 705):</span>

<span class="sd">        &gt;&gt;&gt; references = [[&#39;a&#39;] * 11, [&#39;a&#39;] * 8]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 7</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; _brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS</span>
<span class="sd">        0.8668...</span>

<span class="sd">        &gt;&gt;&gt; references = [[&#39;a&#39;] * 11, [&#39;a&#39;] * 8, [&#39;a&#39;] * 6, [&#39;a&#39;] * 7]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 7</span>
<span class="sd">        &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">        &gt;&gt;&gt; closest_ref_len =  _closest_ref_length(references, hyp_len)</span>
<span class="sd">        &gt;&gt;&gt; _brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">        1.0</span>
<span class="sd">    </span>
<span class="sd">    :param hyp_len: The length of the hypothesis for a single sentence OR the </span>
<span class="sd">    sum of all the hypotheses&#39; lengths for a corpus</span>
<span class="sd">    :type hyp_len: int</span>
<span class="sd">    :param closest_ref_len: The length of the closest reference for a single </span>
<span class="sd">    hypothesis OR the sum of all the closest references for every hypotheses.</span>
<span class="sd">    :type closest_reference_len: int    </span>
<span class="sd">    :return: BLEU&#39;s brevity penalty.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">hyp_len</span> <span class="o">&gt;</span> <span class="n">closest_ref_len</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">closest_ref_len</span> <span class="o">/</span> <span class="n">hyp_len</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SmoothingFunction</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is an implementation of the smoothing techniques </span>
<span class="sd">    for segment-level BLEU scores that was presented in </span>
<span class="sd">    Boxing Chen and Collin Cherry (2014) A Systematic Comparison of </span>
<span class="sd">    Smoothing Techniques for Sentence-Level BLEU. In WMT14. </span>
<span class="sd">    http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This will initialize the parameters required for the various smoothing</span>
<span class="sd">        techniques, the default values are set to the numbers used in the</span>
<span class="sd">        experiments from Chen and Cherry (2014).</span>

<span class="sd">        &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;, &#39;ensures&#39;, </span>
<span class="sd">        ...                 &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;, &#39;obeys&#39;, &#39;the&#39;, </span>
<span class="sd">        ...                 &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;, &#39;ensures&#39;, </span>
<span class="sd">        ...               &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;, &#39;heed&#39;, </span>
<span class="sd">        ...               &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">                </span>
<span class="sd">        &gt;&gt;&gt; chencherry = SmoothingFunction()</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method0)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4576...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method3)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method4)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method5)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4905...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method6)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.1801...</span>
<span class="sd">        &gt;&gt;&gt; print (sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method7)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4905...</span>

<span class="sd">        :param epsilon: the epsilon value use in method 1</span>
<span class="sd">        :type epsilon: float</span>
<span class="sd">        :param alpha: the alpha value use in method 6</span>
<span class="sd">        :type alpha: int</span>
<span class="sd">        :param k: the k value use in method 4</span>
<span class="sd">        :type k: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        
    <span class="k">def</span> <span class="nf">method0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; No smoothing. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">p_n</span>
        
    <span class="k">def</span> <span class="nf">method1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        Smoothing method 1: Add *epsilon* counts to precision with 0 counts.</span>
<span class="sd">        &quot;&quot;&quot;</span> 
        <span class="k">return</span> <span class="p">[(</span><span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span><span class="o">/</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span> 
                <span class="k">if</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">p_i</span> <span class="k">for</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="n">p_n</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="nf">method2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 2: Add 1 to both numerator and denominator from </span>
<span class="sd">        Chin-Yew Lin and Franz Josef Och (2004) Automatic evaluation of </span>
<span class="sd">        machine translation quality using longest common subsequence and </span>
<span class="sd">        skip-bigram statistics. In ACL04.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">Fraction</span><span class="p">(</span><span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="n">p_n</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="nf">method3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 3: NIST geometric sequence smoothing </span>
<span class="sd">        The smoothing is computed by taking 1 / ( 2^k ), instead of 0, for each </span>
<span class="sd">        precision score whose matching n-gram count is null.</span>
<span class="sd">        k is 1 for the first &#39;n&#39; value for which the n-gram match count is null/</span>
<span class="sd">        For example, if the text contains:</span>
<span class="sd">         - one 2-gram match</span>
<span class="sd">         - and (consequently) two 1-gram matches</span>
<span class="sd">        the n-gram count for each individual precision score would be:</span>
<span class="sd">         - n=1  =&gt;  prec_count = 2     (two unigrams)</span>
<span class="sd">         - n=2  =&gt;  prec_count = 1     (one bigram)</span>
<span class="sd">         - n=3  =&gt;  prec_count = 1/2   (no trigram,  taking &#39;smoothed&#39; value of 1 / ( 2^k ), with k=1)</span>
<span class="sd">         - n=4  =&gt;  prec_count = 1/4   (no fourgram, taking &#39;smoothed&#39; value of 1 / ( 2^k ), with k=2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">incvnt</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># From the mteval-v13a.pl, it&#39;s referred to as k.</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p_i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">incvnt</span> <span class="o">*</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span><span class="p">)</span>
                <span class="n">incvnt</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">p_n</span>
    
    <span class="k">def</span> <span class="nf">method4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 4: </span>
<span class="sd">        Shorter translations may have inflated precision values due to having </span>
<span class="sd">        smaller denominators; therefore, we give them proportionally</span>
<span class="sd">        smaller smoothed counts. Instead of scaling to 1/(2^k), Chen and Cherry </span>
<span class="sd">        suggests dividing by 1/ln(len(T)), where T is the length of the translation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">incvnt</span> <span class="o">=</span> <span class="mi">1</span> 
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p_i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">hyp_len</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">incvnt</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">hyp_len</span><span class="p">)</span> <span class="c1"># Note that this K is different from the K from NIST.</span>
                <span class="n">incvnt</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">p_n</span>


    <span class="k">def</span> <span class="nf">method5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 5:</span>
<span class="sd">        The matched counts for similar values of n should be similar. To a </span>
<span class="sd">        calculate the n-gram matched count, it averages the n−1, n and n+1 gram </span>
<span class="sd">        matched counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># Requires an precision value for an addition ngram order.</span>
        <span class="n">p_n_plus1</span> <span class="o">=</span> <span class="n">p_n</span> <span class="o">+</span> <span class="p">[</span><span class="n">_modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
        <span class="n">m</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">p_i</span> <span class="o">+</span> <span class="n">p_n_plus1</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">3</span>
            <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> 
        <span class="k">return</span> <span class="n">p_n</span>
        
    <span class="k">def</span> <span class="nf">method6</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 6:</span>
<span class="sd">        Interpolates the maximum likelihood estimate of the precision *p_n* with </span>
<span class="sd">        a prior estimate *pi0*. The prior is estimated by assuming that the ratio </span>
<span class="sd">        between pn and pn−1 will be the same as that between pn−1 and pn−2.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]:</span> <span class="c1"># Skips the first 2 orders of ngrams.</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pi0</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> 
                <span class="c1"># No. of ngrams in translation.</span>
                <span class="n">l</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">pi0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_n</span>
    
    <span class="k">def</span> <span class="nf">method7</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 6:</span>
<span class="sd">        Interpolates the maximum likelihood estimate of the precision *p_n* with </span>
<span class="sd">        a prior estimate *pi0*. The prior is estimated by assuming that the ratio </span>
<span class="sd">        between pn and pn−1 will be the same as that between pn−1 and pn−2.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method4</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method5</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_n</span>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>