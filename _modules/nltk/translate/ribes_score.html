

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nltk.translate.ribes_score</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="nltk" href="../../nltk.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../nltk.html">nltk</a> &raquo;</li>
        
      <li>nltk.translate.ribes_score</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nltk.translate.ribes_score</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># Natural Language Toolkit: RIBES Score</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2015 NLTK Project</span>
<span class="c1"># Contributors: Katsuhito Sudoh, Liling Tan, Kasramvd, J.F.Sebastian</span>
<span class="c1">#               Mark Byers, ekhumoro, P. Ortiz</span>
<span class="c1"># URL: &lt;http://nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>
<span class="sd">&quot;&quot;&quot; RIBES score implementation &quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">islice</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">ngrams</span><span class="p">,</span> <span class="n">choose</span>


<span class="k">def</span> <span class="nf">sentence_ribes</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The RIBES (Rank-based Intuitive Bilingual Evaluation Score) from </span>
<span class="sd">    Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh and </span>
<span class="sd">    Hajime Tsukada. 2010. &quot;Automatic Evaluation of Translation Quality for </span>
<span class="sd">    Distant Language Pairs&quot;. In Proceedings of EMNLP. </span>
<span class="sd">    http://www.aclweb.org/anthology/D/D10/D10-1092.pdf </span>
<span class="sd">    </span>
<span class="sd">    The generic RIBES scores used in shared task, e.g. Workshop for </span>
<span class="sd">    Asian Translation (WAT) uses the following RIBES calculations:</span>
<span class="sd">    </span>
<span class="sd">        RIBES = kendall_tau * (alpha**p1) * (beta**bp)</span>
<span class="sd">    </span>
<span class="sd">    Please note that this re-implementation differs from the official</span>
<span class="sd">    RIBES implementation and though it emulates the results as describe</span>
<span class="sd">    in the original paper, there are further optimization implemented </span>
<span class="sd">    in the official RIBES script.</span>
<span class="sd">    </span>
<span class="sd">    Users are encouraged to use the official RIBES script instead of this </span>
<span class="sd">    implementation when evaluating your machine translation system. Refer</span>
<span class="sd">    to http://www.kecl.ntt.co.jp/icl/lirg/ribes/ for the official script.</span>
<span class="sd">    </span>
<span class="sd">    :param references: a list of reference sentences</span>
<span class="sd">    :type reference: list(list(str))</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param alpha: hyperparameter used as a prior for the unigram precision.</span>
<span class="sd">    :type alpha: float</span>
<span class="sd">    :param beta: hyperparameter used as a prior for the brevity penalty.</span>
<span class="sd">    :type beta: float</span>
<span class="sd">    :return: The best ribes score from one of the references.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">best_ribes</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
    <span class="c1"># Calculates RIBES for each reference and returns the best score.</span>
    <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">:</span>
        <span class="c1"># Collects the *worder* from the ranked correlation alignments.</span>
        <span class="n">worder</span> <span class="o">=</span> <span class="n">word_rank_alignment</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">)</span>
        <span class="n">nkt</span> <span class="o">=</span> <span class="n">kendall_tau</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span>
            
        <span class="c1"># Calculates the brevity penalty</span>
        <span class="n">bp</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)))</span>
        
        <span class="c1"># Calculates the unigram precision, *p1*</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        
        <span class="n">_ribes</span> <span class="o">=</span> <span class="n">nkt</span> <span class="o">*</span> <span class="p">(</span><span class="n">p1</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span>  <span class="p">(</span><span class="n">bp</span> <span class="o">**</span> <span class="n">beta</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">_ribes</span> <span class="o">&gt;</span> <span class="n">best_ribes</span><span class="p">:</span> <span class="c1"># Keeps the best score.</span>
            <span class="n">best_ribes</span> <span class="o">=</span> <span class="n">_ribes</span>
        
    <span class="k">return</span> <span class="n">best_ribes</span>


<span class="k">def</span> <span class="nf">corpus_ribes</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function &quot;calculates RIBES for a system output (hypothesis) with </span>
<span class="sd">    multiple references, and returns &quot;best&quot; score among multi-references and </span>
<span class="sd">    individual scores. The scores are corpus-wise, i.e., averaged by the number </span>
<span class="sd">    of sentences.&quot; (c.f. RIBES version 1.03.1 code).</span>
<span class="sd">    </span>
<span class="sd">    Different from BLEU&#39;s micro-average precision, RIBES calculates the </span>
<span class="sd">    macro-average precision by averaging the best RIBES score for each pair of </span>
<span class="sd">    hypothesis and its corresponding references </span>

<span class="sd">    &gt;&gt;&gt; hyp1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...         &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...         &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1a = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...          &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...          &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1b = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...          &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...          &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;, &#39;Party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1c = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...          &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...          &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; hyp2 = [&#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;, &#39;because&#39;, &#39;he&#39;, &#39;was&#39;, </span>
<span class="sd">    ...         &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref2a = [&#39;he&#39;, &#39;was&#39;, &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;, </span>
<span class="sd">    ...          &#39;because&#39;, &#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; list_of_references = [[ref1a, ref1b, ref1c], [ref2a]]</span>
<span class="sd">    &gt;&gt;&gt; hypotheses = [hyp1, hyp2]</span>
<span class="sd">    &gt;&gt;&gt; round(corpus_ribes(list_of_references, hypotheses),4)</span>
<span class="sd">    0.3597</span>
<span class="sd">    </span>
<span class="sd">    :param references: a corpus of lists of reference sentences, w.r.t. hypotheses</span>
<span class="sd">    :type references: list(list(list(str)))</span>
<span class="sd">    :param hypotheses: a list of hypothesis sentences</span>
<span class="sd">    :type hypotheses: list(list(str))</span>
<span class="sd">    :param alpha: hyperparameter used as a prior for the unigram precision.</span>
<span class="sd">    :type alpha: float</span>
<span class="sd">    :param beta: hyperparameter used as a prior for the brevity penalty.</span>
<span class="sd">    :type beta: float</span>
<span class="sd">    :return: The best ribes score from one of the references.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">corpus_best_ribes</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># Iterate through each hypothesis and their corresponding references.</span>
    <span class="k">for</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="n">corpus_best_ribes</span> <span class="o">+=</span> <span class="n">sentence_ribes</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">corpus_best_ribes</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
    
        
<span class="k">def</span> <span class="nf">position_of_ngram</span><span class="p">(</span><span class="n">ngram</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function returns the position of the first instance of the ngram </span>
<span class="sd">    appearing in a sentence.</span>
<span class="sd">    </span>
<span class="sd">    Note that one could also use string as follows but the code is a little</span>
<span class="sd">    convoluted with type casting back and forth:</span>
<span class="sd">        </span>
<span class="sd">        char_pos = &#39; &#39;.join(sent)[:&#39; &#39;.join(sent).index(&#39; &#39;.join(ngram))]</span>
<span class="sd">        word_pos = char_pos.count(&#39; &#39;)</span>
<span class="sd">        </span>
<span class="sd">    Another way to conceive this is:</span>
<span class="sd">    </span>
<span class="sd">        return next(i for i, ng in enumerate(ngrams(sentence, len(ngram))) </span>
<span class="sd">                    if ng == ngram)</span>
<span class="sd">                    </span>
<span class="sd">    :param ngram: The ngram that needs to be searched</span>
<span class="sd">    :type ngram: tuple</span>
<span class="sd">    :param sentence: The list of tokens to search from.</span>
<span class="sd">    :type sentence: list(str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Iterates through the ngrams in sentence.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">sublist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngram</span><span class="p">))):</span>
        <span class="c1"># Returns the index of the word when ngram matches.</span>
        <span class="k">if</span> <span class="n">ngram</span> <span class="o">==</span> <span class="n">sublist</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">i</span>


<span class="k">def</span> <span class="nf">word_rank_alignment</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">character_based</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;    </span>
<span class="sd">    This is the word rank alignment algorithm described in the paper to produce</span>
<span class="sd">    the *worder* list, i.e. a list of word indices of the hypothesis word orders </span>
<span class="sd">    w.r.t. the list of reference words.</span>
<span class="sd">    </span>
<span class="sd">    Below is (H0, R0) example from the Isozaki et al. 2010 paper, </span>
<span class="sd">    note the examples are indexed from 1 but the results here are indexed from 0:</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; ref = str(&#39;he was interested in world history because he &#39;</span>
<span class="sd">        ... &#39;read the book&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; hyp = str(&#39;he read the book because he was interested in world &#39;</span>
<span class="sd">        ... &#39;history&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; word_rank_alignment(ref, hyp)</span>
<span class="sd">        [7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5]</span>
<span class="sd">        </span>
<span class="sd">    The (H1, R1) example from the paper, note the 0th index:</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; ref = &#39;John hit Bob yesterday&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hyp = &#39;Bob hit John yesterday&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; word_rank_alignment(ref, hyp)</span>
<span class="sd">        [2, 1, 0, 3]</span>

<span class="sd">    Here is the (H2, R2) example from the paper, note the 0th index here too:</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; ref = &#39;the boy read the book&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hyp = &#39;the book was read by the boy&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; word_rank_alignment(ref, hyp)</span>
<span class="sd">        [3, 4, 2, 0, 1]</span>
<span class="sd">        </span>
<span class="sd">    :param reference: a reference sentence</span>
<span class="sd">    :type reference: list(str)</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">worder</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
    <span class="c1"># Stores a list of possible ngrams from the reference sentence.</span>
    <span class="c1"># This is used for matching context window later in the algorithm.</span>
    <span class="n">ref_ngrams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hyp_ngrams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ng</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">ref_ngrams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ng</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ng</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">hyp_ngrams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ng</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">h_word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">):</span>
        <span class="c1"># If word is not in the reference, continue.</span>
        <span class="k">if</span> <span class="n">h_word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">reference</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="c1"># If we can determine one-to-one word correspondence for unigrams that </span>
        <span class="c1"># only appear once in both the reference and hypothesis.</span>
        <span class="k">elif</span> <span class="n">hypothesis</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">h_word</span><span class="p">)</span> <span class="o">==</span> <span class="n">reference</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">h_word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">worder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">h_word</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_window_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">-</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">window</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_window_size</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span><span class="o">+</span><span class="n">window</span> <span class="o">&lt;</span> <span class="n">hyp_len</span><span class="p">:</span> <span class="c1"># If searching the right context is possible.</span>
                    <span class="c1"># Retrieve the right context window.</span>
                    <span class="n">right_context_ngram</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">islice</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="n">window</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
                    <span class="n">num_times_in_ref</span> <span class="o">=</span> <span class="n">ref_ngrams</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">right_context_ngram</span><span class="p">)</span>
                    <span class="n">num_times_in_hyp</span> <span class="o">=</span> <span class="n">hyp_ngrams</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">right_context_ngram</span><span class="p">)</span> 
                    <span class="c1"># If ngram appears only once in both ref and hyp.</span>
                    <span class="k">if</span> <span class="n">num_times_in_ref</span> <span class="o">==</span> <span class="n">num_times_in_hyp</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Find the position of ngram that matched the reference.</span>
                        <span class="n">pos</span> <span class="o">=</span> <span class="n">position_of_ngram</span><span class="p">(</span><span class="n">right_context_ngram</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span>
                        <span class="n">worder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>  <span class="c1"># Add the positions of the ngram.</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="n">window</span> <span class="o">&lt;=</span> <span class="n">i</span><span class="p">:</span> <span class="c1"># If searching the left context is possible.</span>
                    <span class="c1"># Retrieve the left context window.</span>
                    <span class="n">left_context_ngram</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">islice</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="n">window</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
                    <span class="n">num_times_in_ref</span> <span class="o">=</span> <span class="n">ref_ngrams</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">left_context_ngram</span><span class="p">)</span>
                    <span class="n">num_times_in_hyp</span> <span class="o">=</span> <span class="n">hyp_ngrams</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">left_context_ngram</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">num_times_in_ref</span> <span class="o">==</span> <span class="n">num_times_in_hyp</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Find the position of ngram that matched the reference.</span>
                        <span class="n">pos</span> <span class="o">=</span> <span class="n">position_of_ngram</span><span class="p">(</span><span class="n">left_context_ngram</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span>
                        <span class="c1"># Add the positions of the ngram.</span>
                        <span class="n">worder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">left_context_ngram</span><span class="p">)</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  
                        <span class="k">break</span>
    <span class="k">return</span> <span class="n">worder</span>

    
<span class="k">def</span> <span class="nf">find_increasing_sequences</span><span class="p">(</span><span class="n">worder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given the *worder* list, this function groups monotonic +1 sequences. </span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; worder = [7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5]</span>
<span class="sd">        &gt;&gt;&gt; list(find_increasing_sequences(worder))</span>
<span class="sd">        [(7, 8, 9, 10), (0, 1, 2, 3, 4, 5)]</span>
<span class="sd">    </span>
<span class="sd">    :param worder: The worder list output from word_rank_alignment</span>
<span class="sd">    :param type: list(int)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">items</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">]</span>
    <span class="k">while</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">b</span><span class="p">:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">yield</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">kendall_tau</span><span class="p">(</span><span class="n">worder</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the Kendall&#39;s Tau correlation coefficient given the *worder*</span>
<span class="sd">    list of word alignments from word_rank_alignment(), using the formula:</span>
<span class="sd">    </span>
<span class="sd">        tau = 2 * num_increasing_pairs / num_possible pairs -1</span>
<span class="sd">    </span>
<span class="sd">    Note that the no. of increasing pairs can be discontinuous in the *worder*</span>
<span class="sd">    list and each each increasing sequence can be tabulated as choose(len(seq), 2) </span>
<span class="sd">    no. of increasing pairs, e.g.</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; worder = [7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5]</span>
<span class="sd">        &gt;&gt;&gt; number_possible_pairs = choose(len(worder), 2)</span>
<span class="sd">        &gt;&gt;&gt; round(kendall_tau(worder, normalize=False),3)</span>
<span class="sd">        -0.236</span>
<span class="sd">        &gt;&gt;&gt; round(kendall_tau(worder),3)</span>
<span class="sd">        0.382</span>
<span class="sd">    </span>
<span class="sd">    :param worder: The worder list output from word_rank_alignment</span>
<span class="sd">    :type worder: list(int)</span>
<span class="sd">    :param normalize: Flag to indicate normalization</span>
<span class="sd">    :type normalize: boolean</span>
<span class="sd">    :return: The Kendall&#39;s Tau correlation coefficient.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">worder_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span>
    <span class="c1"># Extract the groups of increasing/monotonic sequences.</span>
    <span class="n">increasing_sequences</span> <span class="o">=</span> <span class="n">find_increasing_sequences</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span>
    <span class="c1"># Calculate no. of increasing_pairs in *worder* list.</span>
    <span class="n">num_increasing_pairs</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">choose</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">increasing_sequences</span><span class="p">)</span> 
    <span class="c1"># Calculate no. of possible pairs.</span>
    <span class="n">num_possible_pairs</span> <span class="o">=</span> <span class="n">choose</span><span class="p">(</span><span class="n">worder_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Kendall&#39;s Tau computation.</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_increasing_pairs</span> <span class="o">/</span> <span class="n">num_possible_pairs</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span> <span class="c1"># If normalized, the tau output falls between 0.0 to 1.0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">tau</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Otherwise, the tau outputs falls between -1.0 to +1.0</span>
        <span class="k">return</span> <span class="n">tau</span>


<span class="k">def</span> <span class="nf">spearman_rho</span><span class="p">(</span><span class="n">worder</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the Spearman&#39;s Rho correlation coefficient given the *worder* </span>
<span class="sd">    list of word alignment from word_rank_alignment(), using the formula:</span>
<span class="sd">    </span>
<span class="sd">        rho = 1 - sum(d**2) / choose(len(worder)+1, 3)  </span>
<span class="sd">        </span>
<span class="sd">    Given that d is the sum of difference between the *worder* list of indices</span>
<span class="sd">    and the original word indices from the reference sentence.</span>
<span class="sd">    </span>
<span class="sd">    Using the (H0,R0) and (H5, R5) example from the paper</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; worder =  [7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5]</span>
<span class="sd">        &gt;&gt;&gt; round(spearman_rho(worder, normalize=False), 3)</span>
<span class="sd">        -0.591</span>
<span class="sd">        &gt;&gt;&gt; round(spearman_rho(worder), 3)</span>
<span class="sd">        0.205</span>
<span class="sd">    </span>
<span class="sd">    :param worder: The worder list output from word_rank_alignment</span>
<span class="sd">    :param type: list(int)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">worder_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">worder</span><span class="p">)</span>
    <span class="n">sum_d_square</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">wi</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">wi</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">worder</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">worder_len</span><span class="p">)))</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sum_d_square</span> <span class="o">/</span> <span class="n">choose</span><span class="p">(</span><span class="n">worder_len</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span> <span class="c1"># If normalized, the rho output falls between 0.0 to 1.0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">rho</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Otherwise, the rho outputs falls between -1.0 to +1.0</span>
        <span class="k">return</span> <span class="n">rho</span>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>