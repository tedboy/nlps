

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>gensim.similarities.docsim</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="gensim" href="../../gensim.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../gensim.html">gensim</a> &raquo;</li>
        
      <li>gensim.similarities.docsim</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for gensim.similarities.docsim</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2013 Radim Rehurek &lt;radimrehurek@seznam.cz&gt;</span>
<span class="c1"># Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains functions and classes for computing similarities across</span>
<span class="sd">a collection of documents in the Vector Space Model.</span>

<span class="sd">The main class is `Similarity`, which builds an index for a given set of documents.</span>
<span class="sd">Once the index is built, you can perform efficient queries like &quot;Tell me how similar</span>
<span class="sd">is this query document to each document in the index?&quot;. The result is a vector</span>
<span class="sd">of numbers as large as the size of the initial set of documents, that is, one float</span>
<span class="sd">for each index document. Alternatively, you can also request only the top-N most</span>
<span class="sd">similar index documents to the query.</span>

<span class="sd">You can later add new documents to the index via `Similarity.add_documents()`.</span>

<span class="sd">How It Works</span>
<span class="sd">------------</span>

<span class="sd">The `Similarity` class splits the index into several smaller sub-indexes (&quot;shards&quot;),</span>
<span class="sd">which are disk-based. If your entire index fits in memory (~hundreds of thousands</span>
<span class="sd">documents for 1GB of RAM), you can also use the `MatrixSimilarity` or `SparseMatrixSimilarity`</span>
<span class="sd">classes directly. These are more simple but do not scale as well (they keep the</span>
<span class="sd">entire index in RAM, no sharding).</span>

<span class="sd">Once the index has been initialized, you can query for document similarity simply by:</span>

<span class="sd">&gt;&gt;&gt; index = Similarity(&#39;/tmp/tst&#39;, corpus, num_features=12) # build the index</span>
<span class="sd">&gt;&gt;&gt; similarities = index[query] # get similarities between the query and all index documents</span>

<span class="sd">If you have more query documents, you can submit them all at once, in a batch:</span>

<span class="sd">&gt;&gt;&gt; for similarities in index[batch_of_documents]: # the batch is simply an iterable of documents (=gensim corpus)</span>
<span class="sd">&gt;&gt;&gt;     ...</span>

<span class="sd">The benefit of this batch (aka &quot;chunked&quot;) querying is much better performance.</span>
<span class="sd">To see the speed-up on your machine, run ``python -m gensim.test.simspeed``</span>
<span class="sd">(compare to my results `here &lt;http://groups.google.com/group/gensim/msg/4f6f171a869e4fca?&gt;`_).</span>

<span class="sd">There is also a special syntax for when you need similarity of documents in the index</span>
<span class="sd">to the index itself (i.e. queries=indexed documents themselves). This special syntax</span>
<span class="sd">uses the faster, batch queries internally and **is ideal for all-vs-all pairwise similarities**:</span>

<span class="sd">&gt;&gt;&gt; for similarities in index: # yield similarities of the 1st indexed document, then 2nd...</span>
<span class="sd">&gt;&gt;&gt;     ...</span>

<span class="sd">&quot;&quot;&quot;</span>


<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">heapq</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span>

<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">interfaces</span><span class="p">,</span> <span class="n">utils</span><span class="p">,</span> <span class="n">matutils</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">map</span> <span class="k">as</span> <span class="n">imap</span><span class="p">,</span> <span class="nb">xrange</span><span class="p">,</span> <span class="nb">zip</span> <span class="k">as</span> <span class="n">izip</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="n">PARALLEL_SHARDS</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">multiprocessing</span>
    <span class="c1"># by default, don&#39;t parallelize queries. uncomment the following line if you want that.</span>
<span class="c1">#    PARALLEL_SHARDS = multiprocessing.cpu_count() # use #parallel processes = #CPus</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>


<span class="k">class</span> <span class="nc">Shard</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">SaveLoad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A proxy class that represents a single shard instance within a Similarity</span>
<span class="sd">    index.</span>

<span class="sd">    Basically just wraps (Sparse)MatrixSimilarity so that it mmaps from disk on</span>
<span class="sd">    request (query).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">__class__</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;saving index shard to </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fullname</span><span class="p">())</span>
        <span class="n">index</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fullname</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">fullname</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fname</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># (S)MS objects must be loaded via load() because of mmap (simple pickle.load won&#39;t do)</span>
        <span class="k">if</span> <span class="s1">&#39;index&#39;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> Shard(</span><span class="si">%i</span><span class="s2"> documents in </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">fullname</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">get_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;index&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;mmaping index from </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fullname</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fullname</span><span class="p">(),</span> <span class="n">mmap</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span>

    <span class="k">def</span> <span class="nf">get_document_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return index vector at position `pos`.</span>

<span class="sd">        The vector is of the same type as the underlying index (ie., dense for</span>
<span class="sd">        MatrixSimilarity and scipy.sparse for SparseMatrixSimilarity.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="s2">&quot;requested position out of range&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">index</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span>
            <span class="n">index</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_best and normalize have to be set before querying a proxy Shard object&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">index</span><span class="p">[</span><span class="n">query</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">query_shard</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">query</span><span class="p">,</span> <span class="n">shard</span> <span class="o">=</span> <span class="n">args</span>  <span class="c1"># simulate starmap (not part of multiprocessing in older Pythons)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;querying shard </span><span class="si">%s</span><span class="s2"> num_best=</span><span class="si">%s</span><span class="s2"> in process </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">shard</span><span class="p">,</span> <span class="n">shard</span><span class="o">.</span><span class="n">num_best</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">())</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">shard</span><span class="p">[</span><span class="n">query</span><span class="p">]</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;finished querying shard </span><span class="si">%s</span><span class="s2"> in process </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">shard</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="Similarity"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.html#gensim.similarities.Similarity">[docs]</a><span class="k">class</span> <span class="nc">Similarity</span><span class="p">(</span><span class="n">interfaces</span><span class="o">.</span><span class="n">SimilarityABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute cosine similarity of a dynamic query against a static corpus of documents</span>
<span class="sd">    (&quot;the index&quot;).</span>

<span class="sd">    Scalability is achieved by sharding the index into smaller pieces, each of which</span>
<span class="sd">    fits into core memory (see the `(Sparse)MatrixSimilarity` classes in this module).</span>
<span class="sd">    The shards themselves are simply stored as files to disk and mmap&#39;ed back as needed.</span>

<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Similarity.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.__init__.html#gensim.similarities.Similarity.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_prefix</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">num_best</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shardsize</span><span class="o">=</span><span class="mi">32768</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct the index from `corpus`. The index can be later extended by calling</span>
<span class="sd">        the `add_documents` method. **Note**: documents are split (internally, transparently)</span>
<span class="sd">        into shards of `shardsize` documents each, converted to a matrix, for faster BLAS calls.</span>
<span class="sd">        Each shard is stored to disk under `output_prefix.shard_number` (=you need write</span>
<span class="sd">        access to that location). If you don&#39;t specify an output prefix, a random</span>
<span class="sd">        filename in temp will be used.</span>

<span class="sd">        `shardsize` should be chosen so that a `shardsize x chunksize` matrix of floats</span>
<span class="sd">        fits comfortably into main memory.</span>

<span class="sd">        `num_features` is the number of features in the `corpus` (e.g. size of the</span>
<span class="sd">        dictionary, or the number of latent topics for latent semantic models).</span>

<span class="sd">        `norm` is the user-chosen normalization to use. Accepted values are: &#39;l1&#39; and &#39;l2&#39;.</span>

<span class="sd">        If `num_best` is left unspecified, similarity queries will return a full</span>
<span class="sd">        vector with one float for every document in the index:</span>

<span class="sd">        &gt;&gt;&gt; index = Similarity(&#39;/path/to/index&#39;, corpus, num_features=400) # if corpus has 7 documents...</span>
<span class="sd">        &gt;&gt;&gt; index[query] # ... then result will have 7 floats</span>
<span class="sd">        [0.0, 0.0, 0.2, 0.13, 0.8, 0.0, 0.1]</span>

<span class="sd">        If `num_best` is set, queries return only the `num_best` most similar documents,</span>
<span class="sd">        always leaving out documents for which the similarity is 0.</span>
<span class="sd">        If the input vector itself only has features with zero values (=the sparse</span>
<span class="sd">        representation is empty), the returned list will always be empty.</span>

<span class="sd">        &gt;&gt;&gt; index.num_best = 3</span>
<span class="sd">        &gt;&gt;&gt; index[query] # return at most &quot;num_best&quot; of `(index_of_document, similarity)` tuples</span>
<span class="sd">        [(4, 0.8), (2, 0.13), (3, 0.13)]</span>

<span class="sd">        You can also override `num_best` dynamically, simply by setting e.g.</span>
<span class="sd">        `self.num_best = 10` before doing a query.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">output_prefix</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># undocumented feature: set output_prefix=None to create the server in temp</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">randfname</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;simserver&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">=</span> <span class="n">output_prefix</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;starting similarity index under </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="n">num_best</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunksize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">chunksize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span> <span class="o">=</span> <span class="n">shardsize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span> <span class="o">=</span> <span class="p">[],</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span> <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s2">&quot;Similarity index with </span><span class="si">%i</span><span class="s2"> documents in </span><span class="si">%i</span><span class="s2"> shards (stored under </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span>
                <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">))</span>

<div class="viewcode-block" id="Similarity.add_documents"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.add_documents.html#gensim.similarities.Similarity.add_documents">[docs]</a>    <span class="k">def</span> <span class="nf">add_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extend the index with new documents.</span>

<span class="sd">        Internally, documents are buffered and then spilled to disk when there&#39;s</span>
<span class="sd">        `self.shardsize` of them (or when a query is issued).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">min_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># 0.5 to only reopen shards that are &lt;50% complete</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">min_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span><span class="p">:</span>
            <span class="c1"># The last shard was incomplete (&lt;; load it back and add the documents there, don&#39;t start a new shard</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reopen_shard</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">doclen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
                <span class="n">doclen</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">nnz</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">doclen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">doclen</span> <span class="o">&lt;</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">:</span>
                    <span class="n">doc</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">corpus2csc</span><span class="p">([</span><span class="n">doc</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">doc</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">sparse2full</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span> <span class="o">+=</span> <span class="n">doclen</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">close_shard</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PROGRESS: fresh_shard size=</span><span class="si">%i</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">))</span></div>

<div class="viewcode-block" id="Similarity.shardid2filename"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.shardid2filename.html#gensim.similarities.Similarity.shardid2filename">[docs]</a>    <span class="k">def</span> <span class="nf">shardid2filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shardid</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">,</span> <span class="n">shardid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">,</span> <span class="n">shardid</span><span class="p">)</span></div>

<div class="viewcode-block" id="Similarity.close_shard"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.close_shard.html#gensim.similarities.Similarity.close_shard">[docs]</a>    <span class="k">def</span> <span class="nf">close_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Force the latest shard to close (be converted to a matrix and stored</span>
<span class="sd">        to disk). Do nothing if no new documents added since last call.</span>

<span class="sd">        **NOTE**: the shard is closed even if it is not full yet (its size is smaller</span>
<span class="sd">        than `self.shardsize`). If documents are added later via `add_documents()`,</span>
<span class="sd">        this incomplete shard will be loaded again and completed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">shardid</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">)</span>
        <span class="c1"># consider the shard sparse if its density is &lt; 30%</span>
        <span class="n">issparse</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">&gt;</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">issparse</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">SparseMatrixSimilarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">,</span> <span class="n">num_terms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
                                           <span class="n">num_docs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">),</span> <span class="n">num_nnz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;creating </span><span class="si">%s</span><span class="s2"> shard #</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;sparse&#39;</span> <span class="k">if</span> <span class="n">issparse</span> <span class="k">else</span> <span class="s1">&#39;dense&#39;</span><span class="p">,</span> <span class="n">shardid</span><span class="p">)</span>
        <span class="n">shard</span> <span class="o">=</span> <span class="n">Shard</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shardid2filename</span><span class="p">(</span><span class="n">shardid</span><span class="p">),</span> <span class="n">index</span><span class="p">)</span>
        <span class="n">shard</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span>
        <span class="n">shard</span><span class="o">.</span><span class="n">num_nnz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span> <span class="o">=</span> <span class="p">[],</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="Similarity.reopen_shard"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.reopen_shard.html#gensim.similarities.Similarity.reopen_shard">[docs]</a>    <span class="k">def</span> <span class="nf">reopen_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cannot reopen a shard with fresh documents in index&quot;</span><span class="p">)</span>
        <span class="n">last_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">last_index</span> <span class="o">=</span> <span class="n">last_shard</span><span class="o">.</span><span class="n">get_index</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;reopening an incomplete shard of </span><span class="si">%i</span><span class="s2"> documents&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">last_shard</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fresh_docs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">last_index</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fresh_nnz</span> <span class="o">=</span> <span class="n">last_shard</span><span class="o">.</span><span class="n">num_nnz</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># remove the shard from index, *but its file on disk is not deleted*</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;reopen complete&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Similarity.query_shards"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.query_shards.html#gensim.similarities.Similarity.query_shards">[docs]</a>    <span class="k">def</span> <span class="nf">query_shards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the result of applying shard[query] for each shard in self.shards,</span>
<span class="sd">        as a sequence.</span>

<span class="sd">        If PARALLEL_SHARDS is set, the shards are queried in parallel, using</span>
<span class="sd">        the multiprocessing module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">args</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">([</span><span class="n">query</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">PARALLEL_SHARDS</span> <span class="ow">and</span> <span class="n">PARALLEL_SHARDS</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;spawning </span><span class="si">%i</span><span class="s2"> query processes&quot;</span><span class="p">,</span> <span class="n">PARALLEL_SHARDS</span><span class="p">)</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">PARALLEL_SHARDS</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap</span><span class="p">(</span><span class="n">query_shard</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">/</span> <span class="n">PARALLEL_SHARDS</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># serial processing, one shard after another</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">imap</span><span class="p">(</span><span class="n">query_shard</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pool</span><span class="p">,</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get similarities of document `query` to all documents in the corpus.</span>

<span class="sd">        **or**</span>

<span class="sd">        If `query` is a corpus (iterable of documents), return a matrix of similarities</span>
<span class="sd">        of all query documents vs. all corpus document. This batch query is more</span>
<span class="sd">        efficient than computing the similarities one document after another.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close_shard</span><span class="p">()</span>  <span class="c1"># no-op if no documents added to index since last query</span>

        <span class="c1"># reset num_best and normalize parameters, in case they were changed dynamically</span>
        <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">:</span>
            <span class="n">shard</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span>
            <span class="n">shard</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span>

        <span class="c1"># there are 4 distinct code paths, depending on whether input `query` is</span>
        <span class="c1"># a corpus (or numpy/scipy matrix) or a single document, and whether the</span>
        <span class="c1"># similarity result should be a full array or only num_best most similar</span>
        <span class="c1"># documents.</span>
        <span class="n">pool</span><span class="p">,</span> <span class="n">shard_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_shards</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># user asked for all documents =&gt; just stack the sub-results into a single matrix</span>
            <span class="c1"># (works for both corpus / single doc query)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">shard_results</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the following uses a lot of lazy evaluation and (optionally) parallel</span>
            <span class="c1"># processing, to improve query latency and minimize memory footprint.</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">cumsum</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span> <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">])</span>
            <span class="n">convert</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">doc</span><span class="p">,</span> <span class="n">shard_no</span><span class="p">:</span> <span class="p">[(</span><span class="n">doc_index</span> <span class="o">+</span> <span class="n">offsets</span><span class="p">[</span><span class="n">shard_no</span><span class="p">],</span> <span class="n">sim</span><span class="p">)</span>
                                             <span class="k">for</span> <span class="n">doc_index</span><span class="p">,</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]</span>
            <span class="n">is_corpus</span><span class="p">,</span> <span class="n">query</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_corpus</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
            <span class="n">is_corpus</span> <span class="o">=</span> <span class="n">is_corpus</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="s1">&#39;ndim&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">query</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_corpus</span><span class="p">:</span>
                <span class="c1"># user asked for num_best most similar and query is a single doc</span>
                <span class="n">results</span> <span class="o">=</span> <span class="p">(</span><span class="n">convert</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">shard_no</span><span class="p">)</span> <span class="k">for</span> <span class="n">shard_no</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shard_results</span><span class="p">))</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">heapq</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_best</span><span class="p">,</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># the trickiest combination: returning num_best results when query was a corpus</span>
                <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">shard_no</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shard_results</span><span class="p">):</span>
                    <span class="n">shard_result</span> <span class="o">=</span> <span class="p">[</span><span class="n">convert</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">shard_no</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">result</span><span class="p">]</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shard_result</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">parts</span> <span class="ow">in</span> <span class="n">izip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">):</span>
                    <span class="n">merged</span> <span class="o">=</span> <span class="n">heapq</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_best</span><span class="p">,</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">parts</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">merged</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pool</span><span class="p">:</span>
            <span class="c1"># gc doesn&#39;t seem to collect the Pools, eventually leading to</span>
            <span class="c1"># &quot;IOError 24: too many open files&quot;. so let&#39;s terminate it manually.</span>
            <span class="n">pool</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">result</span>

<div class="viewcode-block" id="Similarity.vector_by_id"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.vector_by_id.html#gensim.similarities.Similarity.vector_by_id">[docs]</a>    <span class="k">def</span> <span class="nf">vector_by_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docpos</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return indexed vector corresponding to the document at position `docpos`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close_shard</span><span class="p">()</span>  <span class="c1"># no-op if no documents added to index since last query</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">:</span>
            <span class="n">pos</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">docpos</span> <span class="o">&lt;</span> <span class="n">pos</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span> <span class="ow">or</span> <span class="n">docpos</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">docpos</span> <span class="o">&gt;=</span> <span class="n">pos</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid document position: </span><span class="si">%s</span><span class="s2"> (must be 0 &lt;= x &lt; </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">docpos</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">get_document_id</span><span class="p">(</span><span class="n">docpos</span> <span class="o">-</span> <span class="n">pos</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="Similarity.similarity_by_id"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.similarity_by_id.html#gensim.similarities.Similarity.similarity_by_id">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_by_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docpos</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return similarity of the given document only. `docpos` is the position</span>
<span class="sd">        of the query document within index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_by_id</span><span class="p">(</span><span class="n">docpos</span><span class="p">)</span>
        <span class="n">norm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="bp">False</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">query</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For each index document, compute cosine similarity against all other</span>
<span class="sd">        documents in the index and yield the result.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># turn off query normalization (vectors in the index are already normalized, save some CPU)</span>
        <span class="n">norm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="bp">False</span>

        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_chunks</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">[</span><span class="n">chunk</span><span class="p">]:</span>
                    <span class="k">yield</span> <span class="n">sim</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">chunk</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>  <span class="c1"># restore normalization</span>

<div class="viewcode-block" id="Similarity.iter_chunks"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.iter_chunks.html#gensim.similarities.Similarity.iter_chunks">[docs]</a>    <span class="k">def</span> <span class="nf">iter_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Iteratively yield the index as chunks of documents, each of size &lt;= chunksize.</span>

<span class="sd">        The chunk is returned in its raw form (matrix or sparse matrix slice).</span>
<span class="sd">        The size of the chunk may be smaller than requested; it is up to the caller</span>
<span class="sd">        to check the result for real length, using `chunk.shape[0]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close_shard</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">chunksize</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># if not explicitly specified, use the chunksize from the constructor</span>
            <span class="n">chunksize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chunksize</span>

        <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">:</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">get_index</span><span class="p">()</span><span class="o">.</span><span class="n">index</span>
            <span class="k">for</span> <span class="n">chunk_start</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">chunksize</span><span class="p">):</span>
                <span class="c1"># scipy.sparse doesn&#39;t allow slicing beyond real size of the matrix</span>
                <span class="c1"># (unlike numpy). so, clip the end of the chunk explicitly to make</span>
                <span class="c1"># scipy.sparse happy</span>
                <span class="n">chunk_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">chunk_start</span> <span class="o">+</span> <span class="n">chunksize</span><span class="p">)</span>
                <span class="n">chunk</span> <span class="o">=</span> <span class="n">query</span><span class="p">[</span><span class="n">chunk_start</span><span class="p">:</span> <span class="n">chunk_end</span><span class="p">]</span>  <span class="c1"># create a view</span>
                <span class="k">yield</span> <span class="n">chunk</span></div>

<div class="viewcode-block" id="Similarity.check_moved"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.check_moved.html#gensim.similarities.Similarity.check_moved">[docs]</a>    <span class="k">def</span> <span class="nf">check_moved</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update shard locations, in case the server directory has moved on filesystem.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dirname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shards</span><span class="p">:</span>
            <span class="n">shard</span><span class="o">.</span><span class="n">dirname</span> <span class="o">=</span> <span class="n">dirname</span></div>

<div class="viewcode-block" id="Similarity.save"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.save.html#gensim.similarities.Similarity.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the object via pickling (also see load) under filename specified in</span>
<span class="sd">        the constructor.</span>

<span class="sd">        Calls `close_shard` internally to spill any unfinished shards to disk first.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close_shard</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">fname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Similarity</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Similarity.destroy"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.Similarity.destroy.html#gensim.similarities.Similarity.destroy">[docs]</a>    <span class="k">def</span> <span class="nf">destroy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Delete all files under self.output_prefix. Object is not usable after calling</span>
<span class="sd">        this method anymore. Use with care!</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">glob</span>
        <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;deleting </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span></div></div>
<span class="c1">#endclass Similarity</span>


<div class="viewcode-block" id="MatrixSimilarity"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.MatrixSimilarity.html#gensim.similarities.MatrixSimilarity">[docs]</a><span class="k">class</span> <span class="nc">MatrixSimilarity</span><span class="p">(</span><span class="n">interfaces</span><span class="o">.</span><span class="n">SimilarityABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute similarity against a corpus of documents by storing the index matrix</span>
<span class="sd">    in memory. The similarity measure used is cosine between two vectors.</span>

<span class="sd">    Use this if your input corpus contains dense vectors (such as documents in LSI</span>
<span class="sd">    space) and fits into RAM.</span>

<span class="sd">    The matrix is internally stored as a *dense* numpy array. Unless the entire matrix</span>
<span class="sd">    fits into main memory, use `Similarity` instead.</span>

<span class="sd">    See also `Similarity` and `SparseMatrixSimilarity` in this module.</span>

<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="MatrixSimilarity.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.MatrixSimilarity.__init__.html#gensim.similarities.MatrixSimilarity.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">num_best</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">corpus_len</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        `num_features` is the number of features in the corpus (will be determined</span>
<span class="sd">        automatically by scanning the corpus if not specified). See `Similarity`</span>
<span class="sd">        class for description of the other parameters.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_features</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;scanning corpus to determine the number of features (consider setting `num_features` explicitly)&quot;</span><span class="p">)</span>
            <span class="n">num_features</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_max_id</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="n">num_best</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunksize</span> <span class="o">=</span> <span class="n">chunksize</span>
        <span class="k">if</span> <span class="n">corpus_len</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">corpus_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cannot index a corpus with zero features (you must specify either `num_features` or a non-empty corpus in the constructor)&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;creating matrix with </span><span class="si">%i</span><span class="s2"> documents and </span><span class="si">%i</span><span class="s2"> features&quot;</span><span class="p">,</span> <span class="n">corpus_len</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">corpus_len</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="c1"># iterate over corpus, populating the numpy index matrix with (normalized)</span>
            <span class="c1"># document vectors</span>
            <span class="k">for</span> <span class="n">docno</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">docno</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;PROGRESS: at document #</span><span class="si">%i</span><span class="s2">/</span><span class="si">%i</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">docno</span><span class="p">,</span> <span class="n">corpus_len</span><span class="p">)</span>
                <span class="c1"># individual documents in fact may be in numpy.scipy.sparse format as well.</span>
                <span class="c1"># it&#39;s not documented because other it&#39;s not fully supported throughout.</span>
                <span class="c1"># the user better know what he&#39;s doing (no normalization, must</span>
                <span class="c1"># explicitly supply num_features etc).</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="k">pass</span>
                <span class="k">elif</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
                    <span class="n">vector</span> <span class="o">=</span> <span class="n">vector</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">vector</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">sparse2full</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">docno</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector</span></div>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="MatrixSimilarity.get_similarities"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.MatrixSimilarity.get_similarities.html#gensim.similarities.MatrixSimilarity.get_similarities">[docs]</a>    <span class="k">def</span> <span class="nf">get_similarities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return similarity of sparse vector `query` to all documents in the corpus,</span>
<span class="sd">        as a numpy array.</span>

<span class="sd">        If `query` is a collection of documents, return a 2D array of similarities</span>
<span class="sd">        of each document in `query` to all documents in the corpus (=batch query,</span>
<span class="sd">        faster than processing each document in turn).</span>

<span class="sd">        **Do not use this function directly; use the self[query] syntax instead.**</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">is_corpus</span><span class="p">,</span> <span class="n">query</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_corpus</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_corpus</span><span class="p">:</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                <span class="p">[</span><span class="n">matutils</span><span class="o">.</span><span class="n">sparse2full</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span> <span class="k">for</span> <span class="n">vec</span> <span class="ow">in</span> <span class="n">query</span><span class="p">],</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>  <span class="c1"># convert sparse to dense</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># default case: query is a single vector in sparse gensim format</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">sparse2full</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># do a little transposition dance to stop numpy from making a copy of</span>
        <span class="c1"># self.index internally in numpy.dot (very slow).</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># return #queries x #index</span>
        <span class="k">return</span> <span class="n">result</span>  <span class="c1"># XXX: removed casting the result from array to list; does anyone care?</span></div>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&lt;</span><span class="si">%i</span><span class="s2"> docs, </span><span class="si">%i</span><span class="s2"> features&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>
<span class="c1">#endclass MatrixSimilarity</span>

<div class="viewcode-block" id="WmdSimilarity"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.WmdSimilarity.html#gensim.similarities.WmdSimilarity">[docs]</a><span class="k">class</span> <span class="nc">WmdSimilarity</span><span class="p">(</span><span class="n">interfaces</span><span class="o">.</span><span class="n">SimilarityABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Document similarity (like MatrixSimilarity) that uses the negative of WMD</span>
<span class="sd">    as a similarity measure. See gensim.models.word2vec.wmdistance for more</span>
<span class="sd">    information.</span>

<span class="sd">    When a `num_best` value is provided, only the most similar documents are</span>
<span class="sd">    retrieved.</span>

<span class="sd">    When using this code, please consider citing the following papers:</span>

<span class="sd">    .. Ofir Pele and Michael Werman, &quot;A linear time histogram metric for improved SIFT matching&quot;.</span>
<span class="sd">    .. Ofir Pele and Michael Werman, &quot;Fast and robust earth mover&#39;s distances&quot;.</span>
<span class="sd">    .. Matt Kusner et al. &quot;From Word Embeddings To Document Distances&quot;.</span>

<span class="sd">    Example:</span>
<span class="sd">        # See Tutorial Notebook for more examples https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/WMD_tutorial.ipynb</span>
<span class="sd">        &gt;&gt;&gt; # Given a document collection &quot;corpus&quot;, train word2vec model.</span>
<span class="sd">        &gt;&gt;&gt; model = word2vec(corpus)</span>
<span class="sd">        &gt;&gt;&gt; instance = WmdSimilarity(corpus, model, num_best=10)</span>

<span class="sd">        &gt;&gt;&gt; # Make query.</span>
<span class="sd">        &gt;&gt;&gt; query = &#39;Very good, you should seat outdoor.&#39;</span>
<span class="sd">        &gt;&gt;&gt; sims = instance[query]</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="WmdSimilarity.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.WmdSimilarity.__init__.html#gensim.similarities.WmdSimilarity.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">w2v_model</span><span class="p">,</span> <span class="n">num_best</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">normalize_w2v_and_replace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        corpus:                         List of lists of strings, as in gensim.models.word2vec.</span>
<span class="sd">        w2v_model:                      A trained word2vec model.</span>
<span class="sd">        num_best:                       Number of results to retrieve.</span>
<span class="sd">        normalize_w2v_and_replace:      Whether or not to normalize the word2vec vectors to</span>
<span class="sd">                                        length 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2v_model</span> <span class="o">=</span> <span class="n">w2v_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="n">num_best</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunksize</span> <span class="o">=</span> <span class="n">chunksize</span>

        <span class="c1"># Normalization of features is not possible, as corpus is a list (of lists) of strings.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="c1"># index is simply an array from 0 to size of corpus.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)))</span>

        <span class="k">if</span> <span class="n">normalize_w2v_and_replace</span><span class="p">:</span>
            <span class="c1"># Normalize vectors in word2vec class to length 1.</span>
            <span class="n">w2v_model</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>

<div class="viewcode-block" id="WmdSimilarity.get_similarities"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.WmdSimilarity.get_similarities.html#gensim.similarities.WmdSimilarity.get_similarities">[docs]</a>    <span class="k">def</span> <span class="nf">get_similarities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        **Do not use this function directly; use the self[query] syntax instead.**</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="c1"># Convert document indexes to actual documents.</span>
            <span class="n">query</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">query</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">query</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">query</span> <span class="o">=</span> <span class="p">[</span><span class="n">query</span><span class="p">]</span>

        <span class="n">n_queries</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">qidx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_queries</span><span class="p">):</span>
            <span class="c1"># Compute similarity for each query.</span>
            <span class="n">qresult</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">wmdistance</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="n">query</span><span class="p">[</span><span class="n">qidx</span><span class="p">])</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">]</span>
            <span class="n">qresult</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">qresult</span><span class="p">)</span>
            <span class="n">qresult</span> <span class="o">=</span> <span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">qresult</span><span class="p">)</span>  <span class="c1"># Similarity is the negative of the distance.</span>

            <span class="c1"># Append single query result to list of all results.</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qresult</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Only one query.</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&lt;</span><span class="si">%i</span><span class="s2"> docs, </span><span class="si">%i</span><span class="s2"> features&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2v_model</span><span class="o">.</span><span class="n">syn0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>
<span class="c1">#endclass WmdSimilarity</span>

<div class="viewcode-block" id="SparseMatrixSimilarity"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.SparseMatrixSimilarity.html#gensim.similarities.SparseMatrixSimilarity">[docs]</a><span class="k">class</span> <span class="nc">SparseMatrixSimilarity</span><span class="p">(</span><span class="n">interfaces</span><span class="o">.</span><span class="n">SimilarityABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute similarity against a corpus of documents by storing the sparse index</span>
<span class="sd">    matrix in memory. The similarity measure used is cosine between two vectors.</span>

<span class="sd">    Use this if your input corpus contains sparse vectors (such as documents in</span>
<span class="sd">    bag-of-words format) and fits into RAM.</span>

<span class="sd">    The matrix is internally stored as a `scipy.sparse.csr` matrix. Unless the entire</span>
<span class="sd">    matrix fits into main memory, use `Similarity` instead.</span>

<span class="sd">    Takes an optional `maintain_sparsity` argument, setting this to True</span>
<span class="sd">    causes `get_similarities` to return a sparse matrix instead of a</span>
<span class="sd">    dense representation if possible.</span>

<span class="sd">    See also `Similarity` and `MatrixSimilarity` in this module.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="SparseMatrixSimilarity.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.SparseMatrixSimilarity.__init__.html#gensim.similarities.SparseMatrixSimilarity.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_terms</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_docs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_nnz</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">num_best</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">maintain_sparsity</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_best</span> <span class="o">=</span> <span class="n">num_best</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunksize</span> <span class="o">=</span> <span class="n">chunksize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maintain_sparsity</span> <span class="o">=</span> <span class="n">maintain_sparsity</span>

        <span class="k">if</span> <span class="n">corpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;creating sparse index&quot;</span><span class="p">)</span>

            <span class="c1"># iterate over input corpus, populating the sparse index matrix</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># use the more efficient corpus generation version, if the input</span>
                <span class="c1"># `corpus` is MmCorpus-like (knows its shape and number of non-zeroes).</span>
                <span class="n">num_terms</span><span class="p">,</span> <span class="n">num_docs</span><span class="p">,</span> <span class="n">num_nnz</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">num_terms</span><span class="p">,</span> <span class="n">corpus</span><span class="o">.</span><span class="n">num_docs</span><span class="p">,</span> <span class="n">corpus</span><span class="o">.</span><span class="n">num_nnz</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;using efficient sparse index creation&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="c1"># no MmCorpus, use the slower version (or maybe user supplied the</span>
                <span class="c1"># num_* params in constructor)</span>
                <span class="k">pass</span>
            <span class="k">if</span> <span class="n">num_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="c1"># num_terms is just an alias for num_features, for compatibility with MatrixSimilarity</span>
                <span class="n">num_terms</span> <span class="o">=</span> <span class="n">num_features</span>
            <span class="k">if</span> <span class="n">num_terms</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;refusing to guess the number of sparse features: specify num_features explicitly&quot;</span><span class="p">)</span>
            <span class="n">corpus</span> <span class="o">=</span> <span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">scipy2sparse</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">else</span>
                      <span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">full2sparse</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span>
                       <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">corpus2csc</span><span class="p">(</span>
                <span class="n">corpus</span><span class="p">,</span> <span class="n">num_terms</span><span class="o">=</span><span class="n">num_terms</span><span class="p">,</span> <span class="n">num_docs</span><span class="o">=</span><span class="n">num_docs</span><span class="p">,</span> <span class="n">num_nnz</span><span class="o">=</span><span class="n">num_nnz</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">printprogress</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

            <span class="c1"># convert to Compressed Sparse Row for efficient row slicing and multiplications</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>  <span class="c1"># currently no-op, CSC.T is already CSR</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;created </span><span class="si">%r</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="SparseMatrixSimilarity.get_similarities"><a class="viewcode-back" href="../../../generated/generated/gensim.similarities.SparseMatrixSimilarity.get_similarities.html#gensim.similarities.SparseMatrixSimilarity.get_similarities">[docs]</a>    <span class="k">def</span> <span class="nf">get_similarities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return similarity of sparse vector `query` to all documents in the corpus,</span>
<span class="sd">        as a numpy array.</span>

<span class="sd">        If `query` is a collection of documents, return a 2D array of similarities</span>
<span class="sd">        of each document in `query` to all documents in the corpus (=batch query,</span>
<span class="sd">        faster than processing each document in turn).</span>

<span class="sd">        **Do not use this function directly; use the self[query] syntax instead.**</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">is_corpus</span><span class="p">,</span> <span class="n">query</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_corpus</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_corpus</span><span class="p">:</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">corpus2csc</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># convert documents=rows to documents=columns</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">query</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">query</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># default case: query is a single vector, in sparse gensim format</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">corpus2csc</span><span class="p">([</span><span class="n">query</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># compute cosine similarity against every other document in the collection</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">*</span> <span class="n">query</span><span class="o">.</span><span class="n">tocsc</span><span class="p">()</span>  <span class="c1"># N x T * T x C = N x C</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_corpus</span><span class="p">:</span>
            <span class="c1"># for queries of one document, return a 1d array</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">maintain_sparsity</span><span class="p">:</span>
            <span class="c1"># avoid converting to dense array if maintaining sparsity</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># otherwise, return a 2d matrix (#queries x #index)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">result</span></div></div>
<span class="c1">#endclass SparseMatrixSimilarity</span>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>