

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>gensim.models.doc2vec</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="gensim.models" href="../models.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../gensim.html">gensim</a> &raquo;</li>
        
          <li><a href="../models.html">gensim.models</a> &raquo;</li>
        
      <li>gensim.models.doc2vec</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for gensim.models.doc2vec</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2013 Radim Rehurek &lt;me@radimrehurek.com&gt;</span>
<span class="c1"># Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Deep learning via the distributed memory and distributed bag of words models from</span>
<span class="sd">[1]_, using either hierarchical softmax or negative sampling [2]_ [3]_.</span>

<span class="sd">**Make sure you have a C compiler before installing gensim, to use optimized (compiled)</span>
<span class="sd">doc2vec training** (70x speedup [blog]_).</span>

<span class="sd">Initialize a model with e.g.::</span>

<span class="sd">&gt;&gt;&gt; model = Doc2Vec(documents, size=100, window=8, min_count=5, workers=4)</span>

<span class="sd">Persist a model to disk with::</span>

<span class="sd">&gt;&gt;&gt; model.save(fname)</span>
<span class="sd">&gt;&gt;&gt; model = Doc2Vec.load(fname)  # you can continue training with the loaded model!</span>

<span class="sd">The model can also be instantiated from an existing file on disk in the word2vec C format::</span>

<span class="sd">  &gt;&gt;&gt; model = Doc2Vec.load_word2vec_format(&#39;/tmp/vectors.txt&#39;, binary=False)  # C text format</span>
<span class="sd">  &gt;&gt;&gt; model = Doc2Vec.load_word2vec_format(&#39;/tmp/vectors.bin&#39;, binary=True)  # C binary format</span>

<span class="sd">.. [1] Quoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents. http://arxiv.org/pdf/1405.4053v2.pdf</span>
<span class="sd">.. [2] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.</span>
<span class="sd">.. [3] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. Distributed Representations of Words and Phrases and their Compositionality.</span>
<span class="sd">       In Proceedings of NIPS, 2013.</span>
<span class="sd">.. [blog] Optimizing word2vec in gensim, http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">queue</span> <span class="kn">import</span> <span class="n">Queue</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">Queue</span> <span class="kn">import</span> <span class="n">Queue</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span>

<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">random</span><span class="p">,</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">np_sum</span><span class="p">,</span> <span class="n">add</span> <span class="k">as</span> <span class="n">np_add</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> \
    <span class="n">repeat</span> <span class="k">as</span> <span class="n">np_repeat</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">float32</span> <span class="k">as</span> <span class="n">REAL</span><span class="p">,</span> <span class="n">empty</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">memmap</span> <span class="k">as</span> <span class="n">np_memmap</span><span class="p">,</span> \
    <span class="n">sqrt</span><span class="p">,</span> <span class="n">newaxis</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">dot</span><span class="p">,</span> <span class="n">vstack</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">divide</span> <span class="k">as</span> <span class="n">np_divide</span>

<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">matutils</span>  <span class="c1"># utility fnc for pickling, common scipy operations etc</span>
<span class="kn">from</span> <span class="nn">gensim.models.word2vec</span> <span class="kn">import</span> <span class="n">Word2Vec</span><span class="p">,</span> <span class="n">Vocab</span><span class="p">,</span> <span class="n">train_cbow_pair</span><span class="p">,</span> <span class="n">train_sg_pair</span><span class="p">,</span> <span class="n">train_batch_sg</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">xrange</span><span class="p">,</span> <span class="nb">zip</span>
<span class="kn">from</span> <span class="nn">six</span> <span class="kn">import</span> <span class="n">string_types</span><span class="p">,</span> <span class="n">integer_types</span><span class="p">,</span> <span class="n">itervalues</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">gensim.models.doc2vec_inner</span> <span class="kn">import</span> <span class="n">train_document_dbow</span><span class="p">,</span> <span class="n">train_document_dm</span><span class="p">,</span> <span class="n">train_document_dm_concat</span>
    <span class="kn">from</span> <span class="nn">gensim.models.word2vec_inner</span> <span class="kn">import</span> <span class="n">FAST_VERSION</span>  <span class="c1"># blas-adaptation shared from word2vec</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Fast version of {0} is being used&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">__name__</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Slow version of {0} is being used&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">__name__</span><span class="p">))</span>
    <span class="c1"># failed... fall back to plain numpy (20-80x slower training than the above)</span>
    <span class="n">FAST_VERSION</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">def</span> <span class="nf">train_document_dbow</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                            <span class="n">train_words</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">learn_doctags</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_words</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">word_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">word_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update distributed bag of words model (&quot;PV-DBOW&quot;) by training on a single document.</span>

<span class="sd">        Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.</span>

<span class="sd">        The document is provided as `doc_words`, a list of word tokens which are looked up</span>
<span class="sd">        in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span>
<span class="sd">        into the doctag_vectors array.</span>

<span class="sd">        If `train_words` is True, simultaneously train word-to-word (not just doc-to-word)</span>
<span class="sd">        examples, exactly as per Word2Vec skip-gram training. (Without this option,</span>
<span class="sd">        word vectors are neither consulted nor updated during DBOW doc vector training.)</span>

<span class="sd">        Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span>
<span class="sd">        prevent learning-updates to those respective model weights, as if using the</span>
<span class="sd">        (partially-)frozen model to infer other compatible vectors.</span>

<span class="sd">        This is the non-optimized, Python version. If you have cython installed, gensim</span>
<span class="sd">        will use the optimized version from doc2vec_inner instead.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">doctag_vectors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0</span>
        <span class="k">if</span> <span class="n">doctag_locks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_locks</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span>

        <span class="k">if</span> <span class="n">train_words</span> <span class="ow">and</span> <span class="n">learn_words</span><span class="p">:</span>
            <span class="n">train_batch_sg</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">doc_words</span><span class="p">],</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">doctag_index</span> <span class="ow">in</span> <span class="n">doctag_indexes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc_words</span><span class="p">:</span>
                <span class="n">train_sg_pair</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">doctag_index</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">learn_vectors</span><span class="o">=</span><span class="n">learn_doctags</span><span class="p">,</span>
                              <span class="n">learn_hidden</span><span class="o">=</span><span class="n">learn_hidden</span><span class="p">,</span> <span class="n">context_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span>
                              <span class="n">context_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc_words</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_document_dm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">neu1</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                          <span class="n">learn_doctags</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_words</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                          <span class="n">word_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">word_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update distributed memory model (&quot;PV-DM&quot;) by training on a single document.</span>

<span class="sd">        Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`. This</span>
<span class="sd">        method implements the DM model with a projection (input) layer that is</span>
<span class="sd">        either the sum or mean of the context vectors, depending on the model&#39;s</span>
<span class="sd">        `dm_mean` configuration field.  See `train_document_dm_concat()` for the DM</span>
<span class="sd">        model with a concatenated input layer.</span>

<span class="sd">        The document is provided as `doc_words`, a list of word tokens which are looked up</span>
<span class="sd">        in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span>
<span class="sd">        into the doctag_vectors array.</span>

<span class="sd">        Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span>
<span class="sd">        prevent learning-updates to those respective model weights, as if using the</span>
<span class="sd">        (partially-)frozen model to infer other compatible vectors.</span>

<span class="sd">        This is the non-optimized, Python version. If you have a C compiler, gensim</span>
<span class="sd">        will use the optimized version from doc2vec_inner instead.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">word_vectors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">word_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">syn0</span>
        <span class="k">if</span> <span class="n">word_locks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">word_locks</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">syn0_lockf</span>
        <span class="k">if</span> <span class="n">doctag_vectors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0</span>
        <span class="k">if</span> <span class="n">doctag_locks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_locks</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span>

        <span class="n">word_vocabs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">doc_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab</span> <span class="ow">and</span>
                       <span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">sample_int</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">pos</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vocabs</span><span class="p">):</span>
            <span class="n">reduced_window</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">window</span><span class="p">)</span>  <span class="c1"># `b` in the original doc2vec code</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pos</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">window</span> <span class="o">+</span> <span class="n">reduced_window</span><span class="p">)</span>
            <span class="n">window_pos</span> <span class="o">=</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vocabs</span><span class="p">[</span><span class="n">start</span><span class="p">:(</span><span class="n">pos</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">window</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">reduced_window</span><span class="p">)],</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">word2_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">word2</span><span class="o">.</span><span class="n">index</span> <span class="k">for</span> <span class="n">pos2</span><span class="p">,</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">window_pos</span> <span class="k">if</span> <span class="n">pos2</span> <span class="o">!=</span> <span class="n">pos</span><span class="p">]</span>
            <span class="n">l1</span> <span class="o">=</span> <span class="n">np_sum</span><span class="p">(</span><span class="n">word_vectors</span><span class="p">[</span><span class="n">word2_indexes</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">np_sum</span><span class="p">(</span><span class="n">doctag_vectors</span><span class="p">[</span><span class="n">doctag_indexes</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2_indexes</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">doctag_indexes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">cbow_mean</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span>
                <span class="n">l1</span> <span class="o">/=</span> <span class="n">count</span>
            <span class="n">neu1e</span> <span class="o">=</span> <span class="n">train_cbow_pair</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">word2_indexes</span><span class="p">,</span> <span class="n">l1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                    <span class="n">learn_vectors</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="n">learn_hidden</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">cbow_mean</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">neu1e</span> <span class="o">/=</span> <span class="n">count</span>
            <span class="k">if</span> <span class="n">learn_doctags</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">doctag_indexes</span><span class="p">:</span>
                    <span class="n">doctag_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">neu1e</span> <span class="o">*</span> <span class="n">doctag_locks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">learn_words</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word2_indexes</span><span class="p">:</span>
                    <span class="n">word_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">neu1e</span> <span class="o">*</span> <span class="n">word_locks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_vocabs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_document_dm_concat</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">neu1</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                 <span class="n">learn_doctags</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_words</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                 <span class="n">word_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">word_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_vectors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update distributed memory model (&quot;PV-DM&quot;) by training on a single document, using a</span>
<span class="sd">        concatenation of the context window word vectors (rather than a sum or average).</span>

<span class="sd">        Called internally from `Doc2Vec.train()` and `Doc2Vec.infer_vector()`.</span>

<span class="sd">        The document is provided as `doc_words`, a list of word tokens which are looked up</span>
<span class="sd">        in the model&#39;s vocab dictionary, and `doctag_indexes`, which provide indexes</span>
<span class="sd">        into the doctag_vectors array.</span>

<span class="sd">        Any of `learn_doctags&#39;, `learn_words`, and `learn_hidden` may be set False to</span>
<span class="sd">        prevent learning-updates to those respective model weights, as if using the</span>
<span class="sd">        (partially-)frozen model to infer other compatible vectors.</span>

<span class="sd">        This is the non-optimized, Python version. If you have a C compiler, gensim</span>
<span class="sd">        will use the optimized version from doc2vec_inner instead.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">word_vectors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">word_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">syn0</span>
        <span class="k">if</span> <span class="n">word_locks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">word_locks</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">syn0_lockf</span>
        <span class="k">if</span> <span class="n">doctag_vectors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0</span>
        <span class="k">if</span> <span class="n">doctag_locks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">doctag_locks</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span>

        <span class="n">word_vocabs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">doc_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab</span> <span class="ow">and</span>
                       <span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="o">.</span><span class="n">sample_int</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">]</span>
        <span class="n">doctag_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">doctag_indexes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">doctag_len</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">dm_tag_count</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>  <span class="c1"># skip doc without expected number of doctag(s) (TODO: warn/pad?)</span>

        <span class="n">null_word</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;</span><span class="se">\0</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="n">pre_pad_count</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">window</span>
        <span class="n">post_pad_count</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">window</span>
        <span class="n">padded_document_indexes</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">pre_pad_count</span> <span class="o">*</span> <span class="p">[</span><span class="n">null_word</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>  <span class="c1"># pre-padding</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">index</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_vocabs</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>  <span class="c1"># elide out-of-Vocabulary words</span>
            <span class="o">+</span> <span class="p">(</span><span class="n">post_pad_count</span> <span class="o">*</span> <span class="p">[</span><span class="n">null_word</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>  <span class="c1"># post-padding</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pre_pad_count</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">padded_document_indexes</span><span class="p">)</span> <span class="o">-</span> <span class="n">post_pad_count</span><span class="p">):</span>
            <span class="n">word_context_indexes</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">padded_document_indexes</span><span class="p">[(</span><span class="n">pos</span> <span class="o">-</span> <span class="n">pre_pad_count</span><span class="p">):</span> <span class="n">pos</span><span class="p">]</span>  <span class="c1"># preceding words</span>
                <span class="o">+</span> <span class="n">padded_document_indexes</span><span class="p">[(</span><span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):(</span><span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">post_pad_count</span><span class="p">)]</span>  <span class="c1"># following words</span>
            <span class="p">)</span>
            <span class="n">word_context_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_context_indexes</span><span class="p">)</span>
            <span class="n">predict_word</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">padded_document_indexes</span><span class="p">[</span><span class="n">pos</span><span class="p">]]]</span>
            <span class="c1"># numpy advanced-indexing copies; concatenate, flatten to 1d</span>
            <span class="n">l1</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">doctag_vectors</span><span class="p">[</span><span class="n">doctag_indexes</span><span class="p">],</span> <span class="n">word_vectors</span><span class="p">[</span><span class="n">word_context_indexes</span><span class="p">]))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="n">neu1e</span> <span class="o">=</span> <span class="n">train_cbow_pair</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">predict_word</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">l1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                    <span class="n">learn_hidden</span><span class="o">=</span><span class="n">learn_hidden</span><span class="p">,</span> <span class="n">learn_vectors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

            <span class="c1"># filter by locks and shape for addition to source vectors</span>
            <span class="n">e_locks</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">doctag_locks</span><span class="p">[</span><span class="n">doctag_indexes</span><span class="p">],</span> <span class="n">word_locks</span><span class="p">[</span><span class="n">word_context_indexes</span><span class="p">]))</span>
            <span class="n">neu1e_r</span> <span class="o">=</span> <span class="p">(</span><span class="n">neu1e</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vector_size</span><span class="p">)</span>
                       <span class="o">*</span> <span class="n">np_repeat</span><span class="p">(</span><span class="n">e_locks</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vector_size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vector_size</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">learn_doctags</span><span class="p">:</span>
                <span class="n">np_add</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">neu1e_r</span><span class="p">[:</span><span class="n">doctag_len</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">learn_words</span><span class="p">:</span>
                <span class="n">np_add</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">word_vectors</span><span class="p">,</span> <span class="n">word_context_indexes</span><span class="p">,</span> <span class="n">neu1e_r</span><span class="p">[</span><span class="n">doctag_len</span><span class="p">:])</span>

        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">padded_document_indexes</span><span class="p">)</span> <span class="o">-</span> <span class="n">pre_pad_count</span> <span class="o">-</span> <span class="n">post_pad_count</span>


<span class="k">class</span> <span class="nc">TaggedDocument</span><span class="p">(</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;TaggedDocument&#39;</span><span class="p">,</span> <span class="s1">&#39;words tags&#39;</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A single document, made up of `words` (a list of unicode string tokens)</span>
<span class="sd">    and `tags` (a list of tokens). Tags may be one or more unicode string</span>
<span class="sd">    tokens, but typical practice (which will also be most memory-efficient) is</span>
<span class="sd">    for the tags list to include a unique integer id as the only tag.</span>

<span class="sd">    Replaces &quot;sentence as a list of words&quot; from Word2Vec.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(</span><span class="si">%s</span><span class="s1">, </span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">words</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tags</span><span class="p">)</span>


<span class="c1"># for compatibility</span>
<span class="k">class</span> <span class="nc">LabeledSentence</span><span class="p">(</span><span class="n">TaggedDocument</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;LabeledSentence has been replaced by TaggedDocument&#39;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DocvecsArray</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">SaveLoad</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Default storage of doc vectors during/after training, in a numpy array.</span>

<span class="sd">    As the &#39;docvecs&#39; property of a Doc2Vec model, allows access and</span>
<span class="sd">    comparison of document vectors.</span>

<span class="sd">    &gt;&gt;&gt; docvec = d2v_model.docvecs[99]</span>
<span class="sd">    &gt;&gt;&gt; docvec = d2v_model.docvecs[&#39;SENT_99&#39;]  # if string tag used in training</span>
<span class="sd">    &gt;&gt;&gt; sims = d2v_model.docvecs.most_similar(99)</span>
<span class="sd">    &gt;&gt;&gt; sims = d2v_model.docvecs.most_similar(&#39;SENT_99&#39;)</span>
<span class="sd">    &gt;&gt;&gt; sims = d2v_model.docvecs.most_similar(docvec)</span>

<span class="sd">    If only plain int tags are presented during training, the dict (of</span>
<span class="sd">    string tag -&gt; index) and list (of index -&gt; string tag) stay empty,</span>
<span class="sd">    saving memory.</span>

<span class="sd">    Supplying a mapfile_path (as by initializing a Doc2Vec model with a</span>
<span class="sd">    &#39;docvecs_mapfile&#39; value) will use a pair of memory-mapped</span>
<span class="sd">    files as the array backing for doctag_syn0/doctag_syn0_lockf values.</span>

<span class="sd">    The Doc2Vec model automatically uses this class, but a future alternative</span>
<span class="sd">    implementation, based on another persistence mechanism like LMDB, LevelDB,</span>
<span class="sd">    or SQLite, should also be possible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mapfile_path</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># string -&gt; Doctag (only filled if necessary)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># highest rawint-indexed doctag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># int offset-past-(max_rawint+1) -&gt; String (only filled if necessary)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span> <span class="o">=</span> <span class="n">mapfile_path</span>

    <span class="k">def</span> <span class="nf">note_doctag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">document_no</span><span class="p">,</span> <span class="n">document_length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Note a document tag during initial corpus scan, for structure sizing.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">document_length</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Doctag</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="p">),</span> <span class="n">document_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">indexed_doctags</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doctag_tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return indexes and backing-arrays used in training examples.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_int_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">doctag_tokens</span> <span class="k">if</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span><span class="p">,</span> <span class="n">doctag_tokens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">trained_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexed_tuple</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Persist any changes made to the given indexes (matching tuple previously</span>
<span class="sd">        returned by indexed_doctags()); a no-op for this implementation&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_int_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return int index for either string or int index&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">index</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">offset</span>

    <span class="k">def</span> <span class="nf">_key_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i_index</span><span class="p">,</span> <span class="n">missing</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return string index for given int index, if available&quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;use DocvecsArray.index_to_doctag&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_to_doctag</span><span class="p">(</span><span class="n">i_index</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">index_to_doctag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return string key for given i_index, if available. Otherwise return raw int doctag (same int).&quot;&quot;&quot;</span>
        <span class="n">candidate_offset</span> <span class="o">=</span> <span class="n">i_index</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rawint</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">candidate_offset</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="p">[</span><span class="n">candidate_offset</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">i_index</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Accept a single key (int or string tag) or list of keys as input.</span>

<span class="sd">        If a single string or int, return designated tag&#39;s vector</span>
<span class="sd">        representation, as a 1D numpy array.</span>

<span class="sd">        If a list, return designated tags&#39; vector representations as a</span>
<span class="sd">        2D numpy array: #tags x #vector_size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">string_types</span> <span class="o">+</span> <span class="p">(</span><span class="nb">int</span><span class="p">,)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_int_index</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">index</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span>

    <span class="k">def</span> <span class="nf">borrow_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other_docvecs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="n">other_docvecs</span><span class="o">.</span><span class="n">count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span> <span class="o">=</span> <span class="n">other_docvecs</span><span class="o">.</span><span class="n">doctags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span> <span class="o">=</span> <span class="n">other_docvecs</span><span class="o">.</span><span class="n">offset2doctag</span>

    <span class="k">def</span> <span class="nf">clear_sims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">estimated_lookup_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimated memory for tag lookup; 0 if using pure int tags.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">60</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset2doctag</span><span class="p">)</span> <span class="o">+</span> <span class="mi">140</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctags</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span> <span class="o">=</span> <span class="n">np_memmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span><span class="o">+</span><span class="s1">&#39;.doctag_syn0&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">,</span>
                                         <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vector_size</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span> <span class="o">=</span> <span class="n">np_memmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span><span class="o">+</span><span class="s1">&#39;.doctag_syn0_lockf&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">,</span>
                                               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">length</span><span class="p">,))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="n">length</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vector_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0_lockf</span> <span class="o">=</span> <span class="n">ones</span><span class="p">((</span><span class="n">length</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>  <span class="c1"># zeros suppress learning</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
            <span class="c1"># construct deterministic seed from index AND model seed</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_to_doctag</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">seeded_vector</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_sims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Precompute L2-normalized vectors.</span>

<span class="sd">        If `replace` is set, forget the original vectors and only keep the normalized</span>
<span class="sd">        ones = saves lots of memory!</span>

<span class="sd">        Note that you **cannot continue training or inference** after doing a replace.</span>
<span class="sd">        The model becomes effectively read-only = you can call `most_similar`, `similarity`</span>
<span class="sd">        etc., but not `train` or `infer_vector`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;doctag_syn0norm&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">replace</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;precomputing L2-norms of doc weight vectors&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">replace</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/=</span> <span class="n">sqrt</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span> <span class="o">=</span> <span class="n">np_memmap</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">mapfile_path</span><span class="o">+</span><span class="s1">&#39;.doctag_syn0norm&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span> <span class="o">=</span> <span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>
                <span class="n">np_divide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="n">newaxis</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">most_similar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positive</span><span class="o">=</span><span class="p">[],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">clip_start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">clip_end</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">indexer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find the top-N most similar docvecs known from training. Positive docs contribute</span>
<span class="sd">        positively towards the similarity, negative docs negatively.</span>

<span class="sd">        This method computes cosine similarity between a simple mean of the projection</span>
<span class="sd">        weight vectors of the given docs. Docs may be specified as vectors, integer indexes</span>
<span class="sd">        of trained docvecs, or if the documents were originally presented with string tags,</span>
<span class="sd">        by the corresponding tags.</span>

<span class="sd">        The &#39;clip_start&#39; and &#39;clip_end&#39; allow limiting results to a particular contiguous</span>
<span class="sd">        range of the underlying doctag_syn0norm vectors. (This may be useful if the ordering</span>
<span class="sd">        there was chosen to be significant, such as more popular tag IDs in lower indexes.)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_sims</span><span class="p">()</span>
        <span class="n">clip_end</span> <span class="o">=</span> <span class="n">clip_end</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">string_types</span> <span class="o">+</span> <span class="n">integer_types</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">negative</span><span class="p">:</span>
            <span class="c1"># allow calls like most_similar(&#39;dog&#39;), as a shorthand for most_similar([&#39;dog&#39;])</span>
            <span class="n">positive</span> <span class="o">=</span> <span class="p">[</span><span class="n">positive</span><span class="p">]</span>

        <span class="c1"># add weights for each doc, if not already present; default to 1.0 for positive and -1.0 for negative docs</span>
        <span class="n">positive</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">string_types</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndarray</span><span class="p">,)</span> <span class="o">+</span> <span class="n">integer_types</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">positive</span>
        <span class="p">]</span>
        <span class="n">negative</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">string_types</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndarray</span><span class="p">,)</span> <span class="o">+</span> <span class="n">integer_types</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">negative</span>
        <span class="p">]</span>

        <span class="c1"># compute the weighted average of all docs</span>
        <span class="n">all_docs</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(),</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">positive</span> <span class="o">+</span> <span class="n">negative</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">):</span>
                <span class="n">mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="n">doc</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">doc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span> <span class="ow">or</span> <span class="n">doc</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">:</span>
                <span class="n">mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_int_index</span><span class="p">(</span><span class="n">doc</span><span class="p">)])</span>
                <span class="n">all_docs</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_int_index</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;doc &#39;</span><span class="si">%s</span><span class="s2">&#39; not in trained set&quot;</span> <span class="o">%</span> <span class="n">doc</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mean</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cannot compute similarity with no input&quot;</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">REAL</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">indexer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">indexer</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">topn</span><span class="p">)</span>

        <span class="n">dists</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span><span class="p">[</span><span class="n">clip_start</span><span class="p">:</span><span class="n">clip_end</span><span class="p">],</span> <span class="n">mean</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">topn</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dists</span>
        <span class="n">best</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="n">topn</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_docs</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># ignore (don&#39;t return) docs from the input</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">index_to_doctag</span><span class="p">(</span><span class="n">sim</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">dists</span><span class="p">[</span><span class="n">sim</span><span class="p">]))</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">best</span> <span class="k">if</span> <span class="n">sim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_docs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">[:</span><span class="n">topn</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">doesnt_match</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Which doc from the given list doesn&#39;t go with the others?</span>

<span class="sd">        (TODO: Accept vectors of out-of-training-set docs, as if from inference.)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_sims</span><span class="p">()</span>

        <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span> <span class="k">if</span> <span class="n">doc</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">doctags</span> <span class="ow">or</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">doc</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">]</span>  <span class="c1"># filter out unknowns</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;using docs </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">docs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">docs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cannot select a doc from an empty list&quot;</span><span class="p">)</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="n">vstack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">doctag_syn0norm</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_int_index</span><span class="p">(</span><span class="n">doc</span><span class="p">)]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">REAL</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">REAL</span><span class="p">)</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">docs</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cosine similarity between two docvecs in the trained set, specified by int index or</span>
<span class="sd">        string tag. (TODO: Accept vectors of out-of-training-set docs, as if from inference.)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">d1</span><span class="p">]),</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">d2</span><span class="p">]))</span>

    <span class="k">def</span> <span class="nf">n_similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ds1</span><span class="p">,</span> <span class="n">ds2</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cosine similarity between two sets of docvecs from the trained set, specified by int</span>
<span class="sd">        index or string tag. (TODO: Accept vectors of out-of-training-set docs, as if from inference.)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">v1</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">ds1</span><span class="p">]</span>
        <span class="n">v2</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">ds2</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">similarity_unseen_docs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">doc_words1</span><span class="p">,</span> <span class="n">doc_words2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute cosine similarity between two post-bulk out of training documents.</span>

<span class="sd">        Document should be a list of (word) tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_vector</span><span class="p">(</span><span class="n">doc_words</span><span class="o">=</span><span class="n">doc_words1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="n">min_alpha</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_vector</span><span class="p">(</span><span class="n">doc_words</span><span class="o">=</span><span class="n">doc_words2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="n">min_alpha</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">d1</span><span class="p">),</span> <span class="n">matutils</span><span class="o">.</span><span class="n">unitvec</span><span class="p">(</span><span class="n">d2</span><span class="p">))</span>
        
        
<span class="k">class</span> <span class="nc">Doctag</span><span class="p">(</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Doctag&#39;</span><span class="p">,</span> <span class="s1">&#39;offset, word_count, doc_count&#39;</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;A string document tag discovered during the initial vocabulary</span>
<span class="sd">    scan. (The document-vector equivalent of a Vocab object.)</span>

<span class="sd">    Will not be used if all presented document tags are ints.</span>

<span class="sd">    The offset is only the true index into the doctags_syn0/doctags_syn0_lockf</span>
<span class="sd">    if-and-only-if no raw-int tags were used. If any raw-int tags were used,</span>
<span class="sd">    string Doctag vectors begin at index (max_rawint + 1), so the true index is</span>
<span class="sd">    (rawint_index + 1 + offset). See also DocvecsArray.index_to_doctag().</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">__slots__</span> <span class="o">=</span> <span class="p">()</span>

    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">word_count</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">word_count</span> <span class="o">+</span> <span class="n">word_count</span><span class="p">,</span> <span class="n">doc_count</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">doc_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>


<div class="viewcode-block" id="Doc2Vec"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.html#gensim.models.Doc2Vec">[docs]</a><span class="k">class</span> <span class="nc">Doc2Vec</span><span class="p">(</span><span class="n">Word2Vec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Class for training, using and evaluating neural networks described in http://arxiv.org/pdf/1405.4053v2.pdf&quot;&quot;&quot;</span>
<div class="viewcode-block" id="Doc2Vec.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.__init__.html#gensim.models.Doc2Vec.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="n">max_vocab_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span>
                 <span class="n">dm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">negative</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dbow_words</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dm_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dm_concat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dm_tag_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">docvecs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">docvecs_mapfile</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">comment</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">trim_rule</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the model from an iterable of `documents`. Each document is a</span>
<span class="sd">        TaggedDocument object that will be used for training.</span>

<span class="sd">        The `documents` iterable can be simply a list of TaggedDocument elements, but for larger corpora,</span>
<span class="sd">        consider an iterable that streams the documents directly from disk/network.</span>

<span class="sd">        If you don&#39;t supply `documents`, the model is left uninitialized -- use if</span>
<span class="sd">        you plan to initialize it in some other way.</span>

<span class="sd">        `dm` defines the training algorithm. By default (`dm=1`), &#39;distributed memory&#39; (PV-DM) is used.</span>
<span class="sd">        Otherwise, `distributed bag of words` (PV-DBOW) is employed.</span>

<span class="sd">        `size` is the dimensionality of the feature vectors.</span>

<span class="sd">        `window` is the maximum distance between the predicted word and context words used for prediction</span>
<span class="sd">        within a document.</span>

<span class="sd">        `alpha` is the initial learning rate (will linearly drop to zero as training progresses).</span>

<span class="sd">        `seed` = for the random number generator. </span>
<span class="sd">        Note that for a fully deterministically-reproducible run, you must also limit the model to</span>
<span class="sd">        a single worker thread, to eliminate ordering jitter from OS thread scheduling. (In Python</span>
<span class="sd">        3, reproducibility between interpreter launches also requires use of the PYTHONHASHSEED</span>
<span class="sd">        environment variable to control hash randomization.)</span>

<span class="sd">        `min_count` = ignore all words with total frequency lower than this.</span>

<span class="sd">        `max_vocab_size` = limit RAM during vocabulary building; if there are more unique</span>
<span class="sd">        words than this, then prune the infrequent ones. Every 10 million word types</span>
<span class="sd">        need about 1GB of RAM. Set to `None` for no limit (default).</span>

<span class="sd">        `sample` = threshold for configuring which higher-frequency words are randomly downsampled;</span>
<span class="sd">                default is 0 (off), useful value is 1e-5.</span>

<span class="sd">        `workers` = use this many worker threads to train the model (=faster training with multicore machines).</span>

<span class="sd">        `iter` = number of iterations (epochs) over the corpus. The default inherited from Word2Vec is 5, </span>
<span class="sd">        but values of 10 or 20 are common in published &#39;Paragraph Vector&#39; experiments.</span>

<span class="sd">        `hs` = if 1 (default), hierarchical sampling will be used for model training (else set to 0).</span>

<span class="sd">        `negative` = if &gt; 0, negative sampling will be used, the int for negative</span>
<span class="sd">        specifies how many &quot;noise words&quot; should be drawn (usually between 5-20).</span>

<span class="sd">        `dm_mean` = if 0 (default), use the sum of the context word vectors. If 1, use the mean.</span>
<span class="sd">        Only applies when dm is used in non-concatenative mode.</span>

<span class="sd">        `dm_concat` = if 1, use concatenation of context vectors rather than sum/average;</span>
<span class="sd">        default is 0 (off). Note concatenation results in a much-larger model, as the input</span>
<span class="sd">        is no longer the size of one (sampled or arithmatically combined) word vector, but the</span>
<span class="sd">        size of the tag(s) and all words in the context strung together.</span>

<span class="sd">        `dm_tag_count` = expected constant number of document tags per document, when using</span>
<span class="sd">        dm_concat mode; default is 1.</span>

<span class="sd">        `dbow_words` if set to 1 trains word-vectors (in skip-gram fashion) simultaneous with DBOW</span>
<span class="sd">        doc-vector training; default is 0 (faster training of doc-vectors only).</span>

<span class="sd">        `trim_rule` = vocabulary trimming rule, specifies whether certain words should remain</span>
<span class="sd">         in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count).</span>
<span class="sd">         Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and</span>
<span class="sd">         returns either util.RULE_DISCARD, util.RULE_KEEP or util.RULE_DEFAULT.</span>
<span class="sd">         Note: The rule, if given, is only used prune vocabulary during build_vocab() and is not stored as part</span>
<span class="sd">          of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Doc2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">window</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="n">min_count</span><span class="p">,</span> <span class="n">max_vocab_size</span><span class="o">=</span><span class="n">max_vocab_size</span><span class="p">,</span>
            <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="n">min_alpha</span><span class="p">,</span>
            <span class="n">sg</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">dm</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hs</span><span class="o">=</span><span class="n">hs</span><span class="p">,</span> <span class="n">negative</span><span class="o">=</span><span class="n">negative</span><span class="p">,</span> <span class="n">cbow_mean</span><span class="o">=</span><span class="n">dm_mean</span><span class="p">,</span>
            <span class="n">null_word</span><span class="o">=</span><span class="n">dm_concat</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dbow_words</span> <span class="o">=</span> <span class="n">dbow_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span> <span class="o">=</span> <span class="n">dm_concat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dm_tag_count</span> <span class="o">=</span> <span class="n">dm_tag_count</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dm_tag_count</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span> <span class="o">=</span> <span class="n">docvecs</span> <span class="ow">or</span> <span class="n">DocvecsArray</span><span class="p">(</span><span class="n">docvecs_mapfile</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comment</span> <span class="o">=</span> <span class="n">comment</span>
        <span class="k">if</span> <span class="n">documents</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">trim_rule</span><span class="o">=</span><span class="n">trim_rule</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span>  <span class="c1"># opposite of SG</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dbow</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span>  <span class="c1"># same as SG</span>

<div class="viewcode-block" id="Doc2Vec.clear_sims"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.clear_sims.html#gensim.models.Doc2Vec.clear_sims">[docs]</a>    <span class="k">def</span> <span class="nf">clear_sims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Doc2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">clear_sims</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">clear_sims</span><span class="p">()</span></div>

<div class="viewcode-block" id="Doc2Vec.reset_weights"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.reset_weights.html#gensim.models.Doc2Vec.reset_weights">[docs]</a>    <span class="k">def</span> <span class="nf">reset_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span><span class="p">:</span>
            <span class="c1"># expand l1 size to match concatenated tags+words length</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dm_tag_count</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_size</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;using concatenative </span><span class="si">%d</span><span class="s2">-dimensional layer1&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Doc2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">reset_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">reset_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="Doc2Vec.reset_from"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.reset_from.html#gensim.models.Doc2Vec.reset_from">[docs]</a>    <span class="k">def</span> <span class="nf">reset_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other_model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reuse shareable structures from other_model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">borrow_from</span><span class="p">(</span><span class="n">other_model</span><span class="o">.</span><span class="n">docvecs</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Doc2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">reset_from</span><span class="p">(</span><span class="n">other_model</span><span class="p">)</span></div>

<div class="viewcode-block" id="Doc2Vec.scan_vocab"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.scan_vocab.html#gensim.models.Doc2Vec.scan_vocab">[docs]</a>    <span class="k">def</span> <span class="nf">scan_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">progress_per</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">trim_rule</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;collecting all words and their counts&quot;</span><span class="p">)</span>
        <span class="n">document_no</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">total_words</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">min_reduce</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">interval_start</span> <span class="o">=</span> <span class="n">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.00001</span>  <span class="c1"># guard against next sample being identical</span>
        <span class="n">interval_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">checked_string_types</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">document_no</span><span class="p">,</span> <span class="n">document</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">documents</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">checked_string_types</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">document</span><span class="o">.</span><span class="n">words</span><span class="p">,</span> <span class="n">string_types</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Each &#39;words&#39; should be a list of words (usually unicode strings).&quot;</span>
                                <span class="s2">&quot;First &#39;words&#39; here is instead plain </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">document</span><span class="o">.</span><span class="n">words</span><span class="p">))</span>
                <span class="n">checked_string_types</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">document_no</span> <span class="o">%</span> <span class="n">progress_per</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">interval_rate</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_words</span> <span class="o">-</span> <span class="n">interval_count</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">interval_start</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PROGRESS: at example #</span><span class="si">%i</span><span class="s2">, processed </span><span class="si">%i</span><span class="s2"> words (</span><span class="si">%i</span><span class="s2">/s), </span><span class="si">%i</span><span class="s2"> word types, </span><span class="si">%i</span><span class="s2"> tags&quot;</span><span class="p">,</span>
                            <span class="n">document_no</span><span class="p">,</span> <span class="n">total_words</span><span class="p">,</span> <span class="n">interval_rate</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="p">))</span>
                <span class="n">interval_start</span> <span class="o">=</span> <span class="n">default_timer</span><span class="p">()</span>
                <span class="n">interval_count</span> <span class="o">=</span> <span class="n">total_words</span>
            <span class="n">document_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">document</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">tags</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">note_doctag</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">document_no</span><span class="p">,</span> <span class="n">document_length</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">words</span><span class="p">:</span>
                <span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">total_words</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">document</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_vocab_size</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_vocab_size</span><span class="p">:</span>
                <span class="n">utils</span><span class="o">.</span><span class="n">prune_vocab</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">min_reduce</span><span class="p">,</span> <span class="n">trim_rule</span><span class="o">=</span><span class="n">trim_rule</span><span class="p">)</span>
                <span class="n">min_reduce</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;collected </span><span class="si">%i</span><span class="s2"> word types and </span><span class="si">%i</span><span class="s2"> unique tags from a corpus of </span><span class="si">%i</span><span class="s2"> examples and </span><span class="si">%i</span><span class="s2"> words&quot;</span><span class="p">,</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="p">),</span> <span class="n">document_no</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">total_words</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corpus_count</span> <span class="o">=</span> <span class="n">document_no</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">raw_vocab</span> <span class="o">=</span> <span class="n">vocab</span></div>

    <span class="k">def</span> <span class="nf">_do_train_job</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">job</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">inits</span><span class="p">):</span>
        <span class="n">work</span><span class="p">,</span> <span class="n">neu1</span> <span class="o">=</span> <span class="n">inits</span>
        <span class="n">tally</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">job</span><span class="p">:</span>
            <span class="n">indexed_doctags</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">indexed_doctags</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">tags</span><span class="p">)</span>
            <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">indexed_doctags</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span><span class="p">:</span>
                <span class="n">tally</span> <span class="o">+=</span> <span class="n">train_document_dbow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span>
                                             <span class="n">train_words</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dbow_words</span><span class="p">,</span>
                                             <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span><span class="p">:</span>
                <span class="n">tally</span> <span class="o">+=</span> <span class="n">train_document_dm_concat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span> <span class="n">neu1</span><span class="p">,</span>
                                                  <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tally</span> <span class="o">+=</span> <span class="n">train_document_dm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span> <span class="n">neu1</span><span class="p">,</span>
                                           <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">trained_item</span><span class="p">(</span><span class="n">indexed_doctags</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tally</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_word_count</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_raw_word_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">job</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of words in a given job.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">words</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">job</span><span class="p">)</span>

<div class="viewcode-block" id="Doc2Vec.infer_vector"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.infer_vector.html#gensim.models.Doc2Vec.infer_vector">[docs]</a>    <span class="k">def</span> <span class="nf">infer_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Infer a vector for given post-bulk training document.</span>

<span class="sd">        Document should be a list of (word) tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">doctag_vectors</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>
        <span class="n">doctag_vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seeded_vector</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc_words</span><span class="p">))</span>
        <span class="n">doctag_locks</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>
        <span class="n">doctag_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">work</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span><span class="p">:</span>
            <span class="n">neu1</span> <span class="o">=</span> <span class="n">matutils</span><span class="o">.</span><span class="n">zeros_aligned</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">REAL</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span><span class="p">:</span>
                <span class="n">train_document_dbow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span>
                                    <span class="n">learn_words</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                    <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span><span class="p">:</span>
                <span class="n">train_document_dm_concat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span> <span class="n">neu1</span><span class="p">,</span>
                                         <span class="n">learn_words</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                         <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">train_document_dm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_words</span><span class="p">,</span> <span class="n">doctag_indexes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span> <span class="n">neu1</span><span class="p">,</span>
                                  <span class="n">learn_words</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">learn_hidden</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                  <span class="n">doctag_vectors</span><span class="o">=</span><span class="n">doctag_vectors</span><span class="p">,</span> <span class="n">doctag_locks</span><span class="o">=</span><span class="n">doctag_locks</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="p">((</span><span class="n">alpha</span> <span class="o">-</span> <span class="n">min_alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">steps</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span> <span class="o">+</span> <span class="n">min_alpha</span>

        <span class="k">return</span> <span class="n">doctag_vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="Doc2Vec.estimate_memory"><a class="viewcode-back" href="../../../generated/generated/gensim.models.Doc2Vec.estimate_memory.html#gensim.models.Doc2Vec.estimate_memory">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate required memory for a model using current settings.&quot;&quot;&quot;</span>
        <span class="n">report</span> <span class="o">=</span> <span class="n">report</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">report</span><span class="p">[</span><span class="s1">&#39;doctag_lookup&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">estimated_lookup_memory</span><span class="p">()</span>
        <span class="n">report</span><span class="p">[</span><span class="s1">&#39;doctag_syn0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">count</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_size</span> <span class="o">*</span> <span class="n">dtype</span><span class="p">(</span><span class="n">REAL</span><span class="p">)</span><span class="o">.</span><span class="n">itemsize</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Doc2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">estimate_memory</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="n">report</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Abbreviated name reflecting major configuration paramaters.&quot;&quot;&quot;</span>
        <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">comment</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot;&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">comment</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbow_words</span><span class="p">:</span>
                <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;dbow+w&#39;</span><span class="p">)</span>  <span class="c1"># also training words</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;dbow&#39;</span><span class="p">)</span>  <span class="c1"># PV-DBOW (skip-gram-style)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># PV-DM...</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dm_concat</span><span class="p">:</span>
                <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;dm/c&#39;</span><span class="p">)</span>  <span class="c1"># ...with concatenative context layer</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cbow_mean</span><span class="p">:</span>
                    <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;dm/m&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;dm/s&#39;</span><span class="p">)</span>
        <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;d</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_size</span><span class="p">)</span>  <span class="c1"># dimensions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;n</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative</span><span class="p">)</span>  <span class="c1"># negative samples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hs</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;hs&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sg</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbow_words</span><span class="p">):</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;w</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">)</span>  <span class="c1"># window size, when relevant</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_count</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;mc</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_count</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;s</span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">segments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;t</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">segments</span><span class="p">))</span></div>


<span class="k">class</span> <span class="nc">TaggedBrownCorpus</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Iterate over documents from the Brown corpus (part of NLTK data), yielding</span>
<span class="sd">    each document out as a TaggedDocument object.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dirname</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dirname</span> <span class="o">=</span> <span class="n">dirname</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">):</span>
            <span class="n">fname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dirname</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">for</span> <span class="n">item_no</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">smart_open</span><span class="p">(</span><span class="n">fname</span><span class="p">)):</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_unicode</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                <span class="c1"># each file line is a single document in the Brown corpus</span>
                <span class="c1"># each token is WORD/POS_TAG</span>
                <span class="n">token_tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">))</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span>
                <span class="c1"># ignore words with non-alphabetic tags like &quot;,&quot;, &quot;!&quot; etc (punctuation, weird stuff)</span>
                <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">tag</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">token_tags</span> <span class="k">if</span> <span class="n">tag</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">words</span><span class="p">:</span>  <span class="c1"># don&#39;t bother sending out empty documents</span>
                    <span class="k">continue</span>
                <span class="k">yield</span> <span class="n">TaggedDocument</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_SENT_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">item_no</span><span class="p">)])</span>


<span class="k">class</span> <span class="nc">TaggedLineDocument</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simple format: one document = one line = one TaggedDocument object.</span>

<span class="sd">    Words are expected to be already preprocessed and separated by whitespace,</span>
<span class="sd">    tags are constructed automatically from the document line number.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        `source` can be either a string (filename) or a file object.</span>

<span class="sd">        Example::</span>

<span class="sd">            documents = TaggedLineDocument(&#39;myfile.txt&#39;)</span>

<span class="sd">        Or for compressed files::</span>

<span class="sd">            documents = TaggedLineDocument(&#39;compressed_text.txt.bz2&#39;)</span>
<span class="sd">            documents = TaggedLineDocument(&#39;compressed_text.txt.gz&#39;)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Iterate through the lines in the source.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Assume it is a file-like object and try treating it as such</span>
            <span class="c1"># Things that don&#39;t have seek will trigger an exception</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">item_no</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">TaggedDocument</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">to_unicode</span><span class="p">(</span><span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="p">[</span><span class="n">item_no</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="c1"># If it didn&#39;t work like a file, use it as a string filename</span>
            <span class="k">with</span> <span class="n">utils</span><span class="o">.</span><span class="n">smart_open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">item_no</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fin</span><span class="p">):</span>
                    <span class="k">yield</span> <span class="n">TaggedDocument</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">to_unicode</span><span class="p">(</span><span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="p">[</span><span class="n">item_no</span><span class="p">])</span>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>