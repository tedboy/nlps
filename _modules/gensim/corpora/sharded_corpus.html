

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>gensim.corpora.sharded_corpus</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../../../index.html"/>
        <link rel="up" title="gensim" href="../../gensim.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> NLP APIs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gensim_tutorial/tutorial.html">Gensim Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nltk_intro.html">Natural Language Toolkit</a></li>
</ul>
<p class="caption"><span class="caption-text">Autogenerated API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.html"><code class="docutils literal"><span class="pre">nltk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.html"><code class="docutils literal"><span class="pre">gensim</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.interfaces.html"><code class="docutils literal"><span class="pre">gensim.interfaces</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.matutils.html"><code class="docutils literal"><span class="pre">gensim.matutils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.utils.html"><code class="docutils literal"><span class="pre">gensim.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.corpora.html"><code class="docutils literal"><span class="pre">gensim.corpora</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.models.html"><code class="docutils literal"><span class="pre">gensim.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.parsing.html"><code class="docutils literal"><span class="pre">gensim.parsing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.scripts.html"><code class="docutils literal"><span class="pre">gensim.scripts</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.similarities.html"><code class="docutils literal"><span class="pre">gensim.similarities</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.summarization.html"><code class="docutils literal"><span class="pre">gensim.summarization</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/gensim.topic_coherence.html"><code class="docutils literal"><span class="pre">gensim.topic_coherence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/simserver.html"><code class="docutils literal"><span class="pre">simserver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/word2vec.html"><code class="docutils literal"><span class="pre">word2vec</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/stop_words.html"><code class="docutils literal"><span class="pre">stop_words</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.classify.html"><code class="docutils literal"><span class="pre">nltk.classify</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generated/nltk.cluster.html"><code class="docutils literal"><span class="pre">nltk.cluster</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NLP APIs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../gensim.html">gensim</a> &raquo;</li>
        
      <li>gensim.corpora.sharded_corpus</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for gensim.corpora.sharded_corpus</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#</span>
<span class="c1"># Original author: Jan Hajic jr.</span>
<span class="c1"># Copyright (C) 2015 Radim Rehurek and gensim team.</span>
<span class="c1"># Licensed under the GNU LGPL v2.1 - http://www.gnu.org/licenses/lgpl.html</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module implements a corpus class that stores its data in separate files called</span>
<span class="sd">&quot;shards&quot;. This is a compromise between speed (keeping the whole dataset</span>
<span class="sd">in memory) and memory footprint (keeping the data on disk and reading from it</span>
<span class="sd">on demand).</span>

<span class="sd">The corpus is intended for situations where you need to use your data</span>
<span class="sd">as numpy arrays for some iterative processing (like training something</span>
<span class="sd">using SGD, which usually involves heavy matrix multiplication).</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="kn">as</span> <span class="nn">sparse</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="c1">#: Specifies which dtype should be used for serializing the shards.</span>
<span class="n">_default_dtype</span> <span class="o">=</span> <span class="nb">float</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">theano</span>
    <span class="n">_default_dtype</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Could not import Theano, will use standard float for default ShardedCorpus dtype.&#39;</span><span class="p">)</span>


<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">xrange</span>

<span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">from</span> <span class="nn">gensim.corpora</span> <span class="kn">import</span> <span class="n">IndexedCorpus</span>
<span class="kn">from</span> <span class="nn">gensim.interfaces</span> <span class="kn">import</span> <span class="n">TransformedCorpus</span>


<div class="viewcode-block" id="ShardedCorpus"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.html#gensim.corpora.ShardedCorpus">[docs]</a><span class="k">class</span> <span class="nc">ShardedCorpus</span><span class="p">(</span><span class="n">IndexedCorpus</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This corpus is designed for situations where you need to train a model</span>
<span class="sd">    on matrices, with a large number of iterations. (It should be faster than</span>
<span class="sd">    gensim&#39;s other IndexedCorpus implementations for this use case; check the</span>
<span class="sd">    `benchmark_datasets.py` script. It should also serialize faster.)</span>

<span class="sd">    The corpus stores its data in separate files called</span>
<span class="sd">    &quot;shards&quot;. This is a compromise between speed (keeping the whole dataset</span>
<span class="sd">    in memory) and memory footprint (keeping the data on disk and reading from</span>
<span class="sd">    it on demand). Persistence is done using the standard gensim load/save methods.</span>

<span class="sd">    .. note::</span>

<span class="sd">      The dataset is **read-only**, there is - as opposed to gensim&#39;s Similarity</span>
<span class="sd">      class, which works similarly - no way of adding documents to the dataset</span>
<span class="sd">      (for now).</span>

<span class="sd">    You can use ShardedCorpus to serialize your data just like any other gensim</span>
<span class="sd">    corpus that implements serialization. However, because the data is saved</span>
<span class="sd">    as numpy 2-dimensional ndarrays (or scipy sparse matrices), you need to</span>
<span class="sd">    supply the dimension of your data to the corpus. (The dimension of word</span>
<span class="sd">    frequency vectors will typically be the size of the vocabulary, etc.)</span>

<span class="sd">    &gt;&gt;&gt; corpus = gensim.utils.mock_data()</span>
<span class="sd">    &gt;&gt;&gt; output_prefix = &#39;mydata.shdat&#39;</span>
<span class="sd">    &gt;&gt;&gt; ShardedCorpus.serialize(output_prefix, corpus, dim=1000)</span>

<span class="sd">    The `output_prefix` tells the ShardedCorpus where to put the data.</span>
<span class="sd">    Shards are saved as `output_prefix.0`, `output_prefix.1`, etc.</span>
<span class="sd">    All shards must be of the same size. The shards can be re-sized (which</span>
<span class="sd">    is essentially a re-serialization into new-size shards), but note that</span>
<span class="sd">    this operation will temporarily take twice as much disk space, because</span>
<span class="sd">    the old shards are not deleted until the new shards are safely in place.</span>

<span class="sd">    After serializing the data, the corpus will then save itself to the file</span>
<span class="sd">    `output_prefix`.</span>

<span class="sd">    On further initialization with the same `output_prefix`, the corpus</span>
<span class="sd">    will load the already built dataset unless the `overwrite` option is</span>
<span class="sd">    given. (A new object is &quot;cloned&quot; from the one saved to `output_prefix`</span>
<span class="sd">    previously.)</span>

<span class="sd">    To retrieve data, you can load the corpus and use it like a list:</span>

<span class="sd">    &gt;&gt;&gt; sh_corpus = ShardedCorpus.load(output_prefix)</span>
<span class="sd">    &gt;&gt;&gt; batch = sh_corpus[100:150]</span>

<span class="sd">    This will retrieve a numpy 2-dimensional array of 50 rows and 1000</span>
<span class="sd">    columns (1000 was the dimension of the data we supplied to the corpus).</span>
<span class="sd">    To retrieve gensim-style sparse vectors, set the `gensim` property:</span>

<span class="sd">    &gt;&gt;&gt; sh_corpus.gensim = True</span>
<span class="sd">    &gt;&gt;&gt; batch = sh_corpus[100:150]</span>

<span class="sd">    The batch now will be a generator of gensim vectors.</span>

<span class="sd">    Since the corpus needs the data serialized in order to be able to operate,</span>
<span class="sd">    it will serialize data right away on initialization. Instead of calling</span>
<span class="sd">    `ShardedCorpus.serialize()`, you can just initialize and use the corpus</span>
<span class="sd">    right away:</span>

<span class="sd">    &gt;&gt;&gt; corpus = ShardedCorpus(output_prefix, corpus, dim=1000)</span>
<span class="sd">    &gt;&gt;&gt; batch = corpus[100:150]</span>

<span class="sd">    ShardedCorpus also supports working with scipy sparse matrices, both</span>
<span class="sd">    during retrieval and during serialization. If you want to serialize your</span>
<span class="sd">    data as sparse matrices, set the `sparse_serialization` flag. For</span>
<span class="sd">    retrieving your data as sparse matrices, use the `sparse_retrieval`</span>
<span class="sd">    flag. (You can also retrieve densely serialized data as sparse matrices,</span>
<span class="sd">    for the sake of completeness, and vice versa.) By default, the corpus</span>
<span class="sd">    will retrieve numpy ndarrays even if it was serialized into sparse</span>
<span class="sd">    matrices.</span>

<span class="sd">    &gt;&gt;&gt; sparse_prefix = &#39;mydata.sparse.shdat&#39;</span>
<span class="sd">    &gt;&gt;&gt; ShardedCorpus.serialize(sparse_prefix, corpus, dim=1000, sparse_serialization=True)</span>
<span class="sd">    &gt;&gt;&gt; sparse_corpus = ShardedCorpus.load(sparse_prefix)</span>
<span class="sd">    &gt;&gt;&gt; batch = sparse_corpus[100:150]</span>
<span class="sd">    &gt;&gt;&gt; type(batch)</span>
<span class="sd">    &lt;type &#39;numpy.ndarray&#39;&gt;</span>
<span class="sd">    &gt;&gt;&gt; sparse_corpus.sparse_retrieval = True</span>
<span class="sd">    &gt;&gt;&gt; batch = sparse_corpus[100:150]</span>
<span class="sd">    &lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;</span>

<span class="sd">    While you *can* touch the `sparse_retrieval` attribute during the life</span>
<span class="sd">    of a ShardedCorpus object, you should definitely not touch `</span>
<span class="sd">    `sharded_serialization`! Changing the attribute will not miraculously</span>
<span class="sd">    re-serialize the data in the requested format.</span>

<span class="sd">    The CSR format is used for sparse data throughout.</span>

<span class="sd">    Internally, to retrieve data, the dataset keeps track of which shard is</span>
<span class="sd">    currently open and on a `__getitem__` request, either returns an item from</span>
<span class="sd">    the current shard, or opens a new one. The shard size is constant, except</span>
<span class="sd">    for the last shard.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="ShardedCorpus.__init__"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.__init__.html#gensim.corpora.ShardedCorpus.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_prefix</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">shardsize</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">sparse_serialization</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">sparse_retrieval</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">gensim</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initializes the dataset. If `output_prefix` is not found,</span>
<span class="sd">        builds the shards.</span>

<span class="sd">        :type output_prefix: str</span>
<span class="sd">        :param output_prefix: The absolute path to the file from which shard</span>
<span class="sd">            filenames should be derived. The individual shards will be saved</span>
<span class="sd">            as `output_prefix.0`, `output_prefix.1`, etc.</span>

<span class="sd">            The `output_prefix` path then works as the filename to which</span>
<span class="sd">            the ShardedCorpus object itself will be automatically saved.</span>
<span class="sd">            Normally, gensim corpora do not do this, but ShardedCorpus needs</span>
<span class="sd">            to remember several serialization settings: namely the shard</span>
<span class="sd">            size and whether it was serialized in dense or sparse format. By</span>
<span class="sd">            saving automatically, any new ShardedCorpus with the same</span>
<span class="sd">            `output_prefix` will be able to find the information about the</span>
<span class="sd">            data serialized with the given prefix.</span>

<span class="sd">            If you want to *overwrite* your data serialized with some output</span>
<span class="sd">            prefix, set the `overwrite` flag to True.</span>

<span class="sd">            Of course, you can save your corpus separately as well using</span>
<span class="sd">            the `save()` method.</span>

<span class="sd">        :type corpus: gensim.interfaces.CorpusABC</span>
<span class="sd">        :param corpus: The source corpus from which to build the dataset.</span>

<span class="sd">        :type dim: int</span>
<span class="sd">        :param dim: Specify beforehand what the dimension of a dataset item</span>
<span class="sd">            should be. This is useful when initializing from a corpus that</span>
<span class="sd">            doesn&#39;t advertise its dimension, or when it does and you want to</span>
<span class="sd">            check that the corpus matches the expected dimension. **If `dim`</span>
<span class="sd">            is left unused and `corpus` does not provide its dimension in</span>
<span class="sd">            an expected manner, initialization will fail.**</span>

<span class="sd">        :type shardsize: int</span>
<span class="sd">        :param shardsize: How many data points should be in one shard. More</span>
<span class="sd">            data per shard means less shard reloading but higher memory usage</span>
<span class="sd">            and vice versa.</span>

<span class="sd">        :type overwrite: bool</span>
<span class="sd">        :param overwrite: If set, will build dataset from given corpus even</span>
<span class="sd">            if `output_prefix` already exists.</span>

<span class="sd">        :type sparse_serialization: bool</span>
<span class="sd">        :param sparse_serialization: If set, will save the data in a sparse</span>
<span class="sd">            form (as csr matrices). This is to speed up retrieval when you</span>
<span class="sd">            know you will be using sparse matrices.</span>

<span class="sd">            ..note::</span>

<span class="sd">                This property **should not change** during the lifetime of</span>
<span class="sd">                the dataset. (If you find out you need to change from a sparse</span>
<span class="sd">                to a dense representation, the best practice is to create</span>
<span class="sd">                another ShardedCorpus object.)</span>

<span class="sd">        :type sparse_retrieval: bool</span>
<span class="sd">        :param sparse_retrieval: If set, will retrieve data as sparse vectors</span>
<span class="sd">            (numpy csr matrices). If unset, will return ndarrays.</span>

<span class="sd">            Note that retrieval speed for this option depends on how the dataset</span>
<span class="sd">            was serialized. If `sparse_serialization` was set, then setting</span>
<span class="sd">            `sparse_retrieval` will be faster. However, if the two settings</span>
<span class="sd">            do not correspond, the conversion on the fly will slow the dataset</span>
<span class="sd">            down.</span>

<span class="sd">        :type gensim: bool</span>
<span class="sd">        :param gensim: If set, will convert the output to gensim</span>
<span class="sd">            sparse vectors (list of tuples (id, value)) to make it behave like</span>
<span class="sd">            any other gensim corpus. This **will** slow the dataset down.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">=</span> <span class="n">output_prefix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span> <span class="o">=</span> <span class="n">shardsize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>  <span class="c1"># This number may change during initialization/loading.</span>

        <span class="c1"># Sparse vs. dense serialization and retrieval.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span> <span class="o">=</span> <span class="n">sparse_serialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse_retrieval</span> <span class="o">=</span> <span class="n">sparse_retrieval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gensim</span> <span class="o">=</span> <span class="n">gensim</span>

        <span class="c1"># The &quot;state&quot; of the dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span> <span class="o">=</span> <span class="bp">None</span>    <span class="c1"># The current shard itself (numpy ndarray)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c1"># Current shard is the current_shard_n-th</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">=</span> <span class="bp">None</span>   <span class="c1"># The index into the dataset which</span>
                                     <span class="c1"># corresponds to index 0 of current shard</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Initializing sharded corpus with prefix &#39;</span>
                     <span class="s1">&#39;{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_prefix</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">output_prefix</span><span class="p">))</span> <span class="ow">or</span> <span class="n">overwrite</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Building from corpus...&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_shards</span><span class="p">(</span><span class="n">output_prefix</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">shardsize</span><span class="p">)</span>

            <span class="c1"># Save automatically, to facilitate re-loading</span>
            <span class="c1"># and retain information about how the corpus</span>
            <span class="c1"># was serialized.</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Saving ShardedCorpus object to &#39;</span>
                         <span class="s1">&#39;{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Cloning existing...&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_by_clone</span><span class="p">()</span></div>

<div class="viewcode-block" id="ShardedCorpus.init_shards"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.init_shards.html#gensim.corpora.ShardedCorpus.init_shards">[docs]</a>    <span class="k">def</span> <span class="nf">init_shards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_prefix</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">shardsize</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_default_dtype</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize shards from the corpus.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">gensim</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">is_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot initialize shards without a corpus to read&#39;</span>
                             <span class="s1">&#39; from! (Got corpus type: {0})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">corpus</span><span class="p">)))</span>

        <span class="n">proposed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guess_n_features</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">proposed_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Deriving dataset dimension from corpus: &#39;</span>
                             <span class="s1">&#39;{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">proposed_dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Dataset dimension derived from input corpus diffe&#39;</span>
                             <span class="s1">&#39;rs from initialization argument, using corpus.&#39;</span>
                             <span class="s1">&#39;(corpus {0}, init arg {1})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">proposed_dim</span><span class="p">,</span>
                                                                 <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">proposed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Running init from corpus.&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">doc_chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gensim</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">grouper</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">shardsize</span><span class="p">)):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Chunk no. {0} at {1} s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

            <span class="n">current_shard</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_chunk</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Current chunk dimension: &#39;</span>
                          <span class="s1">&#39;{0} x {1}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_chunk</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">doc_chunk</span><span class="p">):</span>
                <span class="n">doc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
                <span class="n">current_shard</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">itervalues</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>

            <span class="c1"># Handles the updating as well.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span><span class="p">:</span>
                <span class="n">current_shard</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">current_shard</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">save_shard</span><span class="p">(</span><span class="n">current_shard</span><span class="p">)</span>

        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Built {0} shards in {1} s.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span><span class="p">,</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span></div>

<div class="viewcode-block" id="ShardedCorpus.init_by_clone"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.init_by_clone.html#gensim.corpora.ShardedCorpus.init_by_clone">[docs]</a>    <span class="k">def</span> <span class="nf">init_by_clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize by copying over attributes of another ShardedCorpus</span>
<span class="sd">        instance saved to the output_prefix given at __init__().</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">n_shards</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">n_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">offsets</span>

        <span class="k">if</span> <span class="n">temp</span><span class="o">.</span><span class="n">dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loaded dataset dimension: {0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">temp</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Loaded dataset dimension differs from init arg &#39;</span>
                             <span class="s1">&#39;dimension, using loaded dim. &#39;</span>
                             <span class="s1">&#39;(loaded {0}, init {1})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">temp</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">dim</span>  <span class="c1"># To be consistent with the loaded data!</span></div>

<div class="viewcode-block" id="ShardedCorpus.save_shard"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.save_shard.html#gensim.corpora.ShardedCorpus.save_shard">[docs]</a>    <span class="k">def</span> <span class="nf">save_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shard</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pickle the given shard. If `n` is not given, will consider the shard</span>
<span class="sd">        a new one.</span>

<span class="sd">        If `filename` is given, will use that file name instead of generating</span>
<span class="sd">        one.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_shard</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="c1"># Saving the *next* one by default.</span>
            <span class="n">new_shard</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shard_name</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">gensim</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">pickle</span><span class="p">(</span><span class="n">shard</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">new_shard</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">shard</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span> <span class="o">+=</span> <span class="n">shard</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="o">+=</span> <span class="mi">1</span></div>

<div class="viewcode-block" id="ShardedCorpus.load_shard"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.load_shard.html#gensim.corpora.ShardedCorpus.load_shard">[docs]</a>    <span class="k">def</span> <span class="nf">load_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load (unpickle) the n-th shard as the &quot;live&quot; part of the dataset</span>
<span class="sd">        into the Dataset object.&quot;&quot;&quot;</span>
        <span class="c1">#logger.debug(&#39;ShardedCorpus loading shard {0}, &#39;</span>
        <span class="c1">#              &#39;current shard: {1}&#39;.format(n, self.current_shard_n))</span>

        <span class="c1"># No-op if the shard is already open.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shard_name</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Attempting to load nonexistent shard no. {0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="n">shard</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unpickle</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span> <span class="o">=</span> <span class="n">shard</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="n">n</span><span class="p">]</span></div>

<div class="viewcode-block" id="ShardedCorpus.reset"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.reset.html#gensim.corpora.ShardedCorpus.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset to no shard at all. Used for saving.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">=</span> <span class="bp">None</span></div>

<div class="viewcode-block" id="ShardedCorpus.shard_by_offset"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.shard_by_offset.html#gensim.corpora.ShardedCorpus.shard_by_offset">[docs]</a>    <span class="k">def</span> <span class="nf">shard_by_offset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine which shard the given offset belongs to. If the offset</span>
<span class="sd">        is greater than the number of available documents, raises a</span>
<span class="sd">        `ValueError`.</span>

<span class="sd">        Assumes that all shards have the same size.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">offset</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Too high offset specified ({0}), available &#39;</span>
                             <span class="s1">&#39;docs: {1}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">offset</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Negative offset {0} currently not&#39;</span>
                             <span class="s1">&#39; supported.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">offset</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">k</span>

        <span class="n">k</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">o</span> <span class="o">&gt;</span> <span class="n">offset</span><span class="p">:</span>  <span class="c1"># Condition should fire for every valid offset,</span>
                            <span class="c1"># since the last offset is n_docs (one-past-end).</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>   <span class="c1"># First offset is always 0, so i is at least 1.</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">k</span></div>

<div class="viewcode-block" id="ShardedCorpus.in_current"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.in_current.html#gensim.corpora.ShardedCorpus.in_current">[docs]</a>    <span class="k">def</span> <span class="nf">in_current</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine whether the given offset falls within the current shard.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span> <span class="o">&lt;=</span> <span class="n">offset</span><span class="p">)</span> \
                <span class="ow">and</span> <span class="p">(</span><span class="n">offset</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="ShardedCorpus.in_next"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.in_next.html#gensim.corpora.ShardedCorpus.in_next">[docs]</a>    <span class="k">def</span> <span class="nf">in_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine whether the given offset falls within the next shard.</span>
<span class="sd">        This is a very small speedup: typically, we will be iterating through</span>
<span class="sd">        the data forward. Could save considerable time with a very large number</span>
<span class="sd">        of smaller shards.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span> <span class="c1"># There&#39;s no next shard.</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">offset</span><span class="p">)</span> \
               <span class="ow">and</span> <span class="p">(</span><span class="n">offset</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">2</span><span class="p">])</span></div>

<div class="viewcode-block" id="ShardedCorpus.resize_shards"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.resize_shards.html#gensim.corpora.ShardedCorpus.resize_shards">[docs]</a>    <span class="k">def</span> <span class="nf">resize_shards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shardsize</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Re-process the dataset to new shard size. This may take pretty long.</span>
<span class="sd">        Also, note that you need some space on disk for this one (we&#39;re</span>
<span class="sd">        assuming there is enough disk space for double the size of the dataset</span>
<span class="sd">        and that there is enough memory for old + new shardsize).</span>

<span class="sd">        :type shardsize: int</span>
<span class="sd">        :param shardsize: The new shard size.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine how many new shards there will be</span>
        <span class="n">n_new_shards</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">shardsize</span><span class="p">)))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span> <span class="o">%</span> <span class="n">shardsize</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">n_new_shards</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">new_shard_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">new_shard_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n_new_shards</span><span class="p">):</span>
            <span class="n">new_start</span> <span class="o">=</span> <span class="n">shardsize</span> <span class="o">*</span> <span class="n">new_shard_idx</span>
            <span class="n">new_stop</span> <span class="o">=</span> <span class="n">new_start</span> <span class="o">+</span> <span class="n">shardsize</span>

            <span class="c1"># Last shard?</span>
            <span class="k">if</span> <span class="n">new_stop</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">:</span>
                <span class="c1"># Sanity check</span>
                <span class="k">assert</span> <span class="n">new_shard_idx</span> <span class="o">==</span> <span class="n">n_new_shards</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> \
                    <span class="s1">&#39;Shard no. {0} that ends at {1} over last document&#39;</span> \
                    <span class="s1">&#39; ({2}) is not the last projected shard ({3})???&#39;</span> \
                    <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">new_shard_idx</span><span class="p">,</span> <span class="n">new_stop</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">,</span> <span class="n">n_new_shards</span><span class="p">)</span>
                <span class="n">new_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span>

            <span class="n">new_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">new_start</span><span class="p">:</span><span class="n">new_stop</span><span class="p">]</span>
            <span class="n">new_shard_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resized_shard_name</span><span class="p">(</span><span class="n">new_shard_idx</span><span class="p">)</span>
            <span class="n">new_shard_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_shard_name</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_shard</span><span class="p">(</span><span class="n">new_shard</span><span class="p">,</span> <span class="n">new_shard_idx</span><span class="p">,</span> <span class="n">new_shard_name</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="c1"># Clean up on unsuccessful resize.</span>
                <span class="k">for</span> <span class="n">new_shard_name</span> <span class="ow">in</span> <span class="n">new_shard_names</span><span class="p">:</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">new_shard_name</span><span class="p">)</span>
                <span class="k">raise</span>

            <span class="n">new_offsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_stop</span><span class="p">)</span>

        <span class="c1"># Move old shard files out, new ones in. Complicated due to possibility</span>
        <span class="c1"># of exceptions.</span>
        <span class="n">old_shard_names</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_shard_name</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span><span class="p">)]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">old_shard_n</span><span class="p">,</span> <span class="n">old_shard_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_shard_names</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">old_shard_name</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;Exception occurred during old shard no. {0} &#39;</span>
                          <span class="s1">&#39;removal: {1}.</span><span class="se">\n</span><span class="s1">Attempting to at least move &#39;</span>
                          <span class="s1">&#39;new shards in.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">old_shard_n</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="c1"># If something happens with cleaning up - try to at least get the</span>
            <span class="c1"># new guys in.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">shard_n</span><span class="p">,</span> <span class="n">new_shard_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">new_shard_names</span><span class="p">):</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">new_shard_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shard_name</span><span class="p">(</span><span class="n">shard_n</span><span class="p">))</span>
            <span class="c1"># If something happens when we&#39;re in this stage, we&#39;re screwed.</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Resizing completely failed for some reason.&#39;</span>
                                   <span class="s1">&#39; Sorry, dataset is probably ruined...&#39;</span><span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="c1"># Sets the new shard stats.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="o">=</span> <span class="n">n_new_shards</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span> <span class="o">=</span> <span class="n">new_offsets</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span> <span class="o">=</span> <span class="n">shardsize</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_shard_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate the name for the n-th shard.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_resized_shard_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate the name for the n-th new shard temporary file when</span>
<span class="sd">        resizing dataset. The file will then be re-named to standard shard name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span> <span class="o">+</span> <span class="s1">&#39;.resize-temp.&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_guess_n_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attempt to guess number of features in `corpus`.&quot;&quot;&quot;</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s1">&#39;dim&#39;</span><span class="p">):</span>
            <span class="c1"># print &#39;Guessing from \&#39;dim\&#39; attribute.&#39;</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">dim</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s1">&#39;dictionary&#39;</span><span class="p">):</span>
            <span class="c1"># print &#39;GUessing from dictionary.&#39;</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">dictionary</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s1">&#39;n_out&#39;</span><span class="p">):</span>
            <span class="c1"># print &#39;Guessing from \&#39;n_out\&#39; attribute.&#39;</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">n_out</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s1">&#39;num_terms&#39;</span><span class="p">):</span>
            <span class="c1"># print &#39;Guessing from \&#39;num_terms\&#39; attribute.&#39;</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">num_terms</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">TransformedCorpus</span><span class="p">):</span>
            <span class="c1"># TransformedCorpus: first check if the transformer object</span>
            <span class="c1"># defines some output dimension; if it doesn&#39;t, relegate guessing</span>
            <span class="c1"># to the corpus that is being transformed. This may easily fail!</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guess_n_features</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">obj</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guess_n_features</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Couldn</span><span class="se">\&#39;</span><span class="s1">t find number of features, &#39;</span>
                                 <span class="s1">&#39;refusing to guess (dimension set to {0},&#39;</span>
                                 <span class="s1">&#39;type of corpus: {1}).&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">corpus</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Couldn</span><span class="se">\&#39;</span><span class="s1">t find number of features, trusting &#39;</span>
                             <span class="s1">&#39;supplied dimension ({0})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">))</span>
                <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="ow">and</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Discovered inconsistent dataset dim ({0}) and &#39;</span>
                         <span class="s1">&#39;feature count from corpus ({1}). Coercing to dimension&#39;</span>
                         <span class="s1">&#39; given by argument.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">n_features</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span>

    <span class="k">def</span> <span class="nf">_ensure_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="c1"># No shard loaded</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">shard_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_by_offset</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="n">shard_n</span><span class="p">)</span>
        <span class="c1"># Find appropriate shard, if necessary</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_current</span><span class="p">(</span><span class="n">offset</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_next</span><span class="p">(</span><span class="n">offset</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shard_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_by_offset</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="n">shard_n</span><span class="p">)</span>

<div class="viewcode-block" id="ShardedCorpus.get_by_offset"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.get_by_offset.html#gensim.corpora.ShardedCorpus.get_by_offset">[docs]</a>    <span class="k">def</span> <span class="nf">get_by_offset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;As opposed to getitem, this one only accepts ints as offsets.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_shard</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="p">[</span><span class="n">offset</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the given row of the dataset. Supports slice notation.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>

            <span class="c1"># Handle all serialization &amp; retrieval options.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span><span class="p">:</span>
                <span class="n">l_result</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_by_offset</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                                          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">offset</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gensim</span><span class="p">:</span>
                    <span class="n">l_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_sparse2gensim</span><span class="p">(</span><span class="n">l_result</span><span class="p">)</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_retrieval</span><span class="p">:</span>
                    <span class="n">l_result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">l_result</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">l_result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_by_offset</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">offset</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gensim</span><span class="p">:</span>
                    <span class="n">l_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_dense2gensim</span><span class="p">(</span><span class="n">l_result</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_retrieval</span><span class="p">:</span>
                    <span class="n">l_result</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">l_result</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">l_result</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">offset</span><span class="o">.</span><span class="n">start</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="n">offset</span><span class="o">.</span><span class="n">stop</span>
            <span class="k">if</span> <span class="n">stop</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;Requested slice offset {0} out of range&#39;</span>
                                 <span class="s1">&#39; ({1} docs)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">))</span>

            <span class="c1"># - get range of shards over which to iterate</span>
            <span class="n">first_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_by_offset</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>

            <span class="n">last_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_shards</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">stop</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_docs</span><span class="p">:</span>
                <span class="n">last_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard_by_offset</span><span class="p">(</span><span class="n">stop</span><span class="p">)</span>
                <span class="c1"># This fails on one-past</span>
                <span class="c1"># slice indexing; that&#39;s why there&#39;s a code branch here.</span>

            <span class="c1">#logger.debug(&#39;ShardedCorpus: Retrieving slice {0}: &#39;</span>
            <span class="c1">#              &#39;shard {1}&#39;.format((offset.start, offset.stop),</span>
            <span class="c1">#                                 (first_shard, last_shard)))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="n">first_shard</span><span class="p">)</span>

            <span class="c1"># The easy case: both in one shard.</span>
            <span class="k">if</span> <span class="n">first_shard</span> <span class="o">==</span> <span class="n">last_shard</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="p">[</span><span class="n">start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">:</span>
                                            <span class="n">stop</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span><span class="p">]</span>
                <span class="c1"># Handle different sparsity settings:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_format</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>

                <span class="k">return</span> <span class="n">s_result</span>

            <span class="c1"># The hard case: the slice is distributed across multiple shards</span>
            <span class="c1"># - initialize numpy.zeros()</span>
            <span class="n">s_result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span>
                                   <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span>
                                             <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># - gradually build it up. We will be using three set of start:stop</span>
            <span class="c1">#   indexes:</span>
            <span class="c1">#    - into the dataset (these are the indexes the caller works with)</span>
            <span class="c1">#    - into the current shard</span>
            <span class="c1">#    - into the result</span>

            <span class="c1"># Indexes into current result rows. These are always smaller than</span>
            <span class="c1"># the dataset indexes by `start` (as we move over the shards,</span>
            <span class="c1"># we&#39;re moving by the same number of rows through the result).</span>
            <span class="n">result_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">result_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">start</span>

            <span class="c1"># Indexes into current shard. These are trickiest:</span>
            <span class="c1">#  - if in starting shard, these are from (start - current_offset)</span>
            <span class="c1">#    to self.shardsize</span>
            <span class="c1">#  - if in intermediate shard, these are from 0 to self.shardsize</span>
            <span class="c1">#  - if in ending shard, these are from 0</span>
            <span class="c1">#    to (stop - current_offset)</span>
            <span class="n">shard_start</span> <span class="o">=</span> <span class="n">start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span>
            <span class="n">shard_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_shard_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> \
                         <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span>

            <span class="c1">#s_result[result_start:result_stop] = self.current_shard[</span>
            <span class="c1">#                                         shard_start:shard_stop]</span>
            <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__add_to_slice</span><span class="p">(</span><span class="n">s_result</span><span class="p">,</span> <span class="n">result_start</span><span class="p">,</span> <span class="n">result_stop</span><span class="p">,</span>
                                           <span class="n">shard_start</span><span class="p">,</span> <span class="n">shard_stop</span><span class="p">)</span>

            <span class="c1"># First and last get special treatment, these are in between</span>
            <span class="k">for</span> <span class="n">shard_n</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">first_shard</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_shard</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="n">shard_n</span><span class="p">)</span>

                <span class="n">result_start</span> <span class="o">=</span> <span class="n">result_stop</span>
                <span class="n">result_stop</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span>
                <span class="n">shard_start</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">shard_stop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shardsize</span>

                <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__add_to_slice</span><span class="p">(</span><span class="n">s_result</span><span class="p">,</span> <span class="n">result_start</span><span class="p">,</span>
                                               <span class="n">result_stop</span><span class="p">,</span> <span class="n">shard_start</span><span class="p">,</span>
                                               <span class="n">shard_stop</span><span class="p">)</span>

            <span class="c1"># Last shard</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_shard</span><span class="p">(</span><span class="n">last_shard</span><span class="p">)</span>
            <span class="n">result_start</span> <span class="o">=</span> <span class="n">result_stop</span>
            <span class="n">result_stop</span> <span class="o">+=</span> <span class="n">stop</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span>
            <span class="n">shard_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">shard_stop</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_offset</span>

            <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__add_to_slice</span><span class="p">(</span><span class="n">s_result</span><span class="p">,</span> <span class="n">result_start</span><span class="p">,</span> <span class="n">result_stop</span><span class="p">,</span>
                                           <span class="n">shard_start</span><span class="p">,</span> <span class="n">shard_stop</span><span class="p">)</span>

            <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_format</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">s_result</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_by_offset</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
            <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_format</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">s_result</span>

    <span class="k">def</span> <span class="nf">__add_to_slice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s_result</span><span class="p">,</span> <span class="n">result_start</span><span class="p">,</span> <span class="n">result_stop</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add the rows of the current shard from `start` to `stop`</span>
<span class="sd">        into rows `result_start` to `result_stop` of `s_result`.</span>

<span class="sd">        Operation is based on the self.sparse_serialize setting. If the shard</span>
<span class="sd">        contents are dense, then s_result is assumed to be an ndarray that</span>
<span class="sd">        already supports row indices `result_start:result_stop`. If the shard</span>
<span class="sd">        contents are sparse, assumes that s_result has `result_start` rows</span>
<span class="sd">        and we should add them up to `result_stop`.</span>

<span class="sd">        Returns the resulting s_result.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">result_stop</span> <span class="o">-</span> <span class="n">result_start</span><span class="p">)</span> <span class="o">!=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Result start/stop range different than stop/start&#39;</span>
                             <span class="s1">&#39;range (</span><span class="si">%d</span><span class="s1"> - </span><span class="si">%d</span><span class="s1"> vs. </span><span class="si">%d</span><span class="s1"> - </span><span class="si">%d</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">result_start</span><span class="p">,</span>
                                                                  <span class="n">result_stop</span><span class="p">,</span>
                                                                  <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">))</span>

        <span class="c1"># Dense data: just copy using numpy&#39;s slice notation</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span><span class="p">:</span>
            <span class="n">s_result</span><span class="p">[</span><span class="n">result_start</span><span class="p">:</span><span class="n">result_stop</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>

            <span class="k">return</span> <span class="n">s_result</span>

        <span class="c1"># A bit more difficult, we&#39;re using a different structure to build the</span>
        <span class="c1"># result.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">s_result</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">result_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Assuption about sparse s_result shape &#39;</span>
                                 <span class="s1">&#39;invalid: {0} expected rows, {1} real &#39;</span>
                                 <span class="s1">&#39;rows.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">result_start</span><span class="p">,</span>
                                                <span class="n">s_result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

            <span class="n">tmp_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_shard</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>
            <span class="n">s_result</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">s_result</span><span class="p">,</span> <span class="n">tmp_matrix</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">s_result</span>

    <span class="k">def</span> <span class="nf">_getitem_format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s_result</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_serialization</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gensim</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_sparse2gensim</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_retrieval</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">s_result</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gensim</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem_dense2gensim</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_retrieval</span><span class="p">:</span>
                <span class="n">s_result</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">s_result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">s_result</span>

    <span class="k">def</span> <span class="nf">_getitem_sparse2gensim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Change given sparse result matrix to gensim sparse vectors.</span>

<span class="sd">        Uses the internals of the sparse matrix to make this fast.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">row_sparse2gensim</span><span class="p">(</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">csr_matrix</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">row_idx</span><span class="p">]:</span><span class="n">csr_matrix</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="n">row_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">g_row</span> <span class="o">=</span> <span class="p">[(</span><span class="n">col_idx</span><span class="p">,</span> <span class="n">csr_matrix</span><span class="p">[</span><span class="n">row_idx</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">col_idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">g_row</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">row_sparse2gensim</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">_getitem_dense2gensim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Change given dense result matrix to gensim sparse vectors.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">full2sparse</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">full2sparse</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="c1"># Overriding the IndexedCorpus and other corpus superclass methods</span>
    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Yield dataset items one by one (generator).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<div class="viewcode-block" id="ShardedCorpus.save"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.save.html#gensim.corpora.ShardedCorpus.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save itself (the wrapper) in clean state (after calling `reset()`)</span>
<span class="sd">        to the output_prefix file. If you wish to save to a different file,</span>
<span class="sd">        use the `fname` argument as the first positional arg.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Can we save to a different file than output_prefix? Well, why not?</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">output_prefix</span><span class="p">])</span>

        <span class="n">attrs_to_ignore</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;current_shard&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;current_shard_n&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;current_offset&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;ignore&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;ignore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">attrs_to_ignore</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;ignore&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;ignore&#39;</span><span class="p">]]</span>
                                         <span class="o">+</span> <span class="n">attrs_to_ignore</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ShardedCorpus</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
        <span class="c1">#</span>
        <span class="c1"># self.reset()</span>
        <span class="c1"># with smart_open(self.output_prefix, &#39;wb&#39;) as pickle_handle:</span>
        <span class="c1">#     cPickle.dump(self, pickle_handle)</span>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="ShardedCorpus.load"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.load.html#gensim.corpora.ShardedCorpus.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="n">mmap</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load itself in clean state. `mmap` has no effect here.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ShardedCorpus</span><span class="p">,</span> <span class="n">cls</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">mmap</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="ShardedCorpus.save_corpus"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.save_corpus.html#gensim.corpora.ShardedCorpus.save_corpus">[docs]</a>    <span class="k">def</span> <span class="nf">save_corpus</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">progress_cnt</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">metadata</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement a serialization interface. Do not call directly;</span>
<span class="sd">        use the `serialize` method instead.</span>

<span class="sd">        Note that you might need some ShardedCorpus init parameters, most</span>
<span class="sd">        likely the dimension (`dim`). Again, pass these as `kwargs` to the</span>
<span class="sd">        `serialize` method.</span>

<span class="sd">        All this thing does is initialize a ShardedCorpus from a corpus</span>
<span class="sd">        with the `output_prefix` argument set to the `fname` parameter</span>
<span class="sd">        of this method. The initialization of a ShardedCorpus takes care of</span>
<span class="sd">        serializing the data (in dense form) to shards.</span>

<span class="sd">        Ignore the parameters id2word, progress_cnt and metadata. They</span>
<span class="sd">        currently do nothing and are here only to provide a compatible</span>
<span class="sd">        method signature with superclass.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ShardedCorpus</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="ShardedCorpus.serialize"><a class="viewcode-back" href="../../../generated/generated/gensim.corpora.ShardedCorpus.serialize.html#gensim.corpora.ShardedCorpus.serialize">[docs]</a>    <span class="k">def</span> <span class="nf">serialize</span><span class="p">(</span><span class="n">serializer</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                  <span class="n">index_fname</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">progress_cnt</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                  <span class="n">metadata</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Iterate through the document stream `corpus`, saving the documents</span>
<span class="sd">        as a ShardedCorpus to `fname`.</span>

<span class="sd">        Use this method instead of calling `save_corpus` directly.</span>
<span class="sd">        You may need to supply some kwargs that are used upon dataset creation</span>
<span class="sd">        (namely: `dim`, unless the dataset can infer the dimension from the</span>
<span class="sd">        given corpus).</span>

<span class="sd">        Ignore the parameters id2word, index_fname, progress_cnt, labels</span>
<span class="sd">        and metadata. They currently do nothing and are here only to</span>
<span class="sd">        provide a compatible method signature with superclass.&quot;&quot;&quot;</span>
        <span class="n">serializer</span><span class="o">.</span><span class="n">save_corpus</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">,</span>
                               <span class="n">progress_cnt</span><span class="o">=</span><span class="n">progress_cnt</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
                               <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>